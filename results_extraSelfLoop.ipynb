{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCeLvoG42mR-",
    "outputId": "0a1ab954-0203-4fe4-b4ea-8b99df6c55f9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.0.1+cu118\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.2/10.2 MB\u001B[0m \u001B[31m44.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.8/4.8 MB\u001B[0m \u001B[31m14.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for torch_geometric (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfDUxD4K3ffO",
    "outputId": "761eee91-d12b-4840-bec0-8cba5c0c5eeb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ShrjQlIi2jyd",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:20:25.276245800Z",
     "start_time": "2023-09-02T08:20:18.407580600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "M0sP-lhX2jyf"
   },
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "WxtE7U-Q2jyg",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:20:25.286246900Z",
     "start_time": "2023-09-02T08:20:25.276245800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, mode=1):\n",
    "        if mode == 1:\n",
    "            x = F.dropout(x,p = 0.5 ,training=self.training)\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x,p = 0.5 ,training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = F.dropout(x,p = 0.05 ,training=self.training)\n",
    "            x = F.relu(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        elif mode == 2:\n",
    "            x = F.dropout(x,p = 0.5 ,training=self.training)\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x,p = 0.5 ,training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = F.dropout(x,p = 0.05 ,training=self.training)\n",
    "            x = F.relu(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "YWcL8Czb2jyg"
   },
   "source": [
    "# GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Vemn24NQ2jyh",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:20:25.296246300Z",
     "start_time": "2023-09-02T08:20:25.286246900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, Linear\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "\n",
    "# Define the GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, output_dim, embedding_dimension=32, num_heads=8):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, embedding_dimension, heads=num_heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(num_heads * embedding_dimension, output_dim, heads=num_heads, dropout=0.6)\n",
    "        self.linear1 = Linear(embedding_dimension * 2 * num_heads, 32)\n",
    "        # self.linear2 = Linear(32, 16)\n",
    "        # self.linear3 = Linear(16, 8)\n",
    "\n",
    "    def forward(self, x, edge_index, mode=1):\n",
    "        if mode == 1:\n",
    "            # Pass the input through the first GAT layer\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        elif mode == 2:\n",
    "            # Pass the input through the first GAT layer\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "M12hQ2Fu2jyh"
   },
   "source": [
    "# GATv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "W78B0Qg_2jyh",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:20:25.316246800Z",
     "start_time": "2023-09-02T08:20:25.296246300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, Linear\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "\n",
    "# Define the GAT model\n",
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, num_features, output_dim, embedding_dimension=16, num_heads=8):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.conv1 = GATv2Conv(num_features, embedding_dimension, heads=num_heads, dropout=0.6)\n",
    "        self.conv2 = GATv2Conv(num_heads * embedding_dimension, embedding_dimension, heads=num_heads, dropout=0.6)\n",
    "        self.linear1 = Linear(embedding_dimension * num_heads, output_dim)\n",
    "        self.linear2 = Linear(embedding_dimension, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, mode=1):\n",
    "        if mode == 1:\n",
    "            # Pass the input through the first GAT layer\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        elif mode == 2:\n",
    "            # Pass the input through the first GAT layer\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p = 0.6 , training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hi9k4bl42jyi",
    "outputId": "bcded8b2-a894-4395-87bc-77991563aa79",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:20:35.502667700Z",
     "start_time": "2023-09-02T08:20:35.492667600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x39PC4j_2jyj",
    "outputId": "e31d2952-21dd-4e4e-e655-b654075fb0d6",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:20:45.682621200Z",
     "start_time": "2023-09-02T08:20:45.672675500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "BuctMzAw2jyj"
   },
   "source": [
    "# Create new masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "cOMYGWQs2jyj",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:01.569148900Z",
     "start_time": "2023-09-02T08:21:01.559147800Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def make_random_mask(size, train_fraction, validation_fraction=0):\n",
    "    new_order = random.sample(range(size), size)\n",
    "\n",
    "    ls_train = np.zeros(size, dtype=bool)\n",
    "    ls_validation = np.zeros(size, dtype=bool)\n",
    "    ls_test = np.zeros(size, dtype=bool)\n",
    "\n",
    "    for i, value in enumerate(new_order):\n",
    "        if i < int(size * train_fraction):\n",
    "            ls_train[value] = True\n",
    "            ls_validation[value] = False\n",
    "            ls_test[value] = False\n",
    "        elif i < int(size * (train_fraction + validation_fraction)):\n",
    "            ls_train[value] = False\n",
    "            ls_validation[value] = True\n",
    "            ls_test[value] = False\n",
    "        else:\n",
    "            ls_train[value] = False\n",
    "            ls_validation[value] = False\n",
    "            ls_test[value] = True\n",
    "\n",
    "    ls_train = torch.from_numpy(ls_train)\n",
    "    ls_validation = torch.from_numpy(ls_validation)\n",
    "    ls_test = torch.from_numpy(ls_test)\n",
    "\n",
    "    return ls_train, ls_validation, ls_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "M5AnH_522jyj",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:02.062903100Z",
     "start_time": "2023-09-02T08:21:02.052850100Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_GNN_mode_and_save(model, data, epochs, train_mask, test_mask, gnn_name=\"GNN_embeds.pt\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            model.eval()\n",
    "            pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "            correct = (pred[test_mask] == data.y[test_mask]).sum()\n",
    "            acc = int(correct) / int(test_mask.sum())\n",
    "            print(f'epoch : {epoch + 1} = >  Accuracy: {acc:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "    correct = (pred[test_mask] == data.y[test_mask]).sum()\n",
    "    acc = int(correct) / int(test_mask.sum())\n",
    "    print(f'Final accuracy: {acc:.4f}')\n",
    "\n",
    "    # now save\n",
    "    model.eval()\n",
    "    pred_emb = model(data.x, data.edge_index, mode=2)\n",
    "    torch.save(pred_emb, gnn_name)\n",
    "\n",
    "    return acc, pred[test_mask], data.y[test_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "hHYonHDt2jyk"
   },
   "source": [
    "# Ecoder decodre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Fc1qByrB2jyk",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:05.945743400Z",
     "start_time": "2023-09-02T08:21:05.915743900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "f7Ka2rKU2jyk",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:07.180976100Z",
     "start_time": "2023-09-02T08:21:07.170710700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define autoencoder\n",
    "class SymmetricAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size):\n",
    "        super(SymmetricAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoder_layers = []\n",
    "        self.decoder_layers = []\n",
    "\n",
    "        # Encoder\n",
    "        size = input_size\n",
    "        while size > embedding_size:\n",
    "            next_size = 2 ** int(math.log2(size) - 1)\n",
    "            self.encoder_layers.append(nn.Linear(size, next_size))\n",
    "            self.encoder_layers.append(nn.ReLU())\n",
    "            size = next_size\n",
    "\n",
    "        self.embedding = nn.Linear(size, embedding_size)\n",
    "\n",
    "        # Decoder\n",
    "\n",
    "        size = embedding_size\n",
    "\n",
    "        while size < input_size:\n",
    "            self.decoder_layers.append(nn.Linear(size, size * 2))\n",
    "            self.encoder_layers.append(nn.ReLU())\n",
    "            size = size * 2\n",
    "\n",
    "        self.decoder_layers.append(nn.Linear(size, input_size))\n",
    "\n",
    "        self.encoder = nn.Sequential(*self.encoder_layers)\n",
    "        self.decoder = nn.Sequential(*self.decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        embedded = self.embedding(encoded)\n",
    "        decoded = self.decoder(embedded)\n",
    "        return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "oUdkMtVy2jyk",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:08.249173700Z",
     "start_time": "2023-09-02T08:21:08.229144800Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_enc_embeds(data_features, num_features, num_epochs=5000, embedding_size=32, file_name=\"encoder_32.pt\"):\n",
    "    # Initialize model and optimizer\n",
    "    model = SymmetricAutoencoder(num_features, embedding_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00003)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed = model(data_features)\n",
    "        loss = criterion(reconstructed, data_features)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "    # Now you can use the encoder part of the trained autoencoder to get embeddings\n",
    "    encoded_features = model.encoder(data_features)\n",
    "    torch.save(encoded_features, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "def split_data(dataset, num_each_class_train, num_val=500, num_test=1000):\n",
    "    data = dataset[0]\n",
    "    y = torch.detach(data.y).numpy()\n",
    "    keys = [x for x in range(len(y))]\n",
    "    y_dictionary = dict(zip(keys, y))\n",
    "    score_list = set(y)\n",
    "    dic_list = [[] for i in range(len(score_list))]\n",
    "\n",
    "    for item in y_dictionary:\n",
    "        dic_list[y_dictionary[item]].append(item)\n",
    "\n",
    "    l = []\n",
    "    for sample_list in (dic_list):\n",
    "        s_list = random.sample(sample_list, num_each_class_train)\n",
    "        l.extend(s_list)\n",
    "\n",
    "    train_mask = [False for i in range(len(data.x))]\n",
    "    for num in l:\n",
    "        train_mask[num] = True\n",
    "    mylist = [x for x in range(len(data.x))]\n",
    "    mylist = [elt for elt in mylist if elt not in l]\n",
    "    l1 = random.sample(mylist, num_val)\n",
    "    mylist = [elt for elt in mylist if elt not in l1]\n",
    "    val_mask = [False for i in range(len(data.x))]\n",
    "    for num in l1:\n",
    "        val_mask[num] = True\n",
    "\n",
    "    l2 = random.sample(mylist, num_test)\n",
    "    test_mask = [False for i in range(len(data.x))]\n",
    "    for num in l2:\n",
    "        test_mask[num] = True\n",
    "\n",
    "    return train_mask, val_mask, test_mask"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:09.125707900Z",
     "start_time": "2023-09-02T08:21:09.115705300Z"
    },
    "id": "k1gzNnVkUMvM"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "xkFNBjZL2jyk"
   },
   "source": [
    "# load ,concat  and finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CBI8vrT42jyk",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:21.260404500Z",
     "start_time": "2023-09-02T08:21:21.240407100Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layer=64):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(input_size, hidden_layer)\n",
    "        self.linear2 = Linear(hidden_layer, hidden_layer)\n",
    "        self.linear3 = Linear(hidden_layer, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "N9KxqYlK2jyk",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:40:23.093680300Z",
     "start_time": "2023-09-02T08:40:23.070727600Z"
    }
   },
   "outputs": [],
   "source": [
    "def finalizer_DNN(train_mask, test_mask, hidden_layer_DNN_size=256, repeat_threshold=0.85,lr=0.001, epochs=3000,\n",
    "                  file_name_gnn_emb=\"GNN_embeds.pt\",\n",
    "                  file_name_enc_emb=\"encoder_emb32_cora.pt\", validation_mask = None , early_stop=0.9):\n",
    "    gnn_emb = torch.load(file_name_gnn_emb).to(device)\n",
    "    enc_emb = torch.load(file_name_enc_emb).to(device)\n",
    "\n",
    "    concated_data = torch.cat((gnn_emb, enc_emb), dim=1)\n",
    "\n",
    "    input_size = concated_data.shape[1]\n",
    "    model = DNN(input_size, dataset.num_classes, hidden_layer=hidden_layer_DNN_size).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(concated_data)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            model.eval()\n",
    "\n",
    "            pred = model(concated_data).argmax(dim=1)\n",
    "            correct = (pred[train_mask] == data.y[train_mask]).sum()\n",
    "            acc_train = int(correct) / int(train_mask.sum())\n",
    "\n",
    "            correct = (pred[test_mask] == data.y[test_mask]).sum()\n",
    "            acc = int(correct) / int(test_mask.sum())\n",
    "            print(f'epoch {epoch} ,Accuracy: {acc:.4f} , train acc : {acc_train}')\n",
    "\n",
    "            if validation_mask is not None:\n",
    "              correct = (pred[validation_mask] == data.y[validation_mask]).sum()\n",
    "              acc_validation = int(correct) / int(validation_mask.sum())\n",
    "              if  acc_validation > early_stop:\n",
    "                break\n",
    "\n",
    "\n",
    "    # calculate train accuracy\n",
    "    pred = model(concated_data).argmax(dim=1)\n",
    "    correct = (pred[new_train_mask] == data.y[new_train_mask]).sum()\n",
    "    acc_train = int(correct) / int(new_train_mask.sum())\n",
    "\n",
    "    if (acc_train < repeat_threshold):\n",
    "        return finalizer_DNN(train_mask, test_mask, repeat_threshold=repeat_threshold, epochs=epochs,\n",
    "                             file_name_gnn_emb=file_name_gnn_emb,\n",
    "                             file_name_enc_emb=file_name_enc_emb)\n",
    "\n",
    "    model.eval()\n",
    "    pred = model(concated_data).argmax(dim=1)\n",
    "    correct = (pred[test_mask] == data.y[test_mask]).sum()\n",
    "    acc = int(correct) / int(test_mask.sum())\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "    return acc, pred[test_mask], data.y[test_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "LdB5TcNl2jyk"
   },
   "source": [
    "# ALL scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lBHpACd52jyk",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:21:54.338327100Z",
     "start_time": "2023-09-02T08:21:54.328325800Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_details(acc_list, f1_score_list):\n",
    "    print(f'Accuracy avg = {statistics.mean(acc_list)}')\n",
    "    print(f'Accuracy deviation = {statistics.stdev(acc_list)}')\n",
    "    print(f'F1 score(macro) avg = {statistics.mean(f1_score_list)}')\n",
    "    print(f'F1 score(macro) deviation = {statistics.stdev(f1_score_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import statistics\n",
    "from sklearn.metrics import f1_score\n",
    "import copy\n",
    "\n",
    "def run_model(GNN_model , Gnn_epochs ,enc_address ,reply_threshold , head_epochs, validation_mask =None , early_stop = 0.9 ,hidden_layer_DNN_size= 256):\n",
    "  f1_score_list_base = []\n",
    "  acc_list_base = []\n",
    "\n",
    "  f1_score_list = []\n",
    "  acc_list = []\n",
    "  for i in range(10):\n",
    "\n",
    "      model = copy.deepcopy(GNN_model)\n",
    "      print(\"*****\")\n",
    "      print(f'epoch : {i + 1} / 10')\n",
    "      # model = GATv2(dataset.num_features, dataset.num_classes, embedding_dimension=32).to(device)\n",
    "      # GNN_model = GAT(dataset.num_features, dataset.num_classes, embedding_dimension=128).to(device)\n",
    "      # model = GCN(128, dataset.num_classes).to(device)\n",
    "      acc_base, preds_base, labels_base = train_GNN_mode_and_save(model, data, Gnn_epochs, train_mask=new_train_mask,\n",
    "                                                                  test_mask=new_test_mask)\n",
    "      preds_base = preds_base.cpu().numpy()\n",
    "      labels_base = labels_base.cpu().numpy()\n",
    "      f1_score_base = f1_score(labels_base, preds_base, average='macro')\n",
    "\n",
    "      f1_score_list_base.append(f1_score_base)\n",
    "      acc_list_base.append(acc_base)\n",
    "\n",
    "      acc, preds, labels = finalizer_DNN(train_mask=new_train_mask, epochs=head_epochs, test_mask=new_test_mask,\n",
    "                                        repeat_threshold=reply_threshold,\n",
    "                                        file_name_enc_emb=enc_address,\n",
    "                                        validation_mask = validation_mask,\n",
    "                                        early_stop = early_stop,\n",
    "                                        hidden_layer_DNN_size = hidden_layer_DNN_size)\n",
    "\n",
    "      preds = preds.cpu().numpy()\n",
    "      labels = labels.cpu().numpy()\n",
    "\n",
    "      print(\"base model\")\n",
    "      print(acc_base)\n",
    "      print(f1_score_base)\n",
    "\n",
    "      print(\"OurModel\")\n",
    "      print(acc)\n",
    "      print(f1_score(labels, preds, average='macro'))\n",
    "      f1_score_list.append(f1_score(labels, preds, average='macro'))\n",
    "      acc_list.append(acc)\n",
    "\n",
    "\n",
    "  print(\"+++***Fianal Result***+++\")\n",
    "  print(\"base\")\n",
    "  print_details(acc_list_base, f1_score_list_base)\n",
    "  print(\"new model\")\n",
    "  print_details(acc_list, f1_score_list)"
   ],
   "metadata": {
    "id": "uCpjqLer3fC3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.utils import add_self_loops"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "0MwOEsCf7s4r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch_geometric.utils import add_self_loops"
   ],
   "metadata": {
    "id": "-VzR7Ukisjnr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "D22OuveT2jyn"
   },
   "source": [
    "# BlogCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTZTRW5s2jyo",
    "outputId": "474558c7-e994-4ea5-8533-aded37edf28c",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:59:20.122924500Z",
     "start_time": "2023-09-02T08:59:20.106846800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cU7z73Z2jyo",
    "outputId": "04b83332-6f84-4e76-e49a-13d94786d530",
    "ExecuteTime": {
     "end_time": "2023-09-02T08:59:28.608090500Z",
     "start_time": "2023-09-02T08:59:20.934497500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes in BlogCatalog: 6\n",
      "Number of Node Features in BlogCatalog: 8189\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import AttributedGraphDataset\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "name_data = 'BlogCatalog'\n",
    "dataset = AttributedGraphDataset(root='/tmp/' + name_data, name=name_data)\n",
    "\n",
    "# dataset.transform = T.NormalizeFeatures()\n",
    "print(f\"Number of Classes in {name_data}:\", dataset.num_classes)\n",
    "print(f\"Number of Node Features in {name_data}:\", dataset.num_node_features)\n",
    "data = dataset[0]\n",
    "data.edge_index = add_self_loops(data.edge_index, num_nodes=data.num_nodes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7VCleDQL2jyo",
    "ExecuteTime": {
     "end_time": "2023-09-02T09:02:09.943254300Z",
     "start_time": "2023-09-02T09:02:09.895254600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "features = data.x  # Feature matrix\n",
    "num_features = features.shape[1]\n",
    "\n",
    "new_train_mask, new_valdation_mask, new_test_mask = make_random_mask(data.x.shape[0], 0.5, 0.2)\n",
    "new_train_mask, new_test_mask.shape\n",
    "#\n",
    "# new_train_mask = data.train_mask\n",
    "# new_test_mask = data.test_mask\n",
    "\n",
    "data = data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Flft84Ek2jyo",
    "outputId": "918700cc-171a-44b7-9fa9-d4994b0091f1",
    "ExecuteTime": {
     "end_time": "2023-09-02T09:11:20.420216300Z",
     "start_time": "2023-09-02T09:02:11.002379800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.008797779679298401\n",
      "Epoch [2/1000], Loss: 0.008658826351165771\n",
      "Epoch [3/1000], Loss: 0.00854803342372179\n",
      "Epoch [4/1000], Loss: 0.008452270179986954\n",
      "Epoch [5/1000], Loss: 0.008364767767488956\n",
      "Epoch [6/1000], Loss: 0.008282391354441643\n",
      "Epoch [7/1000], Loss: 0.00820410717278719\n",
      "Epoch [8/1000], Loss: 0.008130121976137161\n",
      "Epoch [9/1000], Loss: 0.008061368018388748\n",
      "Epoch [10/1000], Loss: 0.007999199442565441\n",
      "Epoch [11/1000], Loss: 0.007945405319333076\n",
      "Epoch [12/1000], Loss: 0.007902255281805992\n",
      "Epoch [13/1000], Loss: 0.007871883921325207\n",
      "Epoch [14/1000], Loss: 0.00785469077527523\n",
      "Epoch [15/1000], Loss: 0.007847809232771397\n",
      "Epoch [16/1000], Loss: 0.007845879532396793\n",
      "Epoch [17/1000], Loss: 0.007844439707696438\n",
      "Epoch [18/1000], Loss: 0.007841890677809715\n",
      "Epoch [19/1000], Loss: 0.007838337682187557\n",
      "Epoch [20/1000], Loss: 0.007834013551473618\n",
      "Epoch [21/1000], Loss: 0.007829245179891586\n",
      "Epoch [22/1000], Loss: 0.007824593223631382\n",
      "Epoch [23/1000], Loss: 0.00782056711614132\n",
      "Epoch [24/1000], Loss: 0.007817360572516918\n",
      "Epoch [25/1000], Loss: 0.007814859040081501\n",
      "Epoch [26/1000], Loss: 0.007812830619513988\n",
      "Epoch [27/1000], Loss: 0.007811065297573805\n",
      "Epoch [28/1000], Loss: 0.00780942477285862\n",
      "Epoch [29/1000], Loss: 0.00780785595998168\n",
      "Epoch [30/1000], Loss: 0.0078063663095235825\n",
      "Epoch [31/1000], Loss: 0.007804990746080875\n",
      "Epoch [32/1000], Loss: 0.007803762331604958\n",
      "Epoch [33/1000], Loss: 0.007802685722708702\n",
      "Epoch [34/1000], Loss: 0.007801737170666456\n",
      "Epoch [35/1000], Loss: 0.00780088035389781\n",
      "Epoch [36/1000], Loss: 0.007800073828548193\n",
      "Epoch [37/1000], Loss: 0.00779928732663393\n",
      "Epoch [38/1000], Loss: 0.007798513863235712\n",
      "Epoch [39/1000], Loss: 0.007797767873853445\n",
      "Epoch [40/1000], Loss: 0.007797077298164368\n",
      "Epoch [41/1000], Loss: 0.007796474266797304\n",
      "Epoch [42/1000], Loss: 0.007795977406203747\n",
      "Epoch [43/1000], Loss: 0.007795588579028845\n",
      "Epoch [44/1000], Loss: 0.007795293349772692\n",
      "Epoch [45/1000], Loss: 0.007795066572725773\n",
      "Epoch [46/1000], Loss: 0.0077948784455657005\n",
      "Epoch [47/1000], Loss: 0.007794705219566822\n",
      "Epoch [48/1000], Loss: 0.007794528733938932\n",
      "Epoch [49/1000], Loss: 0.007794337812811136\n",
      "Epoch [50/1000], Loss: 0.007794135250151157\n",
      "Epoch [51/1000], Loss: 0.0077939266338944435\n",
      "Epoch [52/1000], Loss: 0.007793724536895752\n",
      "Epoch [53/1000], Loss: 0.00779353454709053\n",
      "Epoch [54/1000], Loss: 0.007793368771672249\n",
      "Epoch [55/1000], Loss: 0.007793229538947344\n",
      "Epoch [56/1000], Loss: 0.0077931261621415615\n",
      "Epoch [57/1000], Loss: 0.007793055847287178\n",
      "Epoch [58/1000], Loss: 0.00779300881549716\n",
      "Epoch [59/1000], Loss: 0.0077929748222231865\n",
      "Epoch [60/1000], Loss: 0.007792939431965351\n",
      "Epoch [61/1000], Loss: 0.007792897056788206\n",
      "Epoch [62/1000], Loss: 0.007792843971401453\n",
      "Epoch [63/1000], Loss: 0.007792781572788954\n",
      "Epoch [64/1000], Loss: 0.007792717777192593\n",
      "Epoch [65/1000], Loss: 0.007792659103870392\n",
      "Epoch [66/1000], Loss: 0.007792607881128788\n",
      "Epoch [67/1000], Loss: 0.007792569696903229\n",
      "Epoch [68/1000], Loss: 0.007792538497596979\n",
      "Epoch [69/1000], Loss: 0.007792516611516476\n",
      "Epoch [70/1000], Loss: 0.007792498450726271\n",
      "Epoch [71/1000], Loss: 0.007792482618242502\n",
      "Epoch [72/1000], Loss: 0.00779246911406517\n",
      "Epoch [73/1000], Loss: 0.007792455144226551\n",
      "Epoch [74/1000], Loss: 0.007792440243065357\n",
      "Epoch [75/1000], Loss: 0.0077924239449203014\n",
      "Epoch [76/1000], Loss: 0.007792408112436533\n",
      "Epoch [77/1000], Loss: 0.0077923922799527645\n",
      "Epoch [78/1000], Loss: 0.0077923801727592945\n",
      "Epoch [79/1000], Loss: 0.007792370393872261\n",
      "Epoch [80/1000], Loss: 0.007792362477630377\n",
      "Epoch [81/1000], Loss: 0.00779235502704978\n",
      "Epoch [82/1000], Loss: 0.007792348973453045\n",
      "Epoch [83/1000], Loss: 0.007792342454195023\n",
      "Epoch [84/1000], Loss: 0.007792337331920862\n",
      "Epoch [85/1000], Loss: 0.0077923317439854145\n",
      "Epoch [86/1000], Loss: 0.007792327087372541\n",
      "Epoch [87/1000], Loss: 0.007792321033775806\n",
      "Epoch [88/1000], Loss: 0.007792316842824221\n",
      "Epoch [89/1000], Loss: 0.007792314048856497\n",
      "Epoch [90/1000], Loss: 0.007792310789227486\n",
      "Epoch [91/1000], Loss: 0.007792307995259762\n",
      "Epoch [92/1000], Loss: 0.007792305201292038\n",
      "Epoch [93/1000], Loss: 0.007792302872985601\n",
      "Epoch [94/1000], Loss: 0.007792300544679165\n",
      "Epoch [95/1000], Loss: 0.007792299147695303\n",
      "Epoch [96/1000], Loss: 0.007792297750711441\n",
      "Epoch [97/1000], Loss: 0.007792296353727579\n",
      "Epoch [98/1000], Loss: 0.007792294025421143\n",
      "Epoch [99/1000], Loss: 0.007792292628437281\n",
      "Epoch [100/1000], Loss: 0.007792291231453419\n",
      "Epoch [101/1000], Loss: 0.007792290300130844\n",
      "Epoch [102/1000], Loss: 0.007792288903146982\n",
      "Epoch [103/1000], Loss: 0.007792288437485695\n",
      "Epoch [104/1000], Loss: 0.007792286574840546\n",
      "Epoch [105/1000], Loss: 0.007792286109179258\n",
      "Epoch [106/1000], Loss: 0.007792285177856684\n",
      "Epoch [107/1000], Loss: 0.007792284712195396\n",
      "Epoch [108/1000], Loss: 0.007792284712195396\n",
      "Epoch [109/1000], Loss: 0.007792283780872822\n",
      "Epoch [110/1000], Loss: 0.007792282849550247\n",
      "Epoch [111/1000], Loss: 0.007792282849550247\n",
      "Epoch [112/1000], Loss: 0.007792281452566385\n",
      "Epoch [113/1000], Loss: 0.007792281452566385\n",
      "Epoch [114/1000], Loss: 0.007792281452566385\n",
      "Epoch [115/1000], Loss: 0.007792280055582523\n",
      "Epoch [116/1000], Loss: 0.007792279589921236\n",
      "Epoch [117/1000], Loss: 0.007792279589921236\n",
      "Epoch [118/1000], Loss: 0.007792279589921236\n",
      "Epoch [119/1000], Loss: 0.007792278658598661\n",
      "Epoch [120/1000], Loss: 0.007792278658598661\n",
      "Epoch [121/1000], Loss: 0.007792278658598661\n",
      "Epoch [122/1000], Loss: 0.0077922772616147995\n",
      "Epoch [123/1000], Loss: 0.007792277727276087\n",
      "Epoch [124/1000], Loss: 0.0077922772616147995\n",
      "Epoch [125/1000], Loss: 0.0077922772616147995\n",
      "Epoch [126/1000], Loss: 0.007792276330292225\n",
      "Epoch [127/1000], Loss: 0.007792276330292225\n",
      "Epoch [128/1000], Loss: 0.007792275864630938\n",
      "Epoch [129/1000], Loss: 0.007792275864630938\n",
      "Epoch [130/1000], Loss: 0.007792275864630938\n",
      "Epoch [131/1000], Loss: 0.007792275864630938\n",
      "Epoch [132/1000], Loss: 0.007792275864630938\n",
      "Epoch [133/1000], Loss: 0.007792274467647076\n",
      "Epoch [134/1000], Loss: 0.007792274467647076\n",
      "Epoch [135/1000], Loss: 0.007792274467647076\n",
      "Epoch [136/1000], Loss: 0.007792274467647076\n",
      "Epoch [137/1000], Loss: 0.007792273536324501\n",
      "Epoch [138/1000], Loss: 0.007792272605001926\n",
      "Epoch [139/1000], Loss: 0.007792272605001926\n",
      "Epoch [140/1000], Loss: 0.007792272605001926\n",
      "Epoch [141/1000], Loss: 0.007792272605001926\n",
      "Epoch [142/1000], Loss: 0.007792272605001926\n",
      "Epoch [143/1000], Loss: 0.007792272605001926\n",
      "Epoch [144/1000], Loss: 0.0077922712080180645\n",
      "Epoch [145/1000], Loss: 0.0077922712080180645\n",
      "Epoch [146/1000], Loss: 0.0077922712080180645\n",
      "Epoch [147/1000], Loss: 0.007792270742356777\n",
      "Epoch [148/1000], Loss: 0.007792270742356777\n",
      "Epoch [149/1000], Loss: 0.007792269811034203\n",
      "Epoch [150/1000], Loss: 0.007792269811034203\n",
      "Epoch [151/1000], Loss: 0.007792269811034203\n",
      "Epoch [152/1000], Loss: 0.007792269811034203\n",
      "Epoch [153/1000], Loss: 0.007792269345372915\n",
      "Epoch [154/1000], Loss: 0.007792268414050341\n",
      "Epoch [155/1000], Loss: 0.007792268414050341\n",
      "Epoch [156/1000], Loss: 0.007792268414050341\n",
      "Epoch [157/1000], Loss: 0.007792268414050341\n",
      "Epoch [158/1000], Loss: 0.007792267482727766\n",
      "Epoch [159/1000], Loss: 0.007792267017066479\n",
      "Epoch [160/1000], Loss: 0.007792267017066479\n",
      "Epoch [161/1000], Loss: 0.007792266085743904\n",
      "Epoch [162/1000], Loss: 0.007792266085743904\n",
      "Epoch [163/1000], Loss: 0.007792265620082617\n",
      "Epoch [164/1000], Loss: 0.007792264688760042\n",
      "Epoch [165/1000], Loss: 0.007792264688760042\n",
      "Epoch [166/1000], Loss: 0.007792264688760042\n",
      "Epoch [167/1000], Loss: 0.007792263757437468\n",
      "Epoch [168/1000], Loss: 0.007792263757437468\n",
      "Epoch [169/1000], Loss: 0.00779226329177618\n",
      "Epoch [170/1000], Loss: 0.00779226329177618\n",
      "Epoch [171/1000], Loss: 0.007792262360453606\n",
      "Epoch [172/1000], Loss: 0.007792262360453606\n",
      "Epoch [173/1000], Loss: 0.007792262360453606\n",
      "Epoch [174/1000], Loss: 0.007792260963469744\n",
      "Epoch [175/1000], Loss: 0.007792260963469744\n",
      "Epoch [176/1000], Loss: 0.007792260963469744\n",
      "Epoch [177/1000], Loss: 0.007792260963469744\n",
      "Epoch [178/1000], Loss: 0.007792259566485882\n",
      "Epoch [179/1000], Loss: 0.007792259566485882\n",
      "Epoch [180/1000], Loss: 0.007792258635163307\n",
      "Epoch [181/1000], Loss: 0.00779225816950202\n",
      "Epoch [182/1000], Loss: 0.00779225816950202\n",
      "Epoch [183/1000], Loss: 0.007792257238179445\n",
      "Epoch [184/1000], Loss: 0.007792257238179445\n",
      "Epoch [185/1000], Loss: 0.007792256772518158\n",
      "Epoch [186/1000], Loss: 0.007792255841195583\n",
      "Epoch [187/1000], Loss: 0.007792255841195583\n",
      "Epoch [188/1000], Loss: 0.007792255375534296\n",
      "Epoch [189/1000], Loss: 0.007792254444211721\n",
      "Epoch [190/1000], Loss: 0.007792254444211721\n",
      "Epoch [191/1000], Loss: 0.007792253512889147\n",
      "Epoch [192/1000], Loss: 0.0077922530472278595\n",
      "Epoch [193/1000], Loss: 0.007792252115905285\n",
      "Epoch [194/1000], Loss: 0.007792251650243998\n",
      "Epoch [195/1000], Loss: 0.007792251650243998\n",
      "Epoch [196/1000], Loss: 0.007792250718921423\n",
      "Epoch [197/1000], Loss: 0.007792250253260136\n",
      "Epoch [198/1000], Loss: 0.007792249321937561\n",
      "Epoch [199/1000], Loss: 0.007792249321937561\n",
      "Epoch [200/1000], Loss: 0.007792248390614986\n",
      "Epoch [201/1000], Loss: 0.007792247924953699\n",
      "Epoch [202/1000], Loss: 0.0077922469936311245\n",
      "Epoch [203/1000], Loss: 0.007792246527969837\n",
      "Epoch [204/1000], Loss: 0.007792245596647263\n",
      "Epoch [205/1000], Loss: 0.007792244665324688\n",
      "Epoch [206/1000], Loss: 0.007792244199663401\n",
      "Epoch [207/1000], Loss: 0.007792243268340826\n",
      "Epoch [208/1000], Loss: 0.007792242802679539\n",
      "Epoch [209/1000], Loss: 0.007792241871356964\n",
      "Epoch [210/1000], Loss: 0.007792241405695677\n",
      "Epoch [211/1000], Loss: 0.007792239543050528\n",
      "Epoch [212/1000], Loss: 0.007792239543050528\n",
      "Epoch [213/1000], Loss: 0.00779223907738924\n",
      "Epoch [214/1000], Loss: 0.007792238146066666\n",
      "Epoch [215/1000], Loss: 0.007792236749082804\n",
      "Epoch [216/1000], Loss: 0.007792236283421516\n",
      "Epoch [217/1000], Loss: 0.007792236283421516\n",
      "Epoch [218/1000], Loss: 0.007792234420776367\n",
      "Epoch [219/1000], Loss: 0.00779223395511508\n",
      "Epoch [220/1000], Loss: 0.007792232558131218\n",
      "Epoch [221/1000], Loss: 0.007792231626808643\n",
      "Epoch [222/1000], Loss: 0.007792230695486069\n",
      "Epoch [223/1000], Loss: 0.007792229298502207\n",
      "Epoch [224/1000], Loss: 0.0077922288328409195\n",
      "Epoch [225/1000], Loss: 0.007792227901518345\n",
      "Epoch [226/1000], Loss: 0.007792226504534483\n",
      "Epoch [227/1000], Loss: 0.007792225573211908\n",
      "Epoch [228/1000], Loss: 0.007792224176228046\n",
      "Epoch [229/1000], Loss: 0.0077922227792441845\n",
      "Epoch [230/1000], Loss: 0.007792222313582897\n",
      "Epoch [231/1000], Loss: 0.007792221382260323\n",
      "Epoch [232/1000], Loss: 0.007792219985276461\n",
      "Epoch [233/1000], Loss: 0.007792218588292599\n",
      "Epoch [234/1000], Loss: 0.007792217191308737\n",
      "Epoch [235/1000], Loss: 0.007792215328663588\n",
      "Epoch [236/1000], Loss: 0.007792213931679726\n",
      "Epoch [237/1000], Loss: 0.007792213466018438\n",
      "Epoch [238/1000], Loss: 0.007792211603373289\n",
      "Epoch [239/1000], Loss: 0.007792211137712002\n",
      "Epoch [240/1000], Loss: 0.00779220974072814\n",
      "Epoch [241/1000], Loss: 0.007792207412421703\n",
      "Epoch [242/1000], Loss: 0.007792206481099129\n",
      "Epoch [243/1000], Loss: 0.0077922046184539795\n",
      "Epoch [244/1000], Loss: 0.007792202290147543\n",
      "Epoch [245/1000], Loss: 0.007792200893163681\n",
      "Epoch [246/1000], Loss: 0.007792199496179819\n",
      "Epoch [247/1000], Loss: 0.007792198099195957\n",
      "Epoch [248/1000], Loss: 0.007792196236550808\n",
      "Epoch [249/1000], Loss: 0.007792194839566946\n",
      "Epoch [250/1000], Loss: 0.007792192045599222\n",
      "Epoch [251/1000], Loss: 0.00779219064861536\n",
      "Epoch [252/1000], Loss: 0.007792189251631498\n",
      "Epoch [253/1000], Loss: 0.007792185992002487\n",
      "Epoch [254/1000], Loss: 0.007792184595018625\n",
      "Epoch [255/1000], Loss: 0.007792182266712189\n",
      "Epoch [256/1000], Loss: 0.0077921804040670395\n",
      "Epoch [257/1000], Loss: 0.007792177144438028\n",
      "Epoch [258/1000], Loss: 0.007792175747454166\n",
      "Epoch [259/1000], Loss: 0.00779217341914773\n",
      "Epoch [260/1000], Loss: 0.007792170625180006\n",
      "Epoch [261/1000], Loss: 0.0077921682968735695\n",
      "Epoch [262/1000], Loss: 0.007792165502905846\n",
      "Epoch [263/1000], Loss: 0.007792163174599409\n",
      "Epoch [264/1000], Loss: 0.007792159914970398\n",
      "Epoch [265/1000], Loss: 0.007792157586663961\n",
      "Epoch [266/1000], Loss: 0.00779215432703495\n",
      "Epoch [267/1000], Loss: 0.007792152464389801\n",
      "Epoch [268/1000], Loss: 0.007792147807776928\n",
      "Epoch [269/1000], Loss: 0.007792145013809204\n",
      "Epoch [270/1000], Loss: 0.00779214221984148\n",
      "Epoch [271/1000], Loss: 0.007792138960212469\n",
      "Epoch [272/1000], Loss: 0.007792135234922171\n",
      "Epoch [273/1000], Loss: 0.0077921319752931595\n",
      "Epoch [274/1000], Loss: 0.007792128715664148\n",
      "Epoch [275/1000], Loss: 0.0077921245247125626\n",
      "Epoch [276/1000], Loss: 0.0077921198680996895\n",
      "Epoch [277/1000], Loss: 0.007792116142809391\n",
      "Epoch [278/1000], Loss: 0.00779211288318038\n",
      "Epoch [279/1000], Loss: 0.007792108226567507\n",
      "Epoch [280/1000], Loss: 0.007792104035615921\n",
      "Epoch [281/1000], Loss: 0.007792098913341761\n",
      "Epoch [282/1000], Loss: 0.0077920942567288876\n",
      "Epoch [283/1000], Loss: 0.007792090065777302\n",
      "Epoch [284/1000], Loss: 0.007792084012180567\n",
      "Epoch [285/1000], Loss: 0.007792078889906406\n",
      "Epoch [286/1000], Loss: 0.007792072836309671\n",
      "Epoch [287/1000], Loss: 0.007792067714035511\n",
      "Epoch [288/1000], Loss: 0.007792062126100063\n",
      "Epoch [289/1000], Loss: 0.007792055606842041\n",
      "Epoch [290/1000], Loss: 0.007792049553245306\n",
      "Epoch [291/1000], Loss: 0.007792042102664709\n",
      "Epoch [292/1000], Loss: 0.007792035583406687\n",
      "Epoch [293/1000], Loss: 0.0077920290641486645\n",
      "Epoch [294/1000], Loss: 0.007792020682245493\n",
      "Epoch [295/1000], Loss: 0.007792013697326183\n",
      "Epoch [296/1000], Loss: 0.007792005315423012\n",
      "Epoch [297/1000], Loss: 0.007791996467858553\n",
      "Epoch [298/1000], Loss: 0.007791987620294094\n",
      "Epoch [299/1000], Loss: 0.0077919792383909225\n",
      "Epoch [300/1000], Loss: 0.0077919685281813145\n",
      "Epoch [301/1000], Loss: 0.007791960146278143\n",
      "Epoch [302/1000], Loss: 0.0077919489704072475\n",
      "Epoch [303/1000], Loss: 0.007791939191520214\n",
      "Epoch [304/1000], Loss: 0.007791927549988031\n",
      "Epoch [305/1000], Loss: 0.007791915908455849\n",
      "Epoch [306/1000], Loss: 0.007791903335601091\n",
      "Epoch [307/1000], Loss: 0.007791890762746334\n",
      "Epoch [308/1000], Loss: 0.007791876792907715\n",
      "Epoch [309/1000], Loss: 0.007791862823069096\n",
      "Epoch [310/1000], Loss: 0.007791848387569189\n",
      "Epoch [311/1000], Loss: 0.007791833486407995\n",
      "Epoch [312/1000], Loss: 0.007791817653924227\n",
      "Epoch [313/1000], Loss: 0.007791800424456596\n",
      "Epoch [314/1000], Loss: 0.007791782729327679\n",
      "Epoch [315/1000], Loss: 0.007791764568537474\n",
      "Epoch [316/1000], Loss: 0.0077917445451021194\n",
      "Epoch [317/1000], Loss: 0.007791724056005478\n",
      "Epoch [318/1000], Loss: 0.007791703101247549\n",
      "Epoch [319/1000], Loss: 0.007791680283844471\n",
      "Epoch [320/1000], Loss: 0.007791656069457531\n",
      "Epoch [321/1000], Loss: 0.007791630923748016\n",
      "Epoch [322/1000], Loss: 0.007791602984070778\n",
      "Epoch [323/1000], Loss: 0.007791575044393539\n",
      "Epoch [324/1000], Loss: 0.007791544310748577\n",
      "Epoch [325/1000], Loss: 0.007791511714458466\n",
      "Epoch [326/1000], Loss: 0.007791478186845779\n",
      "Epoch [327/1000], Loss: 0.007791442330926657\n",
      "Epoch [328/1000], Loss: 0.0077914041467010975\n",
      "Epoch [329/1000], Loss: 0.007791362702846527\n",
      "Epoch [330/1000], Loss: 0.00779131893068552\n",
      "Epoch [331/1000], Loss: 0.007791271898895502\n",
      "Epoch [332/1000], Loss: 0.0077912225387990475\n",
      "Epoch [333/1000], Loss: 0.007791169453412294\n",
      "Epoch [334/1000], Loss: 0.0077911121770739555\n",
      "Epoch [335/1000], Loss: 0.007791050709784031\n",
      "Epoch [336/1000], Loss: 0.007790984585881233\n",
      "Epoch [337/1000], Loss: 0.00779091427102685\n",
      "Epoch [338/1000], Loss: 0.007790839299559593\n",
      "Epoch [339/1000], Loss: 0.00779075687751174\n",
      "Epoch [340/1000], Loss: 0.007790668867528439\n",
      "Epoch [341/1000], Loss: 0.007790574803948402\n",
      "Epoch [342/1000], Loss: 0.007790471892803907\n",
      "Epoch [343/1000], Loss: 0.007790361996740103\n",
      "Epoch [344/1000], Loss: 0.00779024139046669\n",
      "Epoch [345/1000], Loss: 0.007790110539644957\n",
      "Epoch [346/1000], Loss: 0.007789968978613615\n",
      "Epoch [347/1000], Loss: 0.0077898139134049416\n",
      "Epoch [348/1000], Loss: 0.0077896444126963615\n",
      "Epoch [349/1000], Loss: 0.007789459079504013\n",
      "Epoch [350/1000], Loss: 0.007789254188537598\n",
      "Epoch [351/1000], Loss: 0.007789029739797115\n",
      "Epoch [352/1000], Loss: 0.007788779679685831\n",
      "Epoch [353/1000], Loss: 0.007788503542542458\n",
      "Epoch [354/1000], Loss: 0.007788196671754122\n",
      "Epoch [355/1000], Loss: 0.007787853013724089\n",
      "Epoch [356/1000], Loss: 0.007787469774484634\n",
      "Epoch [357/1000], Loss: 0.007787039037793875\n",
      "Epoch [358/1000], Loss: 0.007786556147038937\n",
      "Epoch [359/1000], Loss: 0.007786009460687637\n",
      "Epoch [360/1000], Loss: 0.007785390596836805\n",
      "Epoch [361/1000], Loss: 0.007784686051309109\n",
      "Epoch [362/1000], Loss: 0.007783882785588503\n",
      "Epoch [363/1000], Loss: 0.0077829607762396336\n",
      "Epoch [364/1000], Loss: 0.007781899534165859\n",
      "Epoch [365/1000], Loss: 0.007780671119689941\n",
      "Epoch [366/1000], Loss: 0.007779241073876619\n",
      "Epoch [367/1000], Loss: 0.007777567952871323\n",
      "Epoch [368/1000], Loss: 0.007775601465255022\n",
      "Epoch [369/1000], Loss: 0.007773278281092644\n",
      "Epoch [370/1000], Loss: 0.007770515978336334\n",
      "Epoch [371/1000], Loss: 0.007767216768115759\n",
      "Epoch [372/1000], Loss: 0.00776325399056077\n",
      "Epoch [373/1000], Loss: 0.00775847677141428\n",
      "Epoch [374/1000], Loss: 0.0077527048997581005\n",
      "Epoch [375/1000], Loss: 0.007745732087641954\n",
      "Epoch [376/1000], Loss: 0.007737341802567244\n",
      "Epoch [377/1000], Loss: 0.007727356627583504\n",
      "Epoch [378/1000], Loss: 0.007715712767094374\n",
      "Epoch [379/1000], Loss: 0.007702645380049944\n",
      "Epoch [380/1000], Loss: 0.007688961923122406\n",
      "Epoch [381/1000], Loss: 0.007676431909203529\n",
      "Epoch [382/1000], Loss: 0.007667921483516693\n",
      "Epoch [383/1000], Loss: 0.007666048593819141\n",
      "Epoch [384/1000], Loss: 0.007668670732527971\n",
      "Epoch [385/1000], Loss: 0.007667242083698511\n",
      "Epoch [386/1000], Loss: 0.007657452020794153\n",
      "Epoch [387/1000], Loss: 0.007643587421625853\n",
      "Epoch [388/1000], Loss: 0.007631606888025999\n",
      "Epoch [389/1000], Loss: 0.007624038029462099\n",
      "Epoch [390/1000], Loss: 0.0076200938783586025\n",
      "Epoch [391/1000], Loss: 0.007617822382599115\n",
      "Epoch [392/1000], Loss: 0.0076157026924192905\n",
      "Epoch [393/1000], Loss: 0.0076130954548716545\n",
      "Epoch [394/1000], Loss: 0.0076101250015199184\n",
      "Epoch [395/1000], Loss: 0.007607365492731333\n",
      "Epoch [396/1000], Loss: 0.007605448830872774\n",
      "Epoch [397/1000], Loss: 0.007604511454701424\n",
      "Epoch [398/1000], Loss: 0.007603850681334734\n",
      "Epoch [399/1000], Loss: 0.0076023912988603115\n",
      "Epoch [400/1000], Loss: 0.007599817123264074\n",
      "Epoch [401/1000], Loss: 0.007596922107040882\n",
      "Epoch [402/1000], Loss: 0.007594734895974398\n",
      "Epoch [403/1000], Loss: 0.007593617774546146\n",
      "Epoch [404/1000], Loss: 0.007593201473355293\n",
      "Epoch [405/1000], Loss: 0.00759291322901845\n",
      "Epoch [406/1000], Loss: 0.007592441979795694\n",
      "Epoch [407/1000], Loss: 0.0075918398797512054\n",
      "Epoch [408/1000], Loss: 0.00759136164560914\n",
      "Epoch [409/1000], Loss: 0.007591166067868471\n",
      "Epoch [410/1000], Loss: 0.0075911288149654865\n",
      "Epoch [411/1000], Loss: 0.007590945344418287\n",
      "Epoch [412/1000], Loss: 0.007590457331389189\n",
      "Epoch [413/1000], Loss: 0.00758981192484498\n",
      "Epoch [414/1000], Loss: 0.007589268963783979\n",
      "Epoch [415/1000], Loss: 0.0075889513827860355\n",
      "Epoch [416/1000], Loss: 0.007588776294142008\n",
      "Epoch [417/1000], Loss: 0.007588599342852831\n",
      "Epoch [418/1000], Loss: 0.007588356267660856\n",
      "Epoch [419/1000], Loss: 0.007588091306388378\n",
      "Epoch [420/1000], Loss: 0.007587888278067112\n",
      "Epoch [421/1000], Loss: 0.0075877695344388485\n",
      "Epoch [422/1000], Loss: 0.007587679661810398\n",
      "Epoch [423/1000], Loss: 0.007587546017020941\n",
      "Epoch [424/1000], Loss: 0.007587353698909283\n",
      "Epoch [425/1000], Loss: 0.007587152533233166\n",
      "Epoch [426/1000], Loss: 0.007586994674056768\n",
      "Epoch [427/1000], Loss: 0.007586888037621975\n",
      "Epoch [428/1000], Loss: 0.007586800958961248\n",
      "Epoch [429/1000], Loss: 0.007586701773107052\n",
      "Epoch [430/1000], Loss: 0.007586590014398098\n",
      "Epoch [431/1000], Loss: 0.0075864847749471664\n",
      "Epoch [432/1000], Loss: 0.007586406543850899\n",
      "Epoch [433/1000], Loss: 0.007586350664496422\n",
      "Epoch [434/1000], Loss: 0.007586298976093531\n",
      "Epoch [435/1000], Loss: 0.007586236111819744\n",
      "Epoch [436/1000], Loss: 0.007586163468658924\n",
      "Epoch [437/1000], Loss: 0.00758609501644969\n",
      "Epoch [438/1000], Loss: 0.0075860414654016495\n",
      "Epoch [439/1000], Loss: 0.007586000952869654\n",
      "Epoch [440/1000], Loss: 0.0075859627686440945\n",
      "Epoch [441/1000], Loss: 0.007585921790450811\n",
      "Epoch [442/1000], Loss: 0.007585878949612379\n",
      "Epoch [443/1000], Loss: 0.007585839368402958\n",
      "Epoch [444/1000], Loss: 0.007585807703435421\n",
      "Epoch [445/1000], Loss: 0.0075857811607420444\n",
      "Epoch [446/1000], Loss: 0.0075857555493712425\n",
      "Epoch [447/1000], Loss: 0.007585726212710142\n",
      "Epoch [448/1000], Loss: 0.007585696876049042\n",
      "Epoch [449/1000], Loss: 0.007585668936371803\n",
      "Epoch [450/1000], Loss: 0.007585645653307438\n",
      "Epoch [451/1000], Loss: 0.007585625164210796\n",
      "Epoch [452/1000], Loss: 0.0075856042094528675\n",
      "Epoch [453/1000], Loss: 0.007585583720356226\n",
      "Epoch [454/1000], Loss: 0.007585563231259584\n",
      "Epoch [455/1000], Loss: 0.007585544139146805\n",
      "Epoch [456/1000], Loss: 0.007585526444017887\n",
      "Epoch [457/1000], Loss: 0.007585510145872831\n",
      "Epoch [458/1000], Loss: 0.00758549477905035\n",
      "Epoch [459/1000], Loss: 0.007585479412227869\n",
      "Epoch [460/1000], Loss: 0.007585463579744101\n",
      "Epoch [461/1000], Loss: 0.007585448678582907\n",
      "Epoch [462/1000], Loss: 0.007585435640066862\n",
      "Epoch [463/1000], Loss: 0.00758542213588953\n",
      "Epoch [464/1000], Loss: 0.007585409563034773\n",
      "Epoch [465/1000], Loss: 0.007585397455841303\n",
      "Epoch [466/1000], Loss: 0.0075853848829865456\n",
      "Epoch [467/1000], Loss: 0.007585373241454363\n",
      "Epoch [468/1000], Loss: 0.0075853620655834675\n",
      "Epoch [469/1000], Loss: 0.007585351821035147\n",
      "Epoch [470/1000], Loss: 0.007585340645164251\n",
      "Epoch [471/1000], Loss: 0.0075853304006159306\n",
      "Epoch [472/1000], Loss: 0.00758532015606761\n",
      "Epoch [473/1000], Loss: 0.007585308980196714\n",
      "Epoch [474/1000], Loss: 0.0075853001326322556\n",
      "Epoch [475/1000], Loss: 0.007585291750729084\n",
      "Epoch [476/1000], Loss: 0.0075852819718420506\n",
      "Epoch [477/1000], Loss: 0.007585272192955017\n",
      "Epoch [478/1000], Loss: 0.007585262879729271\n",
      "Epoch [479/1000], Loss: 0.007585254032164812\n",
      "Epoch [480/1000], Loss: 0.007585246115922928\n",
      "Epoch [481/1000], Loss: 0.007585237268358469\n",
      "Epoch [482/1000], Loss: 0.00758522842079401\n",
      "Epoch [483/1000], Loss: 0.007585219573229551\n",
      "Epoch [484/1000], Loss: 0.007585212122648954\n",
      "Epoch [485/1000], Loss: 0.00758520420640707\n",
      "Epoch [486/1000], Loss: 0.007585195358842611\n",
      "Epoch [487/1000], Loss: 0.007585187442600727\n",
      "Epoch [488/1000], Loss: 0.0075851790606975555\n",
      "Epoch [489/1000], Loss: 0.007585171144455671\n",
      "Epoch [490/1000], Loss: 0.0075851622968912125\n",
      "Epoch [491/1000], Loss: 0.0075851548463106155\n",
      "Epoch [492/1000], Loss: 0.007585147395730019\n",
      "Epoch [493/1000], Loss: 0.00758513854816556\n",
      "Epoch [494/1000], Loss: 0.0075851306319236755\n",
      "Epoch [495/1000], Loss: 0.007585123181343079\n",
      "Epoch [496/1000], Loss: 0.007585115265101194\n",
      "Epoch [497/1000], Loss: 0.0075851064175367355\n",
      "Epoch [498/1000], Loss: 0.007585098501294851\n",
      "Epoch [499/1000], Loss: 0.007585091050714254\n",
      "Epoch [500/1000], Loss: 0.00758508313447237\n",
      "Epoch [501/1000], Loss: 0.007585074286907911\n",
      "Epoch [502/1000], Loss: 0.007585066836327314\n",
      "Epoch [503/1000], Loss: 0.0075850579887628555\n",
      "Epoch [504/1000], Loss: 0.007585050072520971\n",
      "Epoch [505/1000], Loss: 0.0075850416906178\n",
      "Epoch [506/1000], Loss: 0.007585032843053341\n",
      "Epoch [507/1000], Loss: 0.007585024926811457\n",
      "Epoch [508/1000], Loss: 0.0075850170105695724\n",
      "Epoch [509/1000], Loss: 0.007585008163005114\n",
      "Epoch [510/1000], Loss: 0.007584999781101942\n",
      "Epoch [511/1000], Loss: 0.007584990467876196\n",
      "Epoch [512/1000], Loss: 0.007584981620311737\n",
      "Epoch [513/1000], Loss: 0.007584973704069853\n",
      "Epoch [514/1000], Loss: 0.007584963925182819\n",
      "Epoch [515/1000], Loss: 0.0075849550776183605\n",
      "Epoch [516/1000], Loss: 0.007584945764392614\n",
      "Epoch [517/1000], Loss: 0.007584935985505581\n",
      "Epoch [518/1000], Loss: 0.007584927137941122\n",
      "Epoch [519/1000], Loss: 0.007584917824715376\n",
      "Epoch [520/1000], Loss: 0.007584907580167055\n",
      "Epoch [521/1000], Loss: 0.007584897801280022\n",
      "Epoch [522/1000], Loss: 0.007584887556731701\n",
      "Epoch [523/1000], Loss: 0.00758487731218338\n",
      "Epoch [524/1000], Loss: 0.007584867067635059\n",
      "Epoch [525/1000], Loss: 0.007584856823086739\n",
      "Epoch [526/1000], Loss: 0.007584846578538418\n",
      "Epoch [527/1000], Loss: 0.007584835402667522\n",
      "Epoch [528/1000], Loss: 0.007584824226796627\n",
      "Epoch [529/1000], Loss: 0.007584812585264444\n",
      "Epoch [530/1000], Loss: 0.007584801875054836\n",
      "Epoch [531/1000], Loss: 0.007584789767861366\n",
      "Epoch [532/1000], Loss: 0.007584778126329184\n",
      "Epoch [533/1000], Loss: 0.007584765553474426\n",
      "Epoch [534/1000], Loss: 0.007584753911942244\n",
      "Epoch [535/1000], Loss: 0.007584741339087486\n",
      "Epoch [536/1000], Loss: 0.007584728766232729\n",
      "Epoch [537/1000], Loss: 0.00758471479639411\n",
      "Epoch [538/1000], Loss: 0.00758470268920064\n",
      "Epoch [539/1000], Loss: 0.007584687788039446\n",
      "Epoch [540/1000], Loss: 0.007584674749523401\n",
      "Epoch [541/1000], Loss: 0.007584659848362207\n",
      "Epoch [542/1000], Loss: 0.007584645878523588\n",
      "Epoch [543/1000], Loss: 0.007584631443023682\n",
      "Epoch [544/1000], Loss: 0.007584615610539913\n",
      "Epoch [545/1000], Loss: 0.007584600243717432\n",
      "Epoch [546/1000], Loss: 0.0075845844112336636\n",
      "Epoch [547/1000], Loss: 0.007584569044411182\n",
      "Epoch [548/1000], Loss: 0.007584551349282265\n",
      "Epoch [549/1000], Loss: 0.007584533654153347\n",
      "Epoch [550/1000], Loss: 0.007584515959024429\n",
      "Epoch [551/1000], Loss: 0.007584498263895512\n",
      "Epoch [552/1000], Loss: 0.007584480103105307\n",
      "Epoch [553/1000], Loss: 0.007584461010992527\n",
      "Epoch [554/1000], Loss: 0.007584440987557173\n",
      "Epoch [555/1000], Loss: 0.007584421429783106\n",
      "Epoch [556/1000], Loss: 0.00758440000936389\n",
      "Epoch [557/1000], Loss: 0.007584379520267248\n",
      "Epoch [558/1000], Loss: 0.007584357168525457\n",
      "Epoch [559/1000], Loss: 0.007584335282444954\n",
      "Epoch [560/1000], Loss: 0.0075843119993805885\n",
      "Epoch [561/1000], Loss: 0.007584288250654936\n",
      "Epoch [562/1000], Loss: 0.007584263104945421\n",
      "Epoch [563/1000], Loss: 0.007584237493574619\n",
      "Epoch [564/1000], Loss: 0.007584210950881243\n",
      "Epoch [565/1000], Loss: 0.0075841848738491535\n",
      "Epoch [566/1000], Loss: 0.007584156934171915\n",
      "Epoch [567/1000], Loss: 0.007584127597510815\n",
      "Epoch [568/1000], Loss: 0.00758409732952714\n",
      "Epoch [569/1000], Loss: 0.007584066595882177\n",
      "Epoch [570/1000], Loss: 0.00758403493091464\n",
      "Epoch [571/1000], Loss: 0.007584001868963242\n",
      "Epoch [572/1000], Loss: 0.007583967410027981\n",
      "Epoch [573/1000], Loss: 0.007583932019770145\n",
      "Epoch [574/1000], Loss: 0.007583895232528448\n",
      "Epoch [575/1000], Loss: 0.007583857048302889\n",
      "Epoch [576/1000], Loss: 0.007583817467093468\n",
      "Epoch [577/1000], Loss: 0.007583776954561472\n",
      "Epoch [578/1000], Loss: 0.007583734579384327\n",
      "Epoch [579/1000], Loss: 0.007583689875900745\n",
      "Epoch [580/1000], Loss: 0.007583643309772015\n",
      "Epoch [581/1000], Loss: 0.0075835962779819965\n",
      "Epoch [582/1000], Loss: 0.007583545986562967\n",
      "Epoch [583/1000], Loss: 0.007583493832498789\n",
      "Epoch [584/1000], Loss: 0.007583439815789461\n",
      "Epoch [585/1000], Loss: 0.007583383470773697\n",
      "Epoch [586/1000], Loss: 0.007583324797451496\n",
      "Epoch [587/1000], Loss: 0.007583262864500284\n",
      "Epoch [588/1000], Loss: 0.007583199068903923\n",
      "Epoch [589/1000], Loss: 0.007583132479339838\n",
      "Epoch [590/1000], Loss: 0.007583061698824167\n",
      "Epoch [591/1000], Loss: 0.007582989055663347\n",
      "Epoch [592/1000], Loss: 0.007582911755889654\n",
      "Epoch [593/1000], Loss: 0.00758283119648695\n",
      "Epoch [594/1000], Loss: 0.0075827473774552345\n",
      "Epoch [595/1000], Loss: 0.0075826579704880714\n",
      "Epoch [596/1000], Loss: 0.007582565303891897\n",
      "Epoch [597/1000], Loss: 0.007582467049360275\n",
      "Epoch [598/1000], Loss: 0.00758236413821578\n",
      "Epoch [599/1000], Loss: 0.007582256104797125\n",
      "Epoch [600/1000], Loss: 0.007582142483443022\n",
      "Epoch [601/1000], Loss: 0.007582021877169609\n",
      "Epoch [602/1000], Loss: 0.0075818938203155994\n",
      "Epoch [603/1000], Loss: 0.007581761106848717\n",
      "Epoch [604/1000], Loss: 0.007581619545817375\n",
      "Epoch [605/1000], Loss: 0.007581470068544149\n",
      "Epoch [606/1000], Loss: 0.007581311743706465\n",
      "Epoch [607/1000], Loss: 0.007581143639981747\n",
      "Epoch [608/1000], Loss: 0.007580965757369995\n",
      "Epoch [609/1000], Loss: 0.007580777630209923\n",
      "Epoch [610/1000], Loss: 0.0075805773958563805\n",
      "Epoch [611/1000], Loss: 0.0075803641229867935\n",
      "Epoch [612/1000], Loss: 0.007580137345939875\n",
      "Epoch [613/1000], Loss: 0.0075798965990543365\n",
      "Epoch [614/1000], Loss: 0.007579639554023743\n",
      "Epoch [615/1000], Loss: 0.0075793638825416565\n",
      "Epoch [616/1000], Loss: 0.007579071447253227\n",
      "Epoch [617/1000], Loss: 0.007578759454190731\n",
      "Epoch [618/1000], Loss: 0.007578424643725157\n",
      "Epoch [619/1000], Loss: 0.007578067481517792\n",
      "Epoch [620/1000], Loss: 0.007577685639262199\n",
      "Epoch [621/1000], Loss: 0.0075772772543132305\n",
      "Epoch [622/1000], Loss: 0.007576839532703161\n",
      "Epoch [623/1000], Loss: 0.00757637107744813\n",
      "Epoch [624/1000], Loss: 0.007575870491564274\n",
      "Epoch [625/1000], Loss: 0.007575334049761295\n",
      "Epoch [626/1000], Loss: 0.007574759889394045\n",
      "Epoch [627/1000], Loss: 0.007574147079139948\n",
      "Epoch [628/1000], Loss: 0.007573492359369993\n",
      "Epoch [629/1000], Loss: 0.007572794333100319\n",
      "Epoch [630/1000], Loss: 0.007572053465992212\n",
      "Epoch [631/1000], Loss: 0.0075712683610618114\n",
      "Epoch [632/1000], Loss: 0.007570437155663967\n",
      "Epoch [633/1000], Loss: 0.0075695631094276905\n",
      "Epoch [634/1000], Loss: 0.007568647153675556\n",
      "Epoch [635/1000], Loss: 0.007567693013697863\n",
      "Epoch [636/1000], Loss: 0.0075667076744139194\n",
      "Epoch [637/1000], Loss: 0.007565695326775312\n",
      "Epoch [638/1000], Loss: 0.007564665749669075\n",
      "Epoch [639/1000], Loss: 0.007563630118966103\n",
      "Epoch [640/1000], Loss: 0.007562596816569567\n",
      "Epoch [641/1000], Loss: 0.007561578880995512\n",
      "Epoch [642/1000], Loss: 0.007560583297163248\n",
      "Epoch [643/1000], Loss: 0.007559614256024361\n",
      "Epoch [644/1000], Loss: 0.007558673620223999\n",
      "Epoch [645/1000], Loss: 0.007557753473520279\n",
      "Epoch [646/1000], Loss: 0.007556842640042305\n",
      "Epoch [647/1000], Loss: 0.007555927615612745\n",
      "Epoch [648/1000], Loss: 0.007554993499070406\n",
      "Epoch [649/1000], Loss: 0.007554028183221817\n",
      "Epoch [650/1000], Loss: 0.007553031202405691\n",
      "Epoch [651/1000], Loss: 0.0075520058162510395\n",
      "Epoch [652/1000], Loss: 0.007550971582531929\n",
      "Epoch [653/1000], Loss: 0.007549948059022427\n",
      "Epoch [654/1000], Loss: 0.007548954803496599\n",
      "Epoch [655/1000], Loss: 0.007548010442405939\n",
      "Epoch [656/1000], Loss: 0.007547126151621342\n",
      "Epoch [657/1000], Loss: 0.007546303793787956\n",
      "Epoch [658/1000], Loss: 0.007545539177954197\n",
      "Epoch [659/1000], Loss: 0.0075448257848620415\n",
      "Epoch [660/1000], Loss: 0.007544156163930893\n",
      "Epoch [661/1000], Loss: 0.007543520070612431\n",
      "Epoch [662/1000], Loss: 0.007542910519987345\n",
      "Epoch [663/1000], Loss: 0.0075423200614750385\n",
      "Epoch [664/1000], Loss: 0.007541745901107788\n",
      "Epoch [665/1000], Loss: 0.007541181519627571\n",
      "Epoch [666/1000], Loss: 0.007540620397776365\n",
      "Epoch [667/1000], Loss: 0.0075400578789412975\n",
      "Epoch [668/1000], Loss: 0.007539489772170782\n",
      "Epoch [669/1000], Loss: 0.007538909558206797\n",
      "Epoch [670/1000], Loss: 0.007538315840065479\n",
      "Epoch [671/1000], Loss: 0.0075377062894403934\n",
      "Epoch [672/1000], Loss: 0.0075370799750089645\n",
      "Epoch [673/1000], Loss: 0.00753643736243248\n",
      "Epoch [674/1000], Loss: 0.007535774726420641\n",
      "Epoch [675/1000], Loss: 0.007535092532634735\n",
      "Epoch [676/1000], Loss: 0.007534388452768326\n",
      "Epoch [677/1000], Loss: 0.007533659692853689\n",
      "Epoch [678/1000], Loss: 0.007532911840826273\n",
      "Epoch [679/1000], Loss: 0.007532147690653801\n",
      "Epoch [680/1000], Loss: 0.007531389594078064\n",
      "Epoch [681/1000], Loss: 0.007530664559453726\n",
      "Epoch [682/1000], Loss: 0.0075300405733287334\n",
      "Epoch [683/1000], Loss: 0.007529347203671932\n",
      "Epoch [684/1000], Loss: 0.007528270594775677\n",
      "Epoch [685/1000], Loss: 0.007526798639446497\n",
      "Epoch [686/1000], Loss: 0.007525511085987091\n",
      "Epoch [687/1000], Loss: 0.007524579297751188\n",
      "Epoch [688/1000], Loss: 0.007523584179580212\n",
      "Epoch [689/1000], Loss: 0.007522239815443754\n",
      "Epoch [690/1000], Loss: 0.00752061465755105\n",
      "Epoch [691/1000], Loss: 0.007519126869738102\n",
      "Epoch [692/1000], Loss: 0.007517770864069462\n",
      "Epoch [693/1000], Loss: 0.007516523823142052\n",
      "Epoch [694/1000], Loss: 0.007515590637922287\n",
      "Epoch [695/1000], Loss: 0.007515191566199064\n",
      "Epoch [696/1000], Loss: 0.007515528704971075\n",
      "Epoch [697/1000], Loss: 0.0075151086784899235\n",
      "Epoch [698/1000], Loss: 0.007512484677135944\n",
      "Epoch [699/1000], Loss: 0.0075100744143128395\n",
      "Epoch [700/1000], Loss: 0.007510373834520578\n",
      "Epoch [701/1000], Loss: 0.007510753348469734\n",
      "Epoch [702/1000], Loss: 0.007508663926273584\n",
      "Epoch [703/1000], Loss: 0.00750710628926754\n",
      "Epoch [704/1000], Loss: 0.0075077153742313385\n",
      "Epoch [705/1000], Loss: 0.007507320959120989\n",
      "Epoch [706/1000], Loss: 0.00750556169077754\n",
      "Epoch [707/1000], Loss: 0.0075049735605716705\n",
      "Epoch [708/1000], Loss: 0.007505165413022041\n",
      "Epoch [709/1000], Loss: 0.0075045255944132805\n",
      "Epoch [710/1000], Loss: 0.007503263186663389\n",
      "Epoch [711/1000], Loss: 0.007502678316086531\n",
      "Epoch [712/1000], Loss: 0.007502739317715168\n",
      "Epoch [713/1000], Loss: 0.007502052932977676\n",
      "Epoch [714/1000], Loss: 0.007500864565372467\n",
      "Epoch [715/1000], Loss: 0.007500413339585066\n",
      "Epoch [716/1000], Loss: 0.00750020332634449\n",
      "Epoch [717/1000], Loss: 0.00749944569543004\n",
      "Epoch [718/1000], Loss: 0.007498473394662142\n",
      "Epoch [719/1000], Loss: 0.007497836370021105\n",
      "Epoch [720/1000], Loss: 0.00749746710062027\n",
      "Epoch [721/1000], Loss: 0.007496791426092386\n",
      "Epoch [722/1000], Loss: 0.007495800033211708\n",
      "Epoch [723/1000], Loss: 0.007495038211345673\n",
      "Epoch [724/1000], Loss: 0.007494483608752489\n",
      "Epoch [725/1000], Loss: 0.007493850775063038\n",
      "Epoch [726/1000], Loss: 0.007493054494261742\n",
      "Epoch [727/1000], Loss: 0.007492132019251585\n",
      "Epoch [728/1000], Loss: 0.0074913050048053265\n",
      "Epoch [729/1000], Loss: 0.007490645628422499\n",
      "Epoch [730/1000], Loss: 0.007489990442991257\n",
      "Epoch [731/1000], Loss: 0.007489279378205538\n",
      "Epoch [732/1000], Loss: 0.007488483563065529\n",
      "Epoch [733/1000], Loss: 0.007487630937248468\n",
      "Epoch [734/1000], Loss: 0.00748682813718915\n",
      "Epoch [735/1000], Loss: 0.007486083544790745\n",
      "Epoch [736/1000], Loss: 0.007485390640795231\n",
      "Epoch [737/1000], Loss: 0.007484761998057365\n",
      "Epoch [738/1000], Loss: 0.007484163623303175\n",
      "Epoch [739/1000], Loss: 0.007483604829758406\n",
      "Epoch [740/1000], Loss: 0.007483107969164848\n",
      "Epoch [741/1000], Loss: 0.007482660934329033\n",
      "Epoch [742/1000], Loss: 0.007482283283025026\n",
      "Epoch [743/1000], Loss: 0.007481913082301617\n",
      "Epoch [744/1000], Loss: 0.007481430657207966\n",
      "Epoch [745/1000], Loss: 0.007480732165277004\n",
      "Epoch [746/1000], Loss: 0.007479853928089142\n",
      "Epoch [747/1000], Loss: 0.007479012478142977\n",
      "Epoch [748/1000], Loss: 0.007478430401533842\n",
      "Epoch [749/1000], Loss: 0.007478111889213324\n",
      "Epoch [750/1000], Loss: 0.0074779316782951355\n",
      "Epoch [751/1000], Loss: 0.007477731443941593\n",
      "Epoch [752/1000], Loss: 0.007477384991943836\n",
      "Epoch [753/1000], Loss: 0.007476876024156809\n",
      "Epoch [754/1000], Loss: 0.007476278580725193\n",
      "Epoch [755/1000], Loss: 0.007475742604583502\n",
      "Epoch [756/1000], Loss: 0.007475361227989197\n",
      "Epoch [757/1000], Loss: 0.007475121878087521\n",
      "Epoch [758/1000], Loss: 0.007474950980395079\n",
      "Epoch [759/1000], Loss: 0.007474761456251144\n",
      "Epoch [760/1000], Loss: 0.0074744983576238155\n",
      "Epoch [761/1000], Loss: 0.0074741533026099205\n",
      "Epoch [762/1000], Loss: 0.007473764009773731\n",
      "Epoch [763/1000], Loss: 0.007473388221114874\n",
      "Epoch [764/1000], Loss: 0.007473069243133068\n",
      "Epoch [765/1000], Loss: 0.007472818251699209\n",
      "Epoch [766/1000], Loss: 0.007472616620361805\n",
      "Epoch [767/1000], Loss: 0.007472440600395203\n",
      "Epoch [768/1000], Loss: 0.007472268771380186\n",
      "Epoch [769/1000], Loss: 0.007472085300832987\n",
      "Epoch [770/1000], Loss: 0.007471883669495583\n",
      "Epoch [771/1000], Loss: 0.007471657823771238\n",
      "Epoch [772/1000], Loss: 0.007471405901014805\n",
      "Epoch [773/1000], Loss: 0.007471130229532719\n",
      "Epoch [774/1000], Loss: 0.0074708424508571625\n",
      "Epoch [775/1000], Loss: 0.007470549549907446\n",
      "Epoch [776/1000], Loss: 0.007470263633877039\n",
      "Epoch [777/1000], Loss: 0.007469991222023964\n",
      "Epoch [778/1000], Loss: 0.007469729986041784\n",
      "Epoch [779/1000], Loss: 0.007469477131962776\n",
      "Epoch [780/1000], Loss: 0.007469230331480503\n",
      "Epoch [781/1000], Loss: 0.007468984927982092\n",
      "Epoch [782/1000], Loss: 0.007468740455806255\n",
      "Epoch [783/1000], Loss: 0.007468499708920717\n",
      "Epoch [784/1000], Loss: 0.0074682692065835\n",
      "Epoch [785/1000], Loss: 0.007468061987310648\n",
      "Epoch [786/1000], Loss: 0.007467902731150389\n",
      "Epoch [787/1000], Loss: 0.0074678282253444195\n",
      "Epoch [788/1000], Loss: 0.0074678752571344376\n",
      "Epoch [789/1000], Loss: 0.007468019146472216\n",
      "Epoch [790/1000], Loss: 0.007468079682439566\n",
      "Epoch [791/1000], Loss: 0.007467648945748806\n",
      "Epoch [792/1000], Loss: 0.00746656721457839\n",
      "Epoch [793/1000], Loss: 0.007465307135134935\n",
      "Epoch [794/1000], Loss: 0.007464627735316753\n",
      "Epoch [795/1000], Loss: 0.00746458163484931\n",
      "Epoch [796/1000], Loss: 0.007464519701898098\n",
      "Epoch [797/1000], Loss: 0.00746387941762805\n",
      "Epoch [798/1000], Loss: 0.007462773472070694\n",
      "Epoch [799/1000], Loss: 0.007461817003786564\n",
      "Epoch [800/1000], Loss: 0.00746128847822547\n",
      "Epoch [801/1000], Loss: 0.007460834924131632\n",
      "Epoch [802/1000], Loss: 0.007460002321749926\n",
      "Epoch [803/1000], Loss: 0.007458775769919157\n",
      "Epoch [804/1000], Loss: 0.007457528728991747\n",
      "Epoch [805/1000], Loss: 0.007456472609192133\n",
      "Epoch [806/1000], Loss: 0.007455413695424795\n",
      "Epoch [807/1000], Loss: 0.007454048842191696\n",
      "Epoch [808/1000], Loss: 0.007452330552041531\n",
      "Epoch [809/1000], Loss: 0.007450446020811796\n",
      "Epoch [810/1000], Loss: 0.0074485354125499725\n",
      "Epoch [811/1000], Loss: 0.007446518167853355\n",
      "Epoch [812/1000], Loss: 0.007444217801094055\n",
      "Epoch [813/1000], Loss: 0.0074415565468370914\n",
      "Epoch [814/1000], Loss: 0.0074385893531143665\n",
      "Epoch [815/1000], Loss: 0.0074354251846671104\n",
      "Epoch [816/1000], Loss: 0.007432135753333569\n",
      "Epoch [817/1000], Loss: 0.007428746670484543\n",
      "Epoch [818/1000], Loss: 0.007425295189023018\n",
      "Epoch [819/1000], Loss: 0.007421867921948433\n",
      "Epoch [820/1000], Loss: 0.007418600842356682\n",
      "Epoch [821/1000], Loss: 0.00741563830524683\n",
      "Epoch [822/1000], Loss: 0.007413089275360107\n",
      "Epoch [823/1000], Loss: 0.007410968653857708\n",
      "Epoch [824/1000], Loss: 0.0074091884307563305\n",
      "Epoch [825/1000], Loss: 0.0074075972661376\n",
      "Epoch [826/1000], Loss: 0.00740607175976038\n",
      "Epoch [827/1000], Loss: 0.007404610048979521\n",
      "Epoch [828/1000], Loss: 0.007403402589261532\n",
      "Epoch [829/1000], Loss: 0.007402749266475439\n",
      "Epoch [830/1000], Loss: 0.007402466144412756\n",
      "Epoch [831/1000], Loss: 0.007401096634566784\n",
      "Epoch [832/1000], Loss: 0.007398250512778759\n",
      "Epoch [833/1000], Loss: 0.007396751549094915\n",
      "Epoch [834/1000], Loss: 0.007397364359349012\n",
      "Epoch [835/1000], Loss: 0.007397115230560303\n",
      "Epoch [836/1000], Loss: 0.007395340129733086\n",
      "Epoch [837/1000], Loss: 0.00739468215033412\n",
      "Epoch [838/1000], Loss: 0.007395453285425901\n",
      "Epoch [839/1000], Loss: 0.007395469583570957\n",
      "Epoch [840/1000], Loss: 0.007394313346594572\n",
      "Epoch [841/1000], Loss: 0.007393633481115103\n",
      "Epoch [842/1000], Loss: 0.007393946405500174\n",
      "Epoch [843/1000], Loss: 0.007393894717097282\n",
      "Epoch [844/1000], Loss: 0.007392852101475\n",
      "Epoch [845/1000], Loss: 0.007392013445496559\n",
      "Epoch [846/1000], Loss: 0.007392024155706167\n",
      "Epoch [847/1000], Loss: 0.007391895167529583\n",
      "Epoch [848/1000], Loss: 0.007391178049147129\n",
      "Epoch [849/1000], Loss: 0.007390760350972414\n",
      "Epoch [850/1000], Loss: 0.007390899118036032\n",
      "Epoch [851/1000], Loss: 0.007390813902020454\n",
      "Epoch [852/1000], Loss: 0.007390401791781187\n",
      "Epoch [853/1000], Loss: 0.007390290033072233\n",
      "Epoch [854/1000], Loss: 0.007390433456748724\n",
      "Epoch [855/1000], Loss: 0.007390310987830162\n",
      "Epoch [856/1000], Loss: 0.007389989215880632\n",
      "Epoch [857/1000], Loss: 0.007389873266220093\n",
      "Epoch [858/1000], Loss: 0.007389906793832779\n",
      "Epoch [859/1000], Loss: 0.007389779202640057\n",
      "Epoch [860/1000], Loss: 0.00738952774554491\n",
      "Epoch [861/1000], Loss: 0.007389412727206945\n",
      "Epoch [862/1000], Loss: 0.007389422971755266\n",
      "Epoch [863/1000], Loss: 0.007389350328594446\n",
      "Epoch [864/1000], Loss: 0.0073891798965632915\n",
      "Epoch [865/1000], Loss: 0.0073890783824026585\n",
      "Epoch [866/1000], Loss: 0.007389075588434935\n",
      "Epoch [867/1000], Loss: 0.0073890360072255135\n",
      "Epoch [868/1000], Loss: 0.007388918194919825\n",
      "Epoch [869/1000], Loss: 0.007388819940388203\n",
      "Epoch [870/1000], Loss: 0.00738878920674324\n",
      "Epoch [871/1000], Loss: 0.007388753816485405\n",
      "Epoch [872/1000], Loss: 0.007388664409518242\n",
      "Epoch [873/1000], Loss: 0.0073885731399059296\n",
      "Epoch [874/1000], Loss: 0.0073885321617126465\n",
      "Epoch [875/1000], Loss: 0.007388507016003132\n",
      "Epoch [876/1000], Loss: 0.0073884534649550915\n",
      "Epoch [877/1000], Loss: 0.007388385012745857\n",
      "Epoch [878/1000], Loss: 0.0073883431032299995\n",
      "Epoch [879/1000], Loss: 0.007388322148472071\n",
      "Epoch [880/1000], Loss: 0.007388291880488396\n",
      "Epoch [881/1000], Loss: 0.007388248573988676\n",
      "Epoch [882/1000], Loss: 0.007388221565634012\n",
      "Epoch [883/1000], Loss: 0.00738822715356946\n",
      "Epoch [884/1000], Loss: 0.007388257421553135\n",
      "Epoch [885/1000], Loss: 0.007388313766568899\n",
      "Epoch [886/1000], Loss: 0.007388425525277853\n",
      "Epoch [887/1000], Loss: 0.007388627622276545\n",
      "Epoch [888/1000], Loss: 0.007388914003968239\n",
      "Epoch [889/1000], Loss: 0.00738920783624053\n",
      "Epoch [890/1000], Loss: 0.007389343809336424\n",
      "Epoch [891/1000], Loss: 0.007389136590063572\n",
      "Epoch [892/1000], Loss: 0.00738858338445425\n",
      "Epoch [893/1000], Loss: 0.007387994322925806\n",
      "Epoch [894/1000], Loss: 0.007387756370007992\n",
      "Epoch [895/1000], Loss: 0.007387937977910042\n",
      "Epoch [896/1000], Loss: 0.007388239726424217\n",
      "Epoch [897/1000], Loss: 0.0073882960714399815\n",
      "Epoch [898/1000], Loss: 0.007388025056570768\n",
      "Epoch [899/1000], Loss: 0.007387689780443907\n",
      "Epoch [900/1000], Loss: 0.007387589663267136\n",
      "Epoch [901/1000], Loss: 0.007387729827314615\n",
      "Epoch [902/1000], Loss: 0.007387865334749222\n",
      "Epoch [903/1000], Loss: 0.00738780340179801\n",
      "Epoch [904/1000], Loss: 0.007387602236121893\n",
      "Epoch [905/1000], Loss: 0.007387465797364712\n",
      "Epoch [906/1000], Loss: 0.007387489080429077\n",
      "Epoch [907/1000], Loss: 0.0073875742964446545\n",
      "Epoch [908/1000], Loss: 0.007387573830783367\n",
      "Epoch [909/1000], Loss: 0.007387467194348574\n",
      "Epoch [910/1000], Loss: 0.007387360092252493\n",
      "Epoch [911/1000], Loss: 0.007387343794107437\n",
      "Epoch [912/1000], Loss: 0.007387386169284582\n",
      "Epoch [913/1000], Loss: 0.0073873973451554775\n",
      "Epoch [914/1000], Loss: 0.007387338671833277\n",
      "Epoch [915/1000], Loss: 0.007387261372059584\n",
      "Epoch [916/1000], Loss: 0.007387230638414621\n",
      "Epoch [917/1000], Loss: 0.007387245539575815\n",
      "Epoch [918/1000], Loss: 0.007387255784124136\n",
      "Epoch [919/1000], Loss: 0.007387223187834024\n",
      "Epoch [920/1000], Loss: 0.007387169636785984\n",
      "Epoch [921/1000], Loss: 0.007387136109173298\n",
      "Epoch [922/1000], Loss: 0.007387133780866861\n",
      "Epoch [923/1000], Loss: 0.007387136574834585\n",
      "Epoch [924/1000], Loss: 0.0073871188797056675\n",
      "Epoch [925/1000], Loss: 0.007387083955109119\n",
      "Epoch [926/1000], Loss: 0.00738705275580287\n",
      "Epoch [927/1000], Loss: 0.0073870401829481125\n",
      "Epoch [928/1000], Loss: 0.007387038320302963\n",
      "Epoch [929/1000], Loss: 0.0073870266787707806\n",
      "Epoch [930/1000], Loss: 0.00738700432702899\n",
      "Epoch [931/1000], Loss: 0.007386978715658188\n",
      "Epoch [932/1000], Loss: 0.007386960554867983\n",
      "Epoch [933/1000], Loss: 0.007386951707303524\n",
      "Epoch [934/1000], Loss: 0.0073869433254003525\n",
      "Epoch [935/1000], Loss: 0.007386929355561733\n",
      "Epoch [936/1000], Loss: 0.007386909797787666\n",
      "Epoch [937/1000], Loss: 0.007386890705674887\n",
      "Epoch [938/1000], Loss: 0.007386878132820129\n",
      "Epoch [939/1000], Loss: 0.007386867888271809\n",
      "Epoch [940/1000], Loss: 0.007386857643723488\n",
      "Epoch [941/1000], Loss: 0.007386844139546156\n",
      "Epoch [942/1000], Loss: 0.0073868283070623875\n",
      "Epoch [943/1000], Loss: 0.007386813405901194\n",
      "Epoch [944/1000], Loss: 0.007386801764369011\n",
      "Epoch [945/1000], Loss: 0.00738679151982069\n",
      "Epoch [946/1000], Loss: 0.007386781275272369\n",
      "Epoch [947/1000], Loss: 0.0073867677710950375\n",
      "Epoch [948/1000], Loss: 0.007386754732578993\n",
      "Epoch [949/1000], Loss: 0.0073867421597242355\n",
      "Epoch [950/1000], Loss: 0.00738673098385334\n",
      "Epoch [951/1000], Loss: 0.007386720739305019\n",
      "Epoch [952/1000], Loss: 0.007386710494756699\n",
      "Epoch [953/1000], Loss: 0.007386700250208378\n",
      "Epoch [954/1000], Loss: 0.007386688608676195\n",
      "Epoch [955/1000], Loss: 0.0073866769671440125\n",
      "Epoch [956/1000], Loss: 0.007386666722595692\n",
      "Epoch [957/1000], Loss: 0.007386656943708658\n",
      "Epoch [958/1000], Loss: 0.007386647630482912\n",
      "Epoch [959/1000], Loss: 0.007386637851595879\n",
      "Epoch [960/1000], Loss: 0.007386627607047558\n",
      "Epoch [961/1000], Loss: 0.007386618293821812\n",
      "Epoch [962/1000], Loss: 0.007386608049273491\n",
      "Epoch [963/1000], Loss: 0.0073865982703864574\n",
      "Epoch [964/1000], Loss: 0.007386588957160711\n",
      "Epoch [965/1000], Loss: 0.00738658057525754\n",
      "Epoch [966/1000], Loss: 0.007386571262031794\n",
      "Epoch [967/1000], Loss: 0.007386562414467335\n",
      "Epoch [968/1000], Loss: 0.007386552635580301\n",
      "Epoch [969/1000], Loss: 0.007386544719338417\n",
      "Epoch [970/1000], Loss: 0.007386534940451384\n",
      "Epoch [971/1000], Loss: 0.007386527024209499\n",
      "Epoch [972/1000], Loss: 0.0073865181766450405\n",
      "Epoch [973/1000], Loss: 0.007386510260403156\n",
      "Epoch [974/1000], Loss: 0.007386501878499985\n",
      "Epoch [975/1000], Loss: 0.007386493030935526\n",
      "Epoch [976/1000], Loss: 0.007386486046016216\n",
      "Epoch [977/1000], Loss: 0.007386477198451757\n",
      "Epoch [978/1000], Loss: 0.0073864697478711605\n",
      "Epoch [979/1000], Loss: 0.007386462297290564\n",
      "Epoch [980/1000], Loss: 0.007386453449726105\n",
      "Epoch [981/1000], Loss: 0.007386446464806795\n",
      "Epoch [982/1000], Loss: 0.007386439014226198\n",
      "Epoch [983/1000], Loss: 0.007386431563645601\n",
      "Epoch [984/1000], Loss: 0.007386424113065004\n",
      "Epoch [985/1000], Loss: 0.007386416662484407\n",
      "Epoch [986/1000], Loss: 0.007386409677565098\n",
      "Epoch [987/1000], Loss: 0.007386402226984501\n",
      "Epoch [988/1000], Loss: 0.007386394776403904\n",
      "Epoch [989/1000], Loss: 0.007386388257145882\n",
      "Epoch [990/1000], Loss: 0.007386380806565285\n",
      "Epoch [991/1000], Loss: 0.007386373355984688\n",
      "Epoch [992/1000], Loss: 0.0073863668367266655\n",
      "Epoch [993/1000], Loss: 0.007386360317468643\n",
      "Epoch [994/1000], Loss: 0.007386353798210621\n",
      "Epoch [995/1000], Loss: 0.007386346347630024\n",
      "Epoch [996/1000], Loss: 0.007386340294033289\n",
      "Epoch [997/1000], Loss: 0.007386333774775267\n",
      "Epoch [998/1000], Loss: 0.00738632632419467\n",
      "Epoch [999/1000], Loss: 0.007386320736259222\n",
      "Epoch [1000/1000], Loss: 0.0073863142170012\n"
     ]
    }
   ],
   "source": [
    "make_enc_embeds(data.x, num_features, num_epochs=1000, embedding_size=64, file_name=\"encoder_emb_BlogCatalog64.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "try vector size = 64"
   ],
   "metadata": {
    "id": "kTs1ut1VxPRv",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "GNN_model = GATv2(dataset.num_features, dataset.num_classes, embedding_dimension=8).to(device)\n",
    "run_model(GNN_model , Gnn_epochs=700 ,enc_address=\"encoder_emb_BlogCatalog64.pt\" ,reply_threshold=0.85 , head_epochs= 3000 , validation_mask=new_valdation_mask , early_stop=0.88 )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2iVa34yxVCg",
    "outputId": "715b3a14-61fb-4e79-9552-eee2c357f0c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "epoch : 1 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1911\n",
      "epoch : 100 = >  Accuracy: 0.3393\n",
      "epoch : 150 = >  Accuracy: 0.4586\n",
      "epoch : 200 = >  Accuracy: 0.5215\n",
      "epoch : 250 = >  Accuracy: 0.5394\n",
      "epoch : 300 = >  Accuracy: 0.5619\n",
      "epoch : 350 = >  Accuracy: 0.5863\n",
      "epoch : 400 = >  Accuracy: 0.6023\n",
      "epoch : 450 = >  Accuracy: 0.6183\n",
      "epoch : 500 = >  Accuracy: 0.6151\n",
      "epoch : 550 = >  Accuracy: 0.6171\n",
      "epoch : 600 = >  Accuracy: 0.6183\n",
      "epoch : 650 = >  Accuracy: 0.6177\n",
      "epoch : 700 = >  Accuracy: 0.6158\n",
      "Final accuracy: 0.6158\n",
      "epoch 0 ,Accuracy: 0.2322 , train acc : 0.21208622016936104\n",
      "epoch 50 ,Accuracy: 0.6280 , train acc : 0.8210161662817552\n",
      "epoch 100 ,Accuracy: 0.6639 , train acc : 0.8779830638953041\n",
      "epoch 150 ,Accuracy: 0.6754 , train acc : 0.9053117782909931\n",
      "epoch 200 ,Accuracy: 0.6870 , train acc : 0.9337952270977675\n",
      "epoch 250 ,Accuracy: 0.6857 , train acc : 0.941108545034642\n",
      "epoch 300 ,Accuracy: 0.6979 , train acc : 0.9515011547344111\n",
      "epoch 350 ,Accuracy: 0.6915 , train acc : 0.9607390300230947\n",
      "epoch 400 ,Accuracy: 0.6953 , train acc : 0.9649730561970746\n",
      "epoch 450 ,Accuracy: 0.6940 , train acc : 0.9730561970746728\n",
      "epoch 500 ,Accuracy: 0.7049 , train acc : 0.9757505773672055\n",
      "epoch 550 ,Accuracy: 0.6934 , train acc : 0.9761354888375674\n",
      "epoch 600 ,Accuracy: 0.6915 , train acc : 0.9826789838337182\n",
      "epoch 650 ,Accuracy: 0.6966 , train acc : 0.9792147806004619\n",
      "epoch 700 ,Accuracy: 0.7004 , train acc : 0.9842186297151655\n",
      "epoch 750 ,Accuracy: 0.6953 , train acc : 0.9899923017705927\n",
      "epoch 800 ,Accuracy: 0.7017 , train acc : 0.9869130100076983\n",
      "epoch 850 ,Accuracy: 0.7107 , train acc : 0.9903772132409546\n",
      "epoch 900 ,Accuracy: 0.6998 , train acc : 0.9911470361816782\n",
      "epoch 950 ,Accuracy: 0.7049 , train acc : 0.9876828329484219\n",
      "epoch 1000 ,Accuracy: 0.7011 , train acc : 0.993841416474211\n",
      "epoch 1050 ,Accuracy: 0.6998 , train acc : 0.9953810623556582\n",
      "epoch 1100 ,Accuracy: 0.7017 , train acc : 0.9926866820631255\n",
      "epoch 1150 ,Accuracy: 0.7075 , train acc : 0.9930715935334873\n",
      "epoch 1200 ,Accuracy: 0.6979 , train acc : 0.9934565050038491\n",
      "epoch 1250 ,Accuracy: 0.6972 , train acc : 0.9911470361816782\n",
      "epoch 1300 ,Accuracy: 0.7126 , train acc : 0.9946112394149346\n",
      "epoch 1350 ,Accuracy: 0.7081 , train acc : 0.9961508852963818\n",
      "epoch 1400 ,Accuracy: 0.7037 , train acc : 0.9961508852963818\n",
      "epoch 1450 ,Accuracy: 0.7030 , train acc : 0.9973056197074672\n",
      "epoch 1500 ,Accuracy: 0.6940 , train acc : 0.9976905311778291\n",
      "epoch 1550 ,Accuracy: 0.6947 , train acc : 0.9953810623556582\n",
      "epoch 1600 ,Accuracy: 0.7094 , train acc : 0.9942263279445728\n",
      "epoch 1650 ,Accuracy: 0.7004 , train acc : 0.9949961508852964\n",
      "epoch 1700 ,Accuracy: 0.7158 , train acc : 0.9973056197074672\n",
      "epoch 1750 ,Accuracy: 0.6998 , train acc : 0.9961508852963818\n",
      "epoch 1800 ,Accuracy: 0.6985 , train acc : 0.9953810623556582\n",
      "epoch 1850 ,Accuracy: 0.7075 , train acc : 0.9946112394149346\n",
      "epoch 1900 ,Accuracy: 0.7088 , train acc : 0.9980754426481909\n",
      "epoch 1950 ,Accuracy: 0.6857 , train acc : 0.976905311778291\n",
      "epoch 2000 ,Accuracy: 0.7024 , train acc : 0.9949961508852964\n",
      "epoch 2050 ,Accuracy: 0.7081 , train acc : 0.9953810623556582\n",
      "epoch 2100 ,Accuracy: 0.7011 , train acc : 0.9953810623556582\n",
      "epoch 2150 ,Accuracy: 0.7011 , train acc : 0.9965357967667436\n",
      "epoch 2200 ,Accuracy: 0.6985 , train acc : 0.9980754426481909\n",
      "epoch 2250 ,Accuracy: 0.7017 , train acc : 0.9969207082371054\n",
      "epoch 2300 ,Accuracy: 0.7056 , train acc : 0.9961508852963818\n",
      "epoch 2350 ,Accuracy: 0.7242 , train acc : 0.9969207082371054\n",
      "epoch 2400 ,Accuracy: 0.7139 , train acc : 0.9961508852963818\n",
      "epoch 2450 ,Accuracy: 0.7139 , train acc : 0.9973056197074672\n",
      "epoch 2500 ,Accuracy: 0.7030 , train acc : 0.9984603541185527\n",
      "epoch 2550 ,Accuracy: 0.7101 , train acc : 0.9984603541185527\n",
      "epoch 2600 ,Accuracy: 0.7114 , train acc : 0.9992301770592764\n",
      "epoch 2650 ,Accuracy: 0.7081 , train acc : 0.9988452655889145\n",
      "epoch 2700 ,Accuracy: 0.7114 , train acc : 0.9965357967667436\n",
      "epoch 2750 ,Accuracy: 0.7114 , train acc : 0.9984603541185527\n",
      "epoch 2800 ,Accuracy: 0.7120 , train acc : 0.9988452655889145\n",
      "epoch 2850 ,Accuracy: 0.7101 , train acc : 0.9984603541185527\n",
      "epoch 2900 ,Accuracy: 0.7133 , train acc : 0.9976905311778291\n",
      "epoch 2950 ,Accuracy: 0.7133 , train acc : 0.9984603541185527\n",
      "Accuracy: 0.7062\n",
      "base model\n",
      "0.6157793457344451\n",
      "0.6085268859598782\n",
      "OurModel\n",
      "0.7062219371391918\n",
      "0.7040638095813043\n",
      "*****\n",
      "epoch : 2 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1854\n",
      "epoch : 100 = >  Accuracy: 0.3271\n",
      "epoch : 150 = >  Accuracy: 0.4529\n",
      "epoch : 200 = >  Accuracy: 0.5170\n",
      "epoch : 250 = >  Accuracy: 0.5343\n",
      "epoch : 300 = >  Accuracy: 0.5600\n",
      "epoch : 350 = >  Accuracy: 0.5773\n",
      "epoch : 400 = >  Accuracy: 0.5972\n",
      "epoch : 450 = >  Accuracy: 0.6042\n",
      "epoch : 500 = >  Accuracy: 0.6100\n",
      "epoch : 550 = >  Accuracy: 0.6158\n",
      "epoch : 600 = >  Accuracy: 0.6132\n",
      "epoch : 650 = >  Accuracy: 0.6209\n",
      "epoch : 700 = >  Accuracy: 0.6248\n",
      "Final accuracy: 0.6248\n",
      "epoch 0 ,Accuracy: 0.2181 , train acc : 0.21709006928406466\n",
      "epoch 50 ,Accuracy: 0.6479 , train acc : 0.8110084680523479\n",
      "epoch 100 ,Accuracy: 0.6639 , train acc : 0.876058506543495\n",
      "epoch 150 ,Accuracy: 0.6831 , train acc : 0.9014626635873749\n",
      "epoch 200 ,Accuracy: 0.6889 , train acc : 0.9257120862201693\n",
      "epoch 250 ,Accuracy: 0.7004 , train acc : 0.9399538106235565\n",
      "epoch 300 ,Accuracy: 0.6915 , train acc : 0.9507313317936874\n",
      "epoch 350 ,Accuracy: 0.6966 , train acc : 0.9634334103156275\n",
      "epoch 400 ,Accuracy: 0.7037 , train acc : 0.964203233256351\n",
      "epoch 450 ,Accuracy: 0.7017 , train acc : 0.9665127020785219\n",
      "epoch 500 ,Accuracy: 0.7075 , train acc : 0.9672825250192456\n",
      "epoch 550 ,Accuracy: 0.6992 , train acc : 0.9753656658968437\n",
      "epoch 600 ,Accuracy: 0.7088 , train acc : 0.9795996920708238\n",
      "epoch 650 ,Accuracy: 0.6985 , train acc : 0.9834488067744419\n",
      "epoch 700 ,Accuracy: 0.6979 , train acc : 0.9838337182448037\n",
      "epoch 750 ,Accuracy: 0.7030 , train acc : 0.9849884526558892\n",
      "epoch 800 ,Accuracy: 0.7107 , train acc : 0.985373364126251\n",
      "epoch 850 ,Accuracy: 0.7056 , train acc : 0.9876828329484219\n",
      "epoch 900 ,Accuracy: 0.7017 , train acc : 0.9919168591224018\n",
      "epoch 950 ,Accuracy: 0.7030 , train acc : 0.99153194765204\n",
      "epoch 1000 ,Accuracy: 0.7056 , train acc : 0.9903772132409546\n",
      "epoch 1050 ,Accuracy: 0.6934 , train acc : 0.993841416474211\n",
      "epoch 1100 ,Accuracy: 0.7043 , train acc : 0.9934565050038491\n",
      "epoch 1150 ,Accuracy: 0.7075 , train acc : 0.9930715935334873\n",
      "epoch 1200 ,Accuracy: 0.7011 , train acc : 0.99153194765204\n",
      "epoch 1250 ,Accuracy: 0.7037 , train acc : 0.9923017705927637\n",
      "epoch 1300 ,Accuracy: 0.7094 , train acc : 0.9949961508852964\n",
      "epoch 1350 ,Accuracy: 0.6979 , train acc : 0.9919168591224018\n",
      "epoch 1400 ,Accuracy: 0.7158 , train acc : 0.9930715935334873\n",
      "epoch 1450 ,Accuracy: 0.7139 , train acc : 0.9934565050038491\n",
      "epoch 1500 ,Accuracy: 0.6992 , train acc : 0.9919168591224018\n",
      "epoch 1550 ,Accuracy: 0.7017 , train acc : 0.9953810623556582\n",
      "epoch 1600 ,Accuracy: 0.7024 , train acc : 0.9949961508852964\n",
      "epoch 1650 ,Accuracy: 0.7088 , train acc : 0.9961508852963818\n",
      "epoch 1700 ,Accuracy: 0.6915 , train acc : 0.9949961508852964\n",
      "epoch 1750 ,Accuracy: 0.7107 , train acc : 0.9961508852963818\n",
      "epoch 1800 ,Accuracy: 0.6992 , train acc : 0.9934565050038491\n",
      "epoch 1850 ,Accuracy: 0.7081 , train acc : 0.9961508852963818\n",
      "epoch 1900 ,Accuracy: 0.7024 , train acc : 0.9984603541185527\n",
      "epoch 1950 ,Accuracy: 0.6979 , train acc : 0.9984603541185527\n",
      "epoch 2000 ,Accuracy: 0.7088 , train acc : 0.9980754426481909\n",
      "epoch 2050 ,Accuracy: 0.7088 , train acc : 0.9973056197074672\n",
      "epoch 2100 ,Accuracy: 0.7101 , train acc : 0.9976905311778291\n",
      "epoch 2150 ,Accuracy: 0.7107 , train acc : 0.9984603541185527\n",
      "epoch 2200 ,Accuracy: 0.7075 , train acc : 0.9942263279445728\n",
      "epoch 2250 ,Accuracy: 0.7030 , train acc : 0.9973056197074672\n",
      "epoch 2300 ,Accuracy: 0.7056 , train acc : 0.9988452655889145\n",
      "epoch 2350 ,Accuracy: 0.7049 , train acc : 0.9980754426481909\n",
      "epoch 2400 ,Accuracy: 0.7107 , train acc : 0.9984603541185527\n",
      "epoch 2450 ,Accuracy: 0.7037 , train acc : 0.9984603541185527\n",
      "epoch 2500 ,Accuracy: 0.7024 , train acc : 0.9969207082371054\n",
      "epoch 2550 ,Accuracy: 0.7088 , train acc : 0.9973056197074672\n",
      "epoch 2600 ,Accuracy: 0.7088 , train acc : 0.9976905311778291\n",
      "epoch 2650 ,Accuracy: 0.7062 , train acc : 0.9988452655889145\n",
      "epoch 2700 ,Accuracy: 0.7101 , train acc : 0.9996150885296382\n",
      "epoch 2750 ,Accuracy: 0.7049 , train acc : 0.9980754426481909\n",
      "epoch 2800 ,Accuracy: 0.7075 , train acc : 0.9992301770592764\n",
      "epoch 2850 ,Accuracy: 0.7004 , train acc : 0.9984603541185527\n",
      "epoch 2900 ,Accuracy: 0.7069 , train acc : 0.9976905311778291\n",
      "epoch 2950 ,Accuracy: 0.7133 , train acc : 0.9976905311778291\n",
      "Accuracy: 0.7049\n",
      "base model\n",
      "0.6247594611930725\n",
      "0.6182663711667805\n",
      "OurModel\n",
      "0.704939063502245\n",
      "0.7017419709944916\n",
      "*****\n",
      "epoch : 3 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1854\n",
      "epoch : 100 = >  Accuracy: 0.3316\n",
      "epoch : 150 = >  Accuracy: 0.4419\n",
      "epoch : 200 = >  Accuracy: 0.5170\n",
      "epoch : 250 = >  Accuracy: 0.5420\n",
      "epoch : 300 = >  Accuracy: 0.5600\n",
      "epoch : 350 = >  Accuracy: 0.5888\n",
      "epoch : 400 = >  Accuracy: 0.6081\n",
      "epoch : 450 = >  Accuracy: 0.6177\n",
      "epoch : 500 = >  Accuracy: 0.6203\n",
      "epoch : 550 = >  Accuracy: 0.6196\n",
      "epoch : 600 = >  Accuracy: 0.6209\n",
      "epoch : 650 = >  Accuracy: 0.6228\n",
      "epoch : 700 = >  Accuracy: 0.6273\n",
      "Final accuracy: 0.6273\n",
      "epoch 0 ,Accuracy: 0.1963 , train acc : 0.2040030792917629\n",
      "epoch 50 ,Accuracy: 0.4978 , train acc : 0.5669745958429562\n",
      "epoch 100 ,Accuracy: 0.5119 , train acc : 0.6085450346420324\n",
      "epoch 150 ,Accuracy: 0.6228 , train acc : 0.7551963048498845\n",
      "epoch 200 ,Accuracy: 0.6414 , train acc : 0.7736720554272517\n",
      "epoch 250 ,Accuracy: 0.6453 , train acc : 0.7829099307159353\n",
      "epoch 300 ,Accuracy: 0.6511 , train acc : 0.7936874518860662\n",
      "epoch 350 ,Accuracy: 0.6626 , train acc : 0.7967667436489607\n",
      "epoch 400 ,Accuracy: 0.6517 , train acc : 0.7956120092378753\n",
      "epoch 450 ,Accuracy: 0.6555 , train acc : 0.8036951501154734\n",
      "epoch 500 ,Accuracy: 0.6607 , train acc : 0.8029253271747498\n",
      "epoch 550 ,Accuracy: 0.6613 , train acc : 0.8098537336412626\n",
      "epoch 600 ,Accuracy: 0.6671 , train acc : 0.8090839107005389\n",
      "epoch 650 ,Accuracy: 0.6562 , train acc : 0.8144726712856043\n",
      "epoch 700 ,Accuracy: 0.6581 , train acc : 0.8133179368745188\n",
      "epoch 750 ,Accuracy: 0.6613 , train acc : 0.8144726712856043\n",
      "epoch 800 ,Accuracy: 0.6600 , train acc : 0.8175519630484989\n",
      "epoch 850 ,Accuracy: 0.6697 , train acc : 0.8187066974595842\n",
      "epoch 900 ,Accuracy: 0.6607 , train acc : 0.8171670515781371\n",
      "epoch 950 ,Accuracy: 0.6652 , train acc : 0.8187066974595842\n",
      "epoch 1000 ,Accuracy: 0.6549 , train acc : 0.8202463433410315\n",
      "epoch 1050 ,Accuracy: 0.6632 , train acc : 0.8187066974595842\n",
      "epoch 1100 ,Accuracy: 0.6594 , train acc : 0.8225558121632025\n",
      "epoch 1150 ,Accuracy: 0.6613 , train acc : 0.821401077752117\n",
      "epoch 1200 ,Accuracy: 0.6658 , train acc : 0.8233256351039261\n",
      "epoch 1250 ,Accuracy: 0.6555 , train acc : 0.8233256351039261\n",
      "epoch 1300 ,Accuracy: 0.6620 , train acc : 0.8225558121632025\n",
      "epoch 1350 ,Accuracy: 0.6620 , train acc : 0.8229407236335643\n",
      "epoch 1400 ,Accuracy: 0.6626 , train acc : 0.8217859892224788\n",
      "epoch 1450 ,Accuracy: 0.6652 , train acc : 0.8237105465742879\n",
      "epoch 1500 ,Accuracy: 0.6581 , train acc : 0.8221709006928406\n",
      "epoch 1550 ,Accuracy: 0.6607 , train acc : 0.8229407236335643\n",
      "epoch 1600 ,Accuracy: 0.6562 , train acc : 0.8240954580446497\n",
      "epoch 1650 ,Accuracy: 0.6607 , train acc : 0.8233256351039261\n",
      "epoch 1700 ,Accuracy: 0.6549 , train acc : 0.8217859892224788\n",
      "epoch 1750 ,Accuracy: 0.6639 , train acc : 0.8237105465742879\n",
      "epoch 1800 ,Accuracy: 0.6588 , train acc : 0.8244803695150116\n",
      "epoch 1850 ,Accuracy: 0.6568 , train acc : 0.8233256351039261\n",
      "epoch 1900 ,Accuracy: 0.6600 , train acc : 0.8237105465742879\n",
      "epoch 1950 ,Accuracy: 0.6658 , train acc : 0.8244803695150116\n",
      "epoch 2000 ,Accuracy: 0.6607 , train acc : 0.8248652809853734\n",
      "epoch 2050 ,Accuracy: 0.6594 , train acc : 0.8229407236335643\n",
      "epoch 2100 ,Accuracy: 0.6568 , train acc : 0.8244803695150116\n",
      "epoch 2150 ,Accuracy: 0.6658 , train acc : 0.8240954580446497\n",
      "epoch 2200 ,Accuracy: 0.6562 , train acc : 0.8252501924557352\n",
      "epoch 2250 ,Accuracy: 0.6652 , train acc : 0.8240954580446497\n",
      "epoch 2300 ,Accuracy: 0.6530 , train acc : 0.8252501924557352\n",
      "epoch 2350 ,Accuracy: 0.6652 , train acc : 0.8260200153964589\n",
      "epoch 2400 ,Accuracy: 0.6677 , train acc : 0.8264049268668207\n",
      "epoch 2450 ,Accuracy: 0.6626 , train acc : 0.8248652809853734\n",
      "epoch 2500 ,Accuracy: 0.6639 , train acc : 0.8252501924557352\n",
      "epoch 2550 ,Accuracy: 0.6549 , train acc : 0.8248652809853734\n",
      "epoch 2600 ,Accuracy: 0.6594 , train acc : 0.8252501924557352\n",
      "epoch 2650 ,Accuracy: 0.6588 , train acc : 0.825635103926097\n",
      "epoch 2700 ,Accuracy: 0.6504 , train acc : 0.825635103926097\n",
      "epoch 2750 ,Accuracy: 0.6620 , train acc : 0.8260200153964589\n",
      "epoch 2800 ,Accuracy: 0.6594 , train acc : 0.8252501924557352\n",
      "epoch 2850 ,Accuracy: 0.6665 , train acc : 0.825635103926097\n",
      "epoch 2900 ,Accuracy: 0.6626 , train acc : 0.8229407236335643\n",
      "epoch 2950 ,Accuracy: 0.6568 , train acc : 0.8260200153964589\n",
      "epoch 0 ,Accuracy: 0.2437 , train acc : 0.24480369515011546\n",
      "epoch 50 ,Accuracy: 0.6254 , train acc : 0.7763664357197845\n",
      "epoch 100 ,Accuracy: 0.6748 , train acc : 0.8579676674364896\n",
      "epoch 150 ,Accuracy: 0.6921 , train acc : 0.8979984603541186\n",
      "epoch 200 ,Accuracy: 0.6960 , train acc : 0.9145496535796767\n",
      "epoch 250 ,Accuracy: 0.7178 , train acc : 0.9291762894534257\n",
      "epoch 300 ,Accuracy: 0.7075 , train acc : 0.9414934565050038\n",
      "epoch 350 ,Accuracy: 0.7146 , train acc : 0.9484218629715165\n",
      "epoch 400 ,Accuracy: 0.7120 , train acc : 0.9549653579676675\n",
      "epoch 450 ,Accuracy: 0.7043 , train acc : 0.9553502694380293\n",
      "epoch 500 ,Accuracy: 0.7178 , train acc : 0.9653579676674365\n",
      "epoch 550 ,Accuracy: 0.7210 , train acc : 0.9668976135488837\n",
      "epoch 600 ,Accuracy: 0.7223 , train acc : 0.9734411085450346\n",
      "epoch 650 ,Accuracy: 0.7088 , train acc : 0.9792147806004619\n",
      "epoch 700 ,Accuracy: 0.7081 , train acc : 0.9807544264819091\n",
      "epoch 750 ,Accuracy: 0.7133 , train acc : 0.9849884526558892\n",
      "epoch 800 ,Accuracy: 0.7165 , train acc : 0.9811393379522709\n",
      "epoch 850 ,Accuracy: 0.7114 , train acc : 0.9834488067744419\n",
      "epoch 900 ,Accuracy: 0.7203 , train acc : 0.9876828329484219\n",
      "epoch 950 ,Accuracy: 0.7101 , train acc : 0.9857582755966128\n",
      "epoch 1000 ,Accuracy: 0.7216 , train acc : 0.9911470361816782\n",
      "epoch 1050 ,Accuracy: 0.7178 , train acc : 0.9888375673595073\n",
      "epoch 1100 ,Accuracy: 0.7203 , train acc : 0.9872979214780601\n",
      "epoch 1150 ,Accuracy: 0.7210 , train acc : 0.9849884526558892\n",
      "epoch 1200 ,Accuracy: 0.7242 , train acc : 0.9907621247113164\n",
      "epoch 1250 ,Accuracy: 0.7229 , train acc : 0.9903772132409546\n",
      "epoch 1300 ,Accuracy: 0.7165 , train acc : 0.9911470361816782\n",
      "epoch 1350 ,Accuracy: 0.7191 , train acc : 0.9961508852963818\n",
      "epoch 1400 ,Accuracy: 0.7248 , train acc : 0.9934565050038491\n",
      "epoch 1450 ,Accuracy: 0.7223 , train acc : 0.9942263279445728\n",
      "epoch 1500 ,Accuracy: 0.7248 , train acc : 0.9930715935334873\n",
      "epoch 1550 ,Accuracy: 0.7165 , train acc : 0.9946112394149346\n",
      "epoch 1600 ,Accuracy: 0.7210 , train acc : 0.9930715935334873\n",
      "epoch 1650 ,Accuracy: 0.7261 , train acc : 0.9926866820631255\n",
      "epoch 1700 ,Accuracy: 0.7216 , train acc : 0.9953810623556582\n",
      "epoch 1750 ,Accuracy: 0.7197 , train acc : 0.9965357967667436\n",
      "epoch 1800 ,Accuracy: 0.7216 , train acc : 0.9965357967667436\n",
      "epoch 1850 ,Accuracy: 0.7203 , train acc : 0.9976905311778291\n",
      "epoch 1900 ,Accuracy: 0.7184 , train acc : 0.9965357967667436\n",
      "epoch 1950 ,Accuracy: 0.7197 , train acc : 0.9946112394149346\n",
      "epoch 2000 ,Accuracy: 0.7165 , train acc : 0.9965357967667436\n",
      "epoch 2050 ,Accuracy: 0.7197 , train acc : 0.9946112394149346\n",
      "epoch 2100 ,Accuracy: 0.7191 , train acc : 0.9946112394149346\n",
      "epoch 2150 ,Accuracy: 0.7197 , train acc : 0.9961508852963818\n",
      "epoch 2200 ,Accuracy: 0.7197 , train acc : 0.9973056197074672\n",
      "epoch 2250 ,Accuracy: 0.7203 , train acc : 0.9973056197074672\n",
      "epoch 2300 ,Accuracy: 0.7203 , train acc : 0.9953810623556582\n",
      "epoch 2350 ,Accuracy: 0.7210 , train acc : 0.9980754426481909\n",
      "epoch 2400 ,Accuracy: 0.7216 , train acc : 0.9969207082371054\n",
      "epoch 2450 ,Accuracy: 0.7184 , train acc : 0.9969207082371054\n",
      "epoch 2500 ,Accuracy: 0.7248 , train acc : 0.9976905311778291\n",
      "epoch 2550 ,Accuracy: 0.7197 , train acc : 0.9965357967667436\n",
      "epoch 2600 ,Accuracy: 0.7242 , train acc : 0.9923017705927637\n",
      "epoch 2650 ,Accuracy: 0.7184 , train acc : 0.9980754426481909\n",
      "epoch 2700 ,Accuracy: 0.7184 , train acc : 0.9973056197074672\n",
      "epoch 2750 ,Accuracy: 0.7165 , train acc : 0.9973056197074672\n",
      "epoch 2800 ,Accuracy: 0.7184 , train acc : 0.9984603541185527\n",
      "epoch 2850 ,Accuracy: 0.7223 , train acc : 0.9946112394149346\n",
      "epoch 2900 ,Accuracy: 0.7171 , train acc : 0.9942263279445728\n",
      "epoch 2950 ,Accuracy: 0.7255 , train acc : 0.9980754426481909\n",
      "Accuracy: 0.7287\n",
      "base model\n",
      "0.627325208466966\n",
      "0.6205481127459812\n",
      "OurModel\n",
      "0.7286722257857601\n",
      "0.7243392112386798\n",
      "*****\n",
      "epoch : 4 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1854\n",
      "epoch : 100 = >  Accuracy: 0.3419\n",
      "epoch : 150 = >  Accuracy: 0.4535\n",
      "epoch : 200 = >  Accuracy: 0.5170\n",
      "epoch : 250 = >  Accuracy: 0.5394\n",
      "epoch : 300 = >  Accuracy: 0.5619\n",
      "epoch : 350 = >  Accuracy: 0.5888\n",
      "epoch : 400 = >  Accuracy: 0.6030\n",
      "epoch : 450 = >  Accuracy: 0.6100\n",
      "epoch : 500 = >  Accuracy: 0.6119\n",
      "epoch : 550 = >  Accuracy: 0.6190\n",
      "epoch : 600 = >  Accuracy: 0.6209\n",
      "epoch : 650 = >  Accuracy: 0.6209\n",
      "epoch : 700 = >  Accuracy: 0.6248\n",
      "Final accuracy: 0.6248\n",
      "epoch 0 ,Accuracy: 0.1956 , train acc : 0.21862971516551194\n",
      "epoch 50 ,Accuracy: 0.6286 , train acc : 0.8121632024634334\n",
      "epoch 100 ,Accuracy: 0.6555 , train acc : 0.8787528868360277\n",
      "epoch 150 ,Accuracy: 0.6818 , train acc : 0.9141647421093149\n",
      "epoch 200 ,Accuracy: 0.6857 , train acc : 0.9257120862201693\n",
      "epoch 250 ,Accuracy: 0.6940 , train acc : 0.941108545034642\n",
      "epoch 300 ,Accuracy: 0.6895 , train acc : 0.9449576597382602\n",
      "epoch 350 ,Accuracy: 0.6966 , train acc : 0.953810623556582\n",
      "epoch 400 ,Accuracy: 0.7004 , train acc : 0.9615088529638183\n",
      "epoch 450 ,Accuracy: 0.6972 , train acc : 0.9645881447267128\n",
      "epoch 500 ,Accuracy: 0.7030 , train acc : 0.9742109314857583\n",
      "epoch 550 ,Accuracy: 0.7030 , train acc : 0.9734411085450346\n",
      "epoch 600 ,Accuracy: 0.7030 , train acc : 0.9749807544264819\n",
      "epoch 650 ,Accuracy: 0.7037 , train acc : 0.9776751347190146\n",
      "epoch 700 ,Accuracy: 0.7062 , train acc : 0.9865280985373364\n",
      "epoch 750 ,Accuracy: 0.7043 , train acc : 0.9795996920708238\n",
      "epoch 800 ,Accuracy: 0.7075 , train acc : 0.9861431870669746\n",
      "epoch 850 ,Accuracy: 0.7056 , train acc : 0.9819091608929946\n",
      "epoch 900 ,Accuracy: 0.7191 , train acc : 0.99153194765204\n",
      "epoch 950 ,Accuracy: 0.7094 , train acc : 0.993841416474211\n",
      "epoch 1000 ,Accuracy: 0.7101 , train acc : 0.9880677444187836\n",
      "epoch 1050 ,Accuracy: 0.7049 , train acc : 0.9907621247113164\n",
      "epoch 1100 ,Accuracy: 0.7075 , train acc : 0.9946112394149346\n",
      "epoch 1150 ,Accuracy: 0.7101 , train acc : 0.993841416474211\n",
      "epoch 1200 ,Accuracy: 0.7049 , train acc : 0.9946112394149346\n",
      "epoch 1250 ,Accuracy: 0.7062 , train acc : 0.9953810623556582\n",
      "epoch 1300 ,Accuracy: 0.7171 , train acc : 0.9953810623556582\n",
      "epoch 1350 ,Accuracy: 0.7146 , train acc : 0.9953810623556582\n",
      "epoch 1400 ,Accuracy: 0.7120 , train acc : 0.9934565050038491\n",
      "epoch 1450 ,Accuracy: 0.7120 , train acc : 0.9957659738260201\n",
      "epoch 1500 ,Accuracy: 0.7024 , train acc : 0.9957659738260201\n",
      "epoch 1550 ,Accuracy: 0.7158 , train acc : 0.9934565050038491\n",
      "epoch 1600 ,Accuracy: 0.7094 , train acc : 0.9942263279445728\n",
      "epoch 1650 ,Accuracy: 0.7120 , train acc : 0.9961508852963818\n",
      "epoch 1700 ,Accuracy: 0.7165 , train acc : 0.9973056197074672\n",
      "epoch 1750 ,Accuracy: 0.7075 , train acc : 0.9942263279445728\n",
      "epoch 1800 ,Accuracy: 0.7165 , train acc : 0.9946112394149346\n",
      "epoch 1850 ,Accuracy: 0.7101 , train acc : 0.9961508852963818\n",
      "epoch 1900 ,Accuracy: 0.7075 , train acc : 0.9961508852963818\n",
      "epoch 1950 ,Accuracy: 0.7094 , train acc : 0.9973056197074672\n",
      "epoch 2000 ,Accuracy: 0.7075 , train acc : 0.9961508852963818\n",
      "epoch 2050 ,Accuracy: 0.7017 , train acc : 0.9942263279445728\n",
      "epoch 2100 ,Accuracy: 0.7101 , train acc : 0.9976905311778291\n",
      "epoch 2150 ,Accuracy: 0.7101 , train acc : 0.9976905311778291\n",
      "epoch 2200 ,Accuracy: 0.7062 , train acc : 0.9976905311778291\n",
      "epoch 2250 ,Accuracy: 0.7152 , train acc : 0.9969207082371054\n",
      "epoch 2300 ,Accuracy: 0.7069 , train acc : 0.9969207082371054\n",
      "epoch 2350 ,Accuracy: 0.7062 , train acc : 0.9980754426481909\n",
      "epoch 2400 ,Accuracy: 0.6992 , train acc : 0.9969207082371054\n",
      "epoch 2450 ,Accuracy: 0.7101 , train acc : 0.9980754426481909\n",
      "epoch 2500 ,Accuracy: 0.7146 , train acc : 0.9976905311778291\n",
      "epoch 2550 ,Accuracy: 0.7075 , train acc : 0.9973056197074672\n",
      "epoch 2600 ,Accuracy: 0.7171 , train acc : 0.9973056197074672\n",
      "epoch 2650 ,Accuracy: 0.7126 , train acc : 0.9988452655889145\n",
      "epoch 2700 ,Accuracy: 0.7069 , train acc : 0.9984603541185527\n",
      "epoch 2750 ,Accuracy: 0.7094 , train acc : 0.9973056197074672\n",
      "epoch 2800 ,Accuracy: 0.7158 , train acc : 0.9980754426481909\n",
      "epoch 2850 ,Accuracy: 0.7120 , train acc : 0.9988452655889145\n",
      "epoch 2900 ,Accuracy: 0.7126 , train acc : 0.9976905311778291\n",
      "epoch 2950 ,Accuracy: 0.7088 , train acc : 0.9992301770592764\n",
      "Accuracy: 0.7120\n",
      "base model\n",
      "0.6247594611930725\n",
      "0.6188701463952639\n",
      "OurModel\n",
      "0.7119948685054522\n",
      "0.7076331171356222\n",
      "*****\n",
      "epoch : 5 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1911\n",
      "epoch : 100 = >  Accuracy: 0.3515\n",
      "epoch : 150 = >  Accuracy: 0.4554\n",
      "epoch : 200 = >  Accuracy: 0.5208\n",
      "epoch : 250 = >  Accuracy: 0.5427\n",
      "epoch : 300 = >  Accuracy: 0.5638\n",
      "epoch : 350 = >  Accuracy: 0.5837\n",
      "epoch : 400 = >  Accuracy: 0.5940\n",
      "epoch : 450 = >  Accuracy: 0.6068\n",
      "epoch : 500 = >  Accuracy: 0.6126\n",
      "epoch : 550 = >  Accuracy: 0.6190\n",
      "epoch : 600 = >  Accuracy: 0.6183\n",
      "epoch : 650 = >  Accuracy: 0.6203\n",
      "epoch : 700 = >  Accuracy: 0.6209\n",
      "Final accuracy: 0.6209\n",
      "epoch 0 ,Accuracy: 0.2149 , train acc : 0.1997690531177829\n",
      "epoch 50 ,Accuracy: 0.6440 , train acc : 0.815242494226328\n",
      "epoch 100 ,Accuracy: 0.6620 , train acc : 0.8845265588914549\n",
      "epoch 150 ,Accuracy: 0.6818 , train acc : 0.9207082371054658\n",
      "epoch 200 ,Accuracy: 0.6895 , train acc : 0.9364896073903002\n",
      "epoch 250 ,Accuracy: 0.6889 , train acc : 0.9507313317936874\n",
      "epoch 300 ,Accuracy: 0.6895 , train acc : 0.9584295612009238\n",
      "epoch 350 ,Accuracy: 0.6895 , train acc : 0.968437259430331\n",
      "epoch 400 ,Accuracy: 0.6953 , train acc : 0.972671285604311\n",
      "epoch 450 ,Accuracy: 0.6966 , train acc : 0.9772902232486528\n",
      "epoch 500 ,Accuracy: 0.6953 , train acc : 0.972671285604311\n",
      "epoch 550 ,Accuracy: 0.6966 , train acc : 0.9846035411855273\n",
      "epoch 600 ,Accuracy: 0.6985 , train acc : 0.9826789838337182\n",
      "epoch 650 ,Accuracy: 0.7107 , train acc : 0.9826789838337182\n",
      "epoch 700 ,Accuracy: 0.7011 , train acc : 0.9872979214780601\n",
      "epoch 750 ,Accuracy: 0.7011 , train acc : 0.9884526558891455\n",
      "epoch 800 ,Accuracy: 0.7030 , train acc : 0.9892224788298691\n",
      "epoch 850 ,Accuracy: 0.6838 , train acc : 0.9888375673595073\n",
      "epoch 900 ,Accuracy: 0.7178 , train acc : 0.9926866820631255\n",
      "epoch 950 ,Accuracy: 0.6998 , train acc : 0.9930715935334873\n",
      "epoch 1000 ,Accuracy: 0.7037 , train acc : 0.9919168591224018\n",
      "epoch 1050 ,Accuracy: 0.6985 , train acc : 0.9942263279445728\n",
      "epoch 1100 ,Accuracy: 0.6992 , train acc : 0.9946112394149346\n",
      "epoch 1150 ,Accuracy: 0.6992 , train acc : 0.9957659738260201\n",
      "epoch 1200 ,Accuracy: 0.6992 , train acc : 0.9969207082371054\n",
      "epoch 1250 ,Accuracy: 0.7101 , train acc : 0.9957659738260201\n",
      "epoch 1300 ,Accuracy: 0.6992 , train acc : 0.993841416474211\n",
      "epoch 1350 ,Accuracy: 0.7043 , train acc : 0.9965357967667436\n",
      "epoch 1400 ,Accuracy: 0.6985 , train acc : 0.9946112394149346\n",
      "epoch 1450 ,Accuracy: 0.7043 , train acc : 0.9961508852963818\n",
      "epoch 1500 ,Accuracy: 0.7139 , train acc : 0.9961508852963818\n",
      "epoch 1550 ,Accuracy: 0.7024 , train acc : 0.9973056197074672\n",
      "epoch 1600 ,Accuracy: 0.7075 , train acc : 0.9988452655889145\n",
      "epoch 1650 ,Accuracy: 0.6960 , train acc : 0.9965357967667436\n",
      "epoch 1700 ,Accuracy: 0.7011 , train acc : 0.9973056197074672\n",
      "epoch 1750 ,Accuracy: 0.6966 , train acc : 0.9973056197074672\n",
      "epoch 1800 ,Accuracy: 0.7081 , train acc : 0.9992301770592764\n",
      "epoch 1850 ,Accuracy: 0.7030 , train acc : 0.9976905311778291\n",
      "epoch 1900 ,Accuracy: 0.6934 , train acc : 0.9969207082371054\n",
      "epoch 1950 ,Accuracy: 0.6902 , train acc : 0.9973056197074672\n",
      "epoch 2000 ,Accuracy: 0.7056 , train acc : 0.9980754426481909\n",
      "epoch 2050 ,Accuracy: 0.7056 , train acc : 0.9965357967667436\n",
      "epoch 2100 ,Accuracy: 0.7107 , train acc : 0.9984603541185527\n",
      "epoch 2150 ,Accuracy: 0.7101 , train acc : 0.9969207082371054\n",
      "epoch 2200 ,Accuracy: 0.7043 , train acc : 0.9957659738260201\n",
      "epoch 2250 ,Accuracy: 0.6972 , train acc : 0.9973056197074672\n",
      "epoch 2300 ,Accuracy: 0.7043 , train acc : 0.9984603541185527\n",
      "epoch 2350 ,Accuracy: 0.6992 , train acc : 0.9980754426481909\n",
      "epoch 2400 ,Accuracy: 0.7069 , train acc : 0.9984603541185527\n",
      "epoch 2450 ,Accuracy: 0.6998 , train acc : 0.9980754426481909\n",
      "epoch 2500 ,Accuracy: 0.7088 , train acc : 0.9992301770592764\n",
      "epoch 2550 ,Accuracy: 0.6979 , train acc : 0.9980754426481909\n",
      "epoch 2600 ,Accuracy: 0.6928 , train acc : 0.9976905311778291\n",
      "epoch 2650 ,Accuracy: 0.7037 , train acc : 0.9980754426481909\n",
      "epoch 2700 ,Accuracy: 0.7081 , train acc : 0.9988452655889145\n",
      "epoch 2750 ,Accuracy: 0.7094 , train acc : 0.9988452655889145\n",
      "epoch 2800 ,Accuracy: 0.6972 , train acc : 0.9973056197074672\n",
      "epoch 2850 ,Accuracy: 0.7049 , train acc : 0.9976905311778291\n",
      "epoch 2900 ,Accuracy: 0.6940 , train acc : 0.9992301770592764\n",
      "epoch 2950 ,Accuracy: 0.7017 , train acc : 0.9988452655889145\n",
      "Accuracy: 0.7037\n",
      "base model\n",
      "0.6209108402822322\n",
      "0.614038605931974\n",
      "OurModel\n",
      "0.7036561898652983\n",
      "0.7018073756654579\n",
      "*****\n",
      "epoch : 6 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1854\n",
      "epoch : 100 = >  Accuracy: 0.3477\n",
      "epoch : 150 = >  Accuracy: 0.4561\n",
      "epoch : 200 = >  Accuracy: 0.5196\n",
      "epoch : 250 = >  Accuracy: 0.5350\n",
      "epoch : 300 = >  Accuracy: 0.5638\n",
      "epoch : 350 = >  Accuracy: 0.5754\n",
      "epoch : 400 = >  Accuracy: 0.6062\n",
      "epoch : 450 = >  Accuracy: 0.6106\n",
      "epoch : 500 = >  Accuracy: 0.6100\n",
      "epoch : 550 = >  Accuracy: 0.6196\n",
      "epoch : 600 = >  Accuracy: 0.6280\n",
      "epoch : 650 = >  Accuracy: 0.6267\n",
      "epoch : 700 = >  Accuracy: 0.6209\n",
      "Final accuracy: 0.6209\n",
      "epoch 0 ,Accuracy: 0.1751 , train acc : 0.18206312548113934\n",
      "epoch 50 ,Accuracy: 0.5895 , train acc : 0.6882217090069284\n",
      "epoch 100 ,Accuracy: 0.6171 , train acc : 0.7586605080831409\n",
      "epoch 150 ,Accuracy: 0.6851 , train acc : 0.8960739030023095\n",
      "epoch 200 ,Accuracy: 0.6863 , train acc : 0.922247882986913\n",
      "epoch 250 ,Accuracy: 0.6947 , train acc : 0.9384141647421094\n",
      "epoch 300 ,Accuracy: 0.6883 , train acc : 0.9522709776751347\n",
      "epoch 350 ,Accuracy: 0.6992 , train acc : 0.9595842956120092\n",
      "epoch 400 ,Accuracy: 0.6883 , train acc : 0.9653579676674365\n",
      "epoch 450 ,Accuracy: 0.6985 , train acc : 0.968437259430331\n",
      "epoch 500 ,Accuracy: 0.6940 , train acc : 0.9688221709006929\n",
      "epoch 550 ,Accuracy: 0.7011 , train acc : 0.9784449576597383\n",
      "epoch 600 ,Accuracy: 0.7069 , train acc : 0.9826789838337182\n",
      "epoch 650 ,Accuracy: 0.6953 , train acc : 0.9795996920708238\n",
      "epoch 700 ,Accuracy: 0.6985 , train acc : 0.9826789838337182\n",
      "epoch 750 ,Accuracy: 0.7004 , train acc : 0.9872979214780601\n",
      "epoch 800 ,Accuracy: 0.6953 , train acc : 0.9861431870669746\n",
      "epoch 850 ,Accuracy: 0.7075 , train acc : 0.9884526558891455\n",
      "epoch 900 ,Accuracy: 0.7094 , train acc : 0.9884526558891455\n",
      "epoch 950 ,Accuracy: 0.6985 , train acc : 0.9884526558891455\n",
      "epoch 1000 ,Accuracy: 0.7043 , train acc : 0.9926866820631255\n",
      "epoch 1050 ,Accuracy: 0.7101 , train acc : 0.9899923017705927\n",
      "epoch 1100 ,Accuracy: 0.7004 , train acc : 0.9896073903002309\n",
      "epoch 1150 ,Accuracy: 0.7094 , train acc : 0.9926866820631255\n",
      "epoch 1200 ,Accuracy: 0.7152 , train acc : 0.9934565050038491\n",
      "epoch 1250 ,Accuracy: 0.7043 , train acc : 0.9942263279445728\n",
      "epoch 1300 ,Accuracy: 0.7081 , train acc : 0.9923017705927637\n",
      "epoch 1350 ,Accuracy: 0.7017 , train acc : 0.9930715935334873\n",
      "epoch 1400 ,Accuracy: 0.7004 , train acc : 0.9946112394149346\n",
      "epoch 1450 ,Accuracy: 0.7203 , train acc : 0.9957659738260201\n",
      "epoch 1500 ,Accuracy: 0.7126 , train acc : 0.9949961508852964\n",
      "epoch 1550 ,Accuracy: 0.7088 , train acc : 0.9957659738260201\n",
      "epoch 1600 ,Accuracy: 0.7088 , train acc : 0.9946112394149346\n",
      "epoch 1650 ,Accuracy: 0.7146 , train acc : 0.9942263279445728\n",
      "epoch 1700 ,Accuracy: 0.6998 , train acc : 0.9969207082371054\n",
      "epoch 1750 ,Accuracy: 0.7024 , train acc : 0.9961508852963818\n",
      "epoch 1800 ,Accuracy: 0.7107 , train acc : 0.9957659738260201\n",
      "epoch 1850 ,Accuracy: 0.7107 , train acc : 0.9973056197074672\n",
      "epoch 1900 ,Accuracy: 0.7037 , train acc : 0.993841416474211\n",
      "epoch 1950 ,Accuracy: 0.7107 , train acc : 0.9980754426481909\n",
      "epoch 2000 ,Accuracy: 0.7133 , train acc : 0.9961508852963818\n",
      "epoch 2050 ,Accuracy: 0.7120 , train acc : 0.9965357967667436\n",
      "epoch 2100 ,Accuracy: 0.7101 , train acc : 0.9984603541185527\n",
      "epoch 2150 ,Accuracy: 0.7107 , train acc : 0.9973056197074672\n",
      "epoch 2200 ,Accuracy: 0.7126 , train acc : 0.9980754426481909\n",
      "epoch 2250 ,Accuracy: 0.7017 , train acc : 0.9838337182448037\n",
      "epoch 2300 ,Accuracy: 0.7081 , train acc : 0.9953810623556582\n",
      "epoch 2350 ,Accuracy: 0.7094 , train acc : 0.9965357967667436\n",
      "epoch 2400 ,Accuracy: 0.7152 , train acc : 0.9973056197074672\n",
      "epoch 2450 ,Accuracy: 0.7146 , train acc : 0.9949961508852964\n",
      "epoch 2500 ,Accuracy: 0.7075 , train acc : 0.9965357967667436\n",
      "epoch 2550 ,Accuracy: 0.7088 , train acc : 0.9976905311778291\n",
      "epoch 2600 ,Accuracy: 0.7024 , train acc : 0.9973056197074672\n",
      "epoch 2650 ,Accuracy: 0.7171 , train acc : 0.9984603541185527\n",
      "epoch 2700 ,Accuracy: 0.7069 , train acc : 0.9984603541185527\n",
      "epoch 2750 ,Accuracy: 0.7075 , train acc : 0.9984603541185527\n",
      "epoch 2800 ,Accuracy: 0.7152 , train acc : 0.9976905311778291\n",
      "epoch 2850 ,Accuracy: 0.7165 , train acc : 0.9984603541185527\n",
      "epoch 2900 ,Accuracy: 0.7120 , train acc : 0.9980754426481909\n",
      "epoch 2950 ,Accuracy: 0.7146 , train acc : 0.9976905311778291\n",
      "Accuracy: 0.7069\n",
      "base model\n",
      "0.6209108402822322\n",
      "0.6138733018920692\n",
      "OurModel\n",
      "0.7068633739576652\n",
      "0.7027017050674614\n",
      "*****\n",
      "epoch : 7 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1905\n",
      "epoch : 100 = >  Accuracy: 0.3515\n",
      "epoch : 150 = >  Accuracy: 0.4638\n",
      "epoch : 200 = >  Accuracy: 0.5196\n",
      "epoch : 250 = >  Accuracy: 0.5516\n",
      "epoch : 300 = >  Accuracy: 0.5664\n",
      "epoch : 350 = >  Accuracy: 0.5888\n",
      "epoch : 400 = >  Accuracy: 0.6164\n",
      "epoch : 450 = >  Accuracy: 0.6241\n",
      "epoch : 500 = >  Accuracy: 0.6190\n",
      "epoch : 550 = >  Accuracy: 0.6222\n",
      "epoch : 600 = >  Accuracy: 0.6260\n",
      "epoch : 650 = >  Accuracy: 0.6228\n",
      "epoch : 700 = >  Accuracy: 0.6267\n",
      "Final accuracy: 0.6267\n",
      "epoch 0 ,Accuracy: 0.1886 , train acc : 0.19861431870669746\n",
      "epoch 50 ,Accuracy: 0.6337 , train acc : 0.8110084680523479\n",
      "epoch 100 ,Accuracy: 0.6600 , train acc : 0.8710546574287914\n",
      "epoch 150 ,Accuracy: 0.6806 , train acc : 0.9087759815242494\n",
      "epoch 200 ,Accuracy: 0.6812 , train acc : 0.9291762894534257\n",
      "epoch 250 ,Accuracy: 0.7004 , train acc : 0.9380292532717475\n",
      "epoch 300 ,Accuracy: 0.6947 , train acc : 0.9530408006158584\n",
      "epoch 350 ,Accuracy: 0.6915 , train acc : 0.9522709776751347\n",
      "epoch 400 ,Accuracy: 0.6992 , train acc : 0.9645881447267128\n",
      "epoch 450 ,Accuracy: 0.6979 , train acc : 0.962278675904542\n",
      "epoch 500 ,Accuracy: 0.7017 , train acc : 0.972671285604311\n",
      "epoch 550 ,Accuracy: 0.7062 , train acc : 0.9738260200153964\n",
      "epoch 600 ,Accuracy: 0.7056 , train acc : 0.976905311778291\n",
      "epoch 650 ,Accuracy: 0.7056 , train acc : 0.9846035411855273\n",
      "epoch 700 ,Accuracy: 0.6908 , train acc : 0.9780600461893765\n",
      "epoch 750 ,Accuracy: 0.7101 , train acc : 0.9842186297151655\n",
      "epoch 800 ,Accuracy: 0.7101 , train acc : 0.9869130100076983\n",
      "epoch 850 ,Accuracy: 0.7056 , train acc : 0.9907621247113164\n",
      "epoch 900 ,Accuracy: 0.7043 , train acc : 0.9876828329484219\n",
      "epoch 950 ,Accuracy: 0.7037 , train acc : 0.9919168591224018\n",
      "epoch 1000 ,Accuracy: 0.7101 , train acc : 0.9888375673595073\n",
      "epoch 1050 ,Accuracy: 0.7049 , train acc : 0.9942263279445728\n",
      "epoch 1100 ,Accuracy: 0.7049 , train acc : 0.9926866820631255\n",
      "epoch 1150 ,Accuracy: 0.7062 , train acc : 0.9930715935334873\n",
      "epoch 1200 ,Accuracy: 0.7152 , train acc : 0.9942263279445728\n",
      "epoch 1250 ,Accuracy: 0.6998 , train acc : 0.9953810623556582\n",
      "epoch 1300 ,Accuracy: 0.7056 , train acc : 0.9946112394149346\n",
      "epoch 1350 ,Accuracy: 0.7024 , train acc : 0.9934565050038491\n",
      "epoch 1400 ,Accuracy: 0.7171 , train acc : 0.9949961508852964\n",
      "epoch 1450 ,Accuracy: 0.7062 , train acc : 0.9973056197074672\n",
      "epoch 1500 ,Accuracy: 0.7069 , train acc : 0.9942263279445728\n",
      "epoch 1550 ,Accuracy: 0.7056 , train acc : 0.9988452655889145\n",
      "epoch 1600 ,Accuracy: 0.7075 , train acc : 0.9976905311778291\n",
      "epoch 1650 ,Accuracy: 0.7107 , train acc : 0.9976905311778291\n",
      "epoch 1700 ,Accuracy: 0.7152 , train acc : 0.9942263279445728\n",
      "epoch 1750 ,Accuracy: 0.7088 , train acc : 0.9957659738260201\n",
      "epoch 1800 ,Accuracy: 0.7133 , train acc : 0.9965357967667436\n",
      "epoch 1850 ,Accuracy: 0.7126 , train acc : 0.9973056197074672\n",
      "epoch 1900 ,Accuracy: 0.7056 , train acc : 0.9969207082371054\n",
      "epoch 1950 ,Accuracy: 0.7043 , train acc : 0.9973056197074672\n",
      "epoch 2000 ,Accuracy: 0.7114 , train acc : 0.9965357967667436\n",
      "epoch 2050 ,Accuracy: 0.7120 , train acc : 0.9961508852963818\n",
      "epoch 2100 ,Accuracy: 0.7094 , train acc : 0.9953810623556582\n",
      "epoch 2150 ,Accuracy: 0.7158 , train acc : 0.9969207082371054\n",
      "epoch 2200 ,Accuracy: 0.7101 , train acc : 0.9973056197074672\n",
      "epoch 2250 ,Accuracy: 0.7094 , train acc : 0.9957659738260201\n",
      "epoch 2300 ,Accuracy: 0.7062 , train acc : 0.9957659738260201\n",
      "epoch 2350 ,Accuracy: 0.7101 , train acc : 0.9946112394149346\n",
      "epoch 2400 ,Accuracy: 0.7024 , train acc : 0.993841416474211\n",
      "epoch 2450 ,Accuracy: 0.7120 , train acc : 0.9969207082371054\n",
      "epoch 2500 ,Accuracy: 0.6953 , train acc : 0.968437259430331\n",
      "epoch 2550 ,Accuracy: 0.7133 , train acc : 0.9976905311778291\n",
      "epoch 2600 ,Accuracy: 0.7139 , train acc : 0.9969207082371054\n",
      "epoch 2650 ,Accuracy: 0.7139 , train acc : 0.9980754426481909\n",
      "epoch 2700 ,Accuracy: 0.7165 , train acc : 0.9992301770592764\n",
      "epoch 2750 ,Accuracy: 0.7094 , train acc : 0.9984603541185527\n",
      "epoch 2800 ,Accuracy: 0.7056 , train acc : 0.9980754426481909\n",
      "epoch 2850 ,Accuracy: 0.7101 , train acc : 0.9976905311778291\n",
      "epoch 2900 ,Accuracy: 0.7101 , train acc : 0.9965357967667436\n",
      "epoch 2950 ,Accuracy: 0.7126 , train acc : 0.9980754426481909\n",
      "Accuracy: 0.7088\n",
      "base model\n",
      "0.6266837716484926\n",
      "0.6206051614880864\n",
      "OurModel\n",
      "0.7087876844130853\n",
      "0.7035345815183335\n",
      "*****\n",
      "epoch : 8 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1899\n",
      "epoch : 100 = >  Accuracy: 0.3509\n",
      "epoch : 150 = >  Accuracy: 0.4599\n",
      "epoch : 200 = >  Accuracy: 0.5183\n",
      "epoch : 250 = >  Accuracy: 0.5362\n",
      "epoch : 300 = >  Accuracy: 0.5632\n",
      "epoch : 350 = >  Accuracy: 0.5895\n",
      "epoch : 400 = >  Accuracy: 0.5997\n",
      "epoch : 450 = >  Accuracy: 0.6139\n",
      "epoch : 500 = >  Accuracy: 0.6209\n",
      "epoch : 550 = >  Accuracy: 0.6267\n",
      "epoch : 600 = >  Accuracy: 0.6248\n",
      "epoch : 650 = >  Accuracy: 0.6280\n",
      "epoch : 700 = >  Accuracy: 0.6222\n",
      "Final accuracy: 0.6222\n",
      "epoch 0 ,Accuracy: 0.1835 , train acc : 0.19438029253271746\n",
      "epoch 50 ,Accuracy: 0.5985 , train acc : 0.7417244033872209\n",
      "epoch 100 ,Accuracy: 0.6626 , train acc : 0.8610469591993841\n",
      "epoch 150 ,Accuracy: 0.6793 , train acc : 0.8999230177059276\n",
      "epoch 200 ,Accuracy: 0.6876 , train acc : 0.9110854503464203\n",
      "epoch 250 ,Accuracy: 0.6979 , train acc : 0.9272517321016166\n",
      "epoch 300 ,Accuracy: 0.7062 , train acc : 0.9407236335642802\n",
      "epoch 350 ,Accuracy: 0.7075 , train acc : 0.949576597382602\n",
      "epoch 400 ,Accuracy: 0.6985 , train acc : 0.9553502694380293\n",
      "epoch 450 ,Accuracy: 0.6998 , train acc : 0.962278675904542\n",
      "epoch 500 ,Accuracy: 0.7049 , train acc : 0.9676674364896074\n",
      "epoch 550 ,Accuracy: 0.7081 , train acc : 0.9692070823710547\n",
      "epoch 600 ,Accuracy: 0.7158 , train acc : 0.976905311778291\n",
      "epoch 650 ,Accuracy: 0.7107 , train acc : 0.9807544264819091\n",
      "epoch 700 ,Accuracy: 0.7165 , train acc : 0.9788298691301001\n",
      "epoch 750 ,Accuracy: 0.7158 , train acc : 0.9849884526558892\n",
      "epoch 800 ,Accuracy: 0.7216 , train acc : 0.9811393379522709\n",
      "epoch 850 ,Accuracy: 0.7171 , train acc : 0.985373364126251\n",
      "epoch 900 ,Accuracy: 0.7178 , train acc : 0.9865280985373364\n",
      "epoch 950 ,Accuracy: 0.7037 , train acc : 0.9911470361816782\n",
      "epoch 1000 ,Accuracy: 0.7197 , train acc : 0.9876828329484219\n",
      "epoch 1050 ,Accuracy: 0.7126 , train acc : 0.9888375673595073\n",
      "epoch 1100 ,Accuracy: 0.7024 , train acc : 0.9896073903002309\n",
      "epoch 1150 ,Accuracy: 0.7191 , train acc : 0.9934565050038491\n",
      "epoch 1200 ,Accuracy: 0.7165 , train acc : 0.9926866820631255\n",
      "epoch 1250 ,Accuracy: 0.7069 , train acc : 0.9957659738260201\n",
      "epoch 1300 ,Accuracy: 0.7056 , train acc : 0.99153194765204\n",
      "epoch 1350 ,Accuracy: 0.7075 , train acc : 0.9903772132409546\n",
      "epoch 1400 ,Accuracy: 0.7114 , train acc : 0.9926866820631255\n",
      "epoch 1450 ,Accuracy: 0.7210 , train acc : 0.9923017705927637\n",
      "epoch 1500 ,Accuracy: 0.7229 , train acc : 0.9946112394149346\n",
      "epoch 1550 ,Accuracy: 0.7126 , train acc : 0.9965357967667436\n",
      "epoch 1600 ,Accuracy: 0.7152 , train acc : 0.9949961508852964\n",
      "epoch 1650 ,Accuracy: 0.7126 , train acc : 0.9961508852963818\n",
      "epoch 1700 ,Accuracy: 0.7133 , train acc : 0.9961508852963818\n",
      "epoch 1750 ,Accuracy: 0.7030 , train acc : 0.9923017705927637\n",
      "epoch 1800 ,Accuracy: 0.7146 , train acc : 0.9949961508852964\n",
      "epoch 1850 ,Accuracy: 0.7146 , train acc : 0.9961508852963818\n",
      "epoch 1900 ,Accuracy: 0.7088 , train acc : 0.9953810623556582\n",
      "epoch 1950 ,Accuracy: 0.7133 , train acc : 0.9961508852963818\n",
      "epoch 2000 ,Accuracy: 0.7158 , train acc : 0.9953810623556582\n",
      "epoch 2050 ,Accuracy: 0.7165 , train acc : 0.9953810623556582\n",
      "epoch 2100 ,Accuracy: 0.7158 , train acc : 0.9961508852963818\n",
      "epoch 2150 ,Accuracy: 0.7139 , train acc : 0.9961508852963818\n",
      "epoch 2200 ,Accuracy: 0.7197 , train acc : 0.9926866820631255\n",
      "epoch 2250 ,Accuracy: 0.7094 , train acc : 0.9930715935334873\n",
      "epoch 2300 ,Accuracy: 0.7184 , train acc : 0.9953810623556582\n",
      "epoch 2350 ,Accuracy: 0.7248 , train acc : 0.9965357967667436\n",
      "epoch 2400 ,Accuracy: 0.7191 , train acc : 0.9953810623556582\n",
      "epoch 2450 ,Accuracy: 0.7056 , train acc : 0.9976905311778291\n",
      "epoch 2500 ,Accuracy: 0.7075 , train acc : 0.9976905311778291\n",
      "epoch 2550 ,Accuracy: 0.7120 , train acc : 0.9973056197074672\n",
      "epoch 2600 ,Accuracy: 0.7114 , train acc : 0.9984603541185527\n",
      "epoch 2650 ,Accuracy: 0.7184 , train acc : 0.9969207082371054\n",
      "epoch 2700 ,Accuracy: 0.7069 , train acc : 0.9957659738260201\n",
      "epoch 2750 ,Accuracy: 0.7139 , train acc : 0.9976905311778291\n",
      "epoch 2800 ,Accuracy: 0.7197 , train acc : 0.9976905311778291\n",
      "epoch 2850 ,Accuracy: 0.7133 , train acc : 0.9984603541185527\n",
      "epoch 2900 ,Accuracy: 0.7261 , train acc : 0.9976905311778291\n",
      "epoch 2950 ,Accuracy: 0.7075 , train acc : 0.9934565050038491\n",
      "Accuracy: 0.7146\n",
      "base model\n",
      "0.622193713919179\n",
      "0.6151664510881171\n",
      "OurModel\n",
      "0.7145606157793457\n",
      "0.7116421094448658\n",
      "*****\n",
      "epoch : 9 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1854\n",
      "epoch : 100 = >  Accuracy: 0.3412\n",
      "epoch : 150 = >  Accuracy: 0.4522\n",
      "epoch : 200 = >  Accuracy: 0.5215\n",
      "epoch : 250 = >  Accuracy: 0.5420\n",
      "epoch : 300 = >  Accuracy: 0.5645\n",
      "epoch : 350 = >  Accuracy: 0.5831\n",
      "epoch : 400 = >  Accuracy: 0.6010\n",
      "epoch : 450 = >  Accuracy: 0.6113\n",
      "epoch : 500 = >  Accuracy: 0.6113\n",
      "epoch : 550 = >  Accuracy: 0.6158\n",
      "epoch : 600 = >  Accuracy: 0.6286\n",
      "epoch : 650 = >  Accuracy: 0.6292\n",
      "epoch : 700 = >  Accuracy: 0.6241\n",
      "Final accuracy: 0.6241\n",
      "epoch 0 ,Accuracy: 0.2547 , train acc : 0.2967667436489607\n",
      "epoch 50 ,Accuracy: 0.6286 , train acc : 0.825635103926097\n",
      "epoch 100 ,Accuracy: 0.6716 , train acc : 0.8849114703618168\n",
      "epoch 150 ,Accuracy: 0.6613 , train acc : 0.9099307159353349\n",
      "epoch 200 ,Accuracy: 0.6940 , train acc : 0.9357197844495766\n",
      "epoch 250 ,Accuracy: 0.6889 , train acc : 0.9449576597382602\n",
      "epoch 300 ,Accuracy: 0.6940 , train acc : 0.9530408006158584\n",
      "epoch 350 ,Accuracy: 0.7004 , train acc : 0.962278675904542\n",
      "epoch 400 ,Accuracy: 0.6857 , train acc : 0.955735180908391\n",
      "epoch 450 ,Accuracy: 0.7030 , train acc : 0.9676674364896074\n",
      "epoch 500 ,Accuracy: 0.6825 , train acc : 0.9657428791377983\n",
      "epoch 550 ,Accuracy: 0.6985 , train acc : 0.9757505773672055\n",
      "epoch 600 ,Accuracy: 0.6960 , train acc : 0.9765204003079292\n",
      "epoch 650 ,Accuracy: 0.7004 , train acc : 0.9807544264819091\n",
      "epoch 700 ,Accuracy: 0.7030 , train acc : 0.9872979214780601\n",
      "epoch 750 ,Accuracy: 0.7062 , train acc : 0.9888375673595073\n",
      "epoch 800 ,Accuracy: 0.6928 , train acc : 0.9884526558891455\n",
      "epoch 850 ,Accuracy: 0.6998 , train acc : 0.9919168591224018\n",
      "epoch 900 ,Accuracy: 0.6960 , train acc : 0.9911470361816782\n",
      "epoch 950 ,Accuracy: 0.6921 , train acc : 0.9884526558891455\n",
      "epoch 1000 ,Accuracy: 0.6998 , train acc : 0.9926866820631255\n",
      "epoch 1050 ,Accuracy: 0.6960 , train acc : 0.9934565050038491\n",
      "epoch 1100 ,Accuracy: 0.7056 , train acc : 0.9911470361816782\n",
      "epoch 1150 ,Accuracy: 0.7081 , train acc : 0.9934565050038491\n",
      "epoch 1200 ,Accuracy: 0.7037 , train acc : 0.9911470361816782\n",
      "epoch 1250 ,Accuracy: 0.6998 , train acc : 0.9957659738260201\n",
      "epoch 1300 ,Accuracy: 0.7024 , train acc : 0.9942263279445728\n",
      "epoch 1350 ,Accuracy: 0.6947 , train acc : 0.9934565050038491\n",
      "epoch 1400 ,Accuracy: 0.6985 , train acc : 0.9961508852963818\n",
      "epoch 1450 ,Accuracy: 0.7069 , train acc : 0.9934565050038491\n",
      "epoch 1500 ,Accuracy: 0.7017 , train acc : 0.9942263279445728\n",
      "epoch 1550 ,Accuracy: 0.6940 , train acc : 0.9980754426481909\n",
      "epoch 1600 ,Accuracy: 0.7037 , train acc : 0.9949961508852964\n",
      "epoch 1650 ,Accuracy: 0.6915 , train acc : 0.9969207082371054\n",
      "epoch 1700 ,Accuracy: 0.7037 , train acc : 0.9965357967667436\n",
      "epoch 1750 ,Accuracy: 0.6985 , train acc : 0.9961508852963818\n",
      "epoch 1800 ,Accuracy: 0.6934 , train acc : 0.9949961508852964\n",
      "epoch 1850 ,Accuracy: 0.7043 , train acc : 0.9969207082371054\n",
      "epoch 1900 ,Accuracy: 0.7011 , train acc : 0.9976905311778291\n",
      "epoch 1950 ,Accuracy: 0.7004 , train acc : 0.9965357967667436\n",
      "epoch 2000 ,Accuracy: 0.6998 , train acc : 0.9957659738260201\n",
      "epoch 2050 ,Accuracy: 0.6953 , train acc : 0.9946112394149346\n",
      "epoch 2100 ,Accuracy: 0.6972 , train acc : 0.9980754426481909\n",
      "epoch 2150 ,Accuracy: 0.6934 , train acc : 0.9961508852963818\n",
      "epoch 2200 ,Accuracy: 0.6915 , train acc : 0.9969207082371054\n",
      "epoch 2250 ,Accuracy: 0.7017 , train acc : 0.9980754426481909\n",
      "epoch 2300 ,Accuracy: 0.7043 , train acc : 0.9976905311778291\n",
      "epoch 2350 ,Accuracy: 0.6998 , train acc : 0.9957659738260201\n",
      "epoch 2400 ,Accuracy: 0.7062 , train acc : 0.9969207082371054\n",
      "epoch 2450 ,Accuracy: 0.7075 , train acc : 0.9980754426481909\n",
      "epoch 2500 ,Accuracy: 0.7056 , train acc : 0.9961508852963818\n",
      "epoch 2550 ,Accuracy: 0.7081 , train acc : 0.9969207082371054\n",
      "epoch 2600 ,Accuracy: 0.6966 , train acc : 0.9969207082371054\n",
      "epoch 2650 ,Accuracy: 0.7037 , train acc : 0.9984603541185527\n",
      "epoch 2700 ,Accuracy: 0.7011 , train acc : 0.9980754426481909\n",
      "epoch 2750 ,Accuracy: 0.7056 , train acc : 0.9992301770592764\n",
      "epoch 2800 ,Accuracy: 0.7088 , train acc : 0.9973056197074672\n",
      "epoch 2850 ,Accuracy: 0.7114 , train acc : 0.9984603541185527\n",
      "epoch 2900 ,Accuracy: 0.6998 , train acc : 0.9961508852963818\n",
      "epoch 2950 ,Accuracy: 0.6934 , train acc : 0.9869130100076983\n",
      "Accuracy: 0.6985\n",
      "base model\n",
      "0.6241180243745991\n",
      "0.6173487470462314\n",
      "OurModel\n",
      "0.6985246953175113\n",
      "0.6946114514630467\n",
      "*****\n",
      "epoch : 10 / 10\n",
      "epoch : 50 = >  Accuracy: 0.1854\n",
      "epoch : 100 = >  Accuracy: 0.3342\n",
      "epoch : 150 = >  Accuracy: 0.4471\n",
      "epoch : 200 = >  Accuracy: 0.5196\n",
      "epoch : 250 = >  Accuracy: 0.5414\n",
      "epoch : 300 = >  Accuracy: 0.5606\n",
      "epoch : 350 = >  Accuracy: 0.5818\n",
      "epoch : 400 = >  Accuracy: 0.6010\n",
      "epoch : 450 = >  Accuracy: 0.6062\n",
      "epoch : 500 = >  Accuracy: 0.6106\n",
      "epoch : 550 = >  Accuracy: 0.6209\n",
      "epoch : 600 = >  Accuracy: 0.6216\n",
      "epoch : 650 = >  Accuracy: 0.6209\n",
      "epoch : 700 = >  Accuracy: 0.6222\n",
      "Final accuracy: 0.6222\n",
      "epoch 0 ,Accuracy: 0.2630 , train acc : 0.25789068514241725\n",
      "epoch 50 ,Accuracy: 0.6369 , train acc : 0.8175519630484989\n",
      "epoch 100 ,Accuracy: 0.6716 , train acc : 0.8787528868360277\n",
      "epoch 150 ,Accuracy: 0.6735 , train acc : 0.9010777521170131\n",
      "epoch 200 ,Accuracy: 0.6812 , train acc : 0.9230177059276367\n",
      "epoch 250 ,Accuracy: 0.6908 , train acc : 0.9399538106235565\n",
      "epoch 300 ,Accuracy: 0.6985 , train acc : 0.9414934565050038\n",
      "epoch 350 ,Accuracy: 0.6902 , train acc : 0.949576597382602\n",
      "epoch 400 ,Accuracy: 0.7133 , train acc : 0.9634334103156275\n",
      "epoch 450 ,Accuracy: 0.6928 , train acc : 0.9676674364896074\n",
      "epoch 500 ,Accuracy: 0.7030 , train acc : 0.9699769053117783\n",
      "epoch 550 ,Accuracy: 0.7030 , train acc : 0.9734411085450346\n",
      "epoch 600 ,Accuracy: 0.7024 , train acc : 0.9819091608929946\n",
      "epoch 650 ,Accuracy: 0.7126 , train acc : 0.9795996920708238\n",
      "epoch 700 ,Accuracy: 0.7004 , train acc : 0.9811393379522709\n",
      "epoch 750 ,Accuracy: 0.7062 , train acc : 0.9880677444187836\n",
      "epoch 800 ,Accuracy: 0.6953 , train acc : 0.9857582755966128\n",
      "epoch 850 ,Accuracy: 0.6979 , train acc : 0.9892224788298691\n",
      "epoch 900 ,Accuracy: 0.7107 , train acc : 0.9896073903002309\n",
      "epoch 950 ,Accuracy: 0.7037 , train acc : 0.993841416474211\n",
      "epoch 1000 ,Accuracy: 0.7043 , train acc : 0.9899923017705927\n",
      "epoch 1050 ,Accuracy: 0.7114 , train acc : 0.9930715935334873\n",
      "epoch 1100 ,Accuracy: 0.6979 , train acc : 0.9911470361816782\n",
      "epoch 1150 ,Accuracy: 0.7056 , train acc : 0.9969207082371054\n",
      "epoch 1200 ,Accuracy: 0.7075 , train acc : 0.9946112394149346\n",
      "epoch 1250 ,Accuracy: 0.7017 , train acc : 0.9949961508852964\n",
      "epoch 1300 ,Accuracy: 0.7146 , train acc : 0.9949961508852964\n",
      "epoch 1350 ,Accuracy: 0.7081 , train acc : 0.993841416474211\n",
      "epoch 1400 ,Accuracy: 0.7011 , train acc : 0.9957659738260201\n",
      "epoch 1450 ,Accuracy: 0.7081 , train acc : 0.9923017705927637\n",
      "epoch 1500 ,Accuracy: 0.7017 , train acc : 0.9934565050038491\n",
      "epoch 1550 ,Accuracy: 0.7114 , train acc : 0.9934565050038491\n",
      "epoch 1600 ,Accuracy: 0.7062 , train acc : 0.9969207082371054\n",
      "epoch 1650 ,Accuracy: 0.7037 , train acc : 0.9969207082371054\n",
      "epoch 1700 ,Accuracy: 0.7081 , train acc : 0.9953810623556582\n",
      "epoch 1750 ,Accuracy: 0.7011 , train acc : 0.9946112394149346\n",
      "epoch 1800 ,Accuracy: 0.7049 , train acc : 0.9969207082371054\n",
      "epoch 1850 ,Accuracy: 0.7062 , train acc : 0.9961508852963818\n",
      "epoch 1900 ,Accuracy: 0.7004 , train acc : 0.9942263279445728\n",
      "epoch 1950 ,Accuracy: 0.7037 , train acc : 0.9980754426481909\n",
      "epoch 2000 ,Accuracy: 0.6985 , train acc : 0.9949961508852964\n",
      "epoch 2050 ,Accuracy: 0.7107 , train acc : 0.9980754426481909\n",
      "epoch 2100 ,Accuracy: 0.7069 , train acc : 0.9957659738260201\n",
      "epoch 2150 ,Accuracy: 0.7030 , train acc : 0.9961508852963818\n",
      "epoch 2200 ,Accuracy: 0.7037 , train acc : 0.9976905311778291\n",
      "epoch 2250 ,Accuracy: 0.7120 , train acc : 0.9988452655889145\n",
      "epoch 2300 ,Accuracy: 0.7107 , train acc : 0.9965357967667436\n",
      "epoch 2350 ,Accuracy: 0.7139 , train acc : 0.9973056197074672\n",
      "epoch 2400 ,Accuracy: 0.7075 , train acc : 0.9984603541185527\n",
      "epoch 2450 ,Accuracy: 0.7184 , train acc : 0.9976905311778291\n",
      "epoch 2500 ,Accuracy: 0.7107 , train acc : 0.9976905311778291\n",
      "epoch 2550 ,Accuracy: 0.7024 , train acc : 0.9976905311778291\n",
      "epoch 2600 ,Accuracy: 0.7133 , train acc : 0.9980754426481909\n",
      "epoch 2650 ,Accuracy: 0.6953 , train acc : 0.9969207082371054\n",
      "epoch 2700 ,Accuracy: 0.7107 , train acc : 0.9934565050038491\n",
      "epoch 2750 ,Accuracy: 0.7062 , train acc : 0.9980754426481909\n",
      "epoch 2800 ,Accuracy: 0.7049 , train acc : 0.9992301770592764\n",
      "epoch 2850 ,Accuracy: 0.7030 , train acc : 0.9973056197074672\n",
      "epoch 2900 ,Accuracy: 0.7062 , train acc : 0.9976905311778291\n",
      "epoch 2950 ,Accuracy: 0.6998 , train acc : 0.9961508852963818\n",
      "Accuracy: 0.7101\n",
      "base model\n",
      "0.622193713919179\n",
      "0.6142798115752491\n",
      "OurModel\n",
      "0.710070558050032\n",
      "0.7053608211311042\n",
      "+++***Fianal Result***+++\n",
      "base\n",
      "Accuracy avg = 0.622963438101347\n",
      "Accuracy deviation = 0.0033644025251692924\n",
      "F1 score(macro) avg = 0.6161523595289631\n",
      "F1 score(macro) deviation = 0.0037226812590092436\n",
      "new model\n",
      "Accuracy avg = 0.7094291212315587\n",
      "Accuracy deviation = 0.008119237778938415\n",
      "F1 score(macro) avg = 0.7057436153240367\n",
      "F1 score(macro) deviation = 0.007864775031883693\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "GNN_model = GAT(dataset.num_features, dataset.num_classes, embedding_dimension=8).to(device)\n",
    "run_model(GNN_model , Gnn_epochs=700 ,enc_address=\"encoder_emb_BlogCatalog64.pt\" ,reply_threshold=0.85 , head_epochs= 3000 , validation_mask=new_valdation_mask , early_stop=0.88 )"
   ],
   "metadata": {
    "id": "lg25po_KxXzF",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "f5e5c91d-074e-4235-973e-5a7970f47914"
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "epoch : 1 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2303\n",
      "epoch : 100 = >  Accuracy: 0.3695\n",
      "epoch : 150 = >  Accuracy: 0.4362\n",
      "epoch : 200 = >  Accuracy: 0.4638\n",
      "epoch : 250 = >  Accuracy: 0.4843\n",
      "epoch : 300 = >  Accuracy: 0.5093\n",
      "epoch : 350 = >  Accuracy: 0.5292\n",
      "epoch : 400 = >  Accuracy: 0.5414\n",
      "epoch : 450 = >  Accuracy: 0.5523\n",
      "epoch : 500 = >  Accuracy: 0.5638\n",
      "epoch : 550 = >  Accuracy: 0.5722\n",
      "epoch : 600 = >  Accuracy: 0.5863\n",
      "epoch : 650 = >  Accuracy: 0.5831\n",
      "epoch : 700 = >  Accuracy: 0.5888\n",
      "Final accuracy: 0.5888\n",
      "epoch 0 ,Accuracy: 0.2373 , train acc : 0.24595842956120093\n",
      "epoch 50 ,Accuracy: 0.5555 , train acc : 0.6354888375673595\n",
      "epoch 100 ,Accuracy: 0.6722 , train acc : 0.8029253271747498\n",
      "epoch 150 ,Accuracy: 0.7017 , train acc : 0.8406466512702079\n",
      "epoch 200 ,Accuracy: 0.7171 , train acc : 0.8683602771362586\n",
      "epoch 250 ,Accuracy: 0.7229 , train acc : 0.8899153194765204\n",
      "epoch 300 ,Accuracy: 0.7191 , train acc : 0.8987682832948422\n",
      "epoch 350 ,Accuracy: 0.7126 , train acc : 0.9145496535796767\n",
      "epoch 400 ,Accuracy: 0.7255 , train acc : 0.9295612009237876\n",
      "epoch 450 ,Accuracy: 0.7191 , train acc : 0.9361046959199384\n",
      "epoch 500 ,Accuracy: 0.7261 , train acc : 0.9430331023864511\n",
      "epoch 550 ,Accuracy: 0.7126 , train acc : 0.949576597382602\n",
      "epoch 600 ,Accuracy: 0.7203 , train acc : 0.9507313317936874\n",
      "epoch 650 ,Accuracy: 0.7274 , train acc : 0.968437259430331\n",
      "epoch 700 ,Accuracy: 0.7133 , train acc : 0.9688221709006929\n",
      "epoch 750 ,Accuracy: 0.7165 , train acc : 0.9692070823710547\n",
      "epoch 800 ,Accuracy: 0.7235 , train acc : 0.9742109314857583\n",
      "epoch 850 ,Accuracy: 0.7158 , train acc : 0.9811393379522709\n",
      "epoch 900 ,Accuracy: 0.7223 , train acc : 0.9784449576597383\n",
      "epoch 950 ,Accuracy: 0.7261 , train acc : 0.9822940723633564\n",
      "epoch 1000 ,Accuracy: 0.7287 , train acc : 0.9834488067744419\n",
      "epoch 1050 ,Accuracy: 0.7114 , train acc : 0.9849884526558892\n",
      "epoch 1100 ,Accuracy: 0.7223 , train acc : 0.9834488067744419\n",
      "epoch 1150 ,Accuracy: 0.7146 , train acc : 0.9899923017705927\n",
      "epoch 1200 ,Accuracy: 0.7184 , train acc : 0.9869130100076983\n",
      "epoch 1250 ,Accuracy: 0.7203 , train acc : 0.9880677444187836\n",
      "epoch 1300 ,Accuracy: 0.7197 , train acc : 0.9896073903002309\n",
      "epoch 1350 ,Accuracy: 0.7229 , train acc : 0.9919168591224018\n",
      "epoch 1400 ,Accuracy: 0.7223 , train acc : 0.9872979214780601\n",
      "epoch 1450 ,Accuracy: 0.7229 , train acc : 0.9930715935334873\n",
      "epoch 1500 ,Accuracy: 0.7235 , train acc : 0.9896073903002309\n",
      "epoch 1550 ,Accuracy: 0.7178 , train acc : 0.9892224788298691\n",
      "epoch 1600 ,Accuracy: 0.7178 , train acc : 0.9899923017705927\n",
      "epoch 1650 ,Accuracy: 0.7255 , train acc : 0.9919168591224018\n",
      "epoch 1700 ,Accuracy: 0.7203 , train acc : 0.9903772132409546\n",
      "epoch 1750 ,Accuracy: 0.7216 , train acc : 0.9953810623556582\n",
      "epoch 1800 ,Accuracy: 0.7255 , train acc : 0.9953810623556582\n",
      "epoch 1850 ,Accuracy: 0.7344 , train acc : 0.9953810623556582\n",
      "epoch 1900 ,Accuracy: 0.7165 , train acc : 0.9903772132409546\n",
      "epoch 1950 ,Accuracy: 0.7158 , train acc : 0.9930715935334873\n",
      "epoch 2000 ,Accuracy: 0.7229 , train acc : 0.9934565050038491\n",
      "epoch 2050 ,Accuracy: 0.7107 , train acc : 0.993841416474211\n",
      "epoch 2100 ,Accuracy: 0.7158 , train acc : 0.9953810623556582\n",
      "epoch 2150 ,Accuracy: 0.7255 , train acc : 0.9934565050038491\n",
      "epoch 2200 ,Accuracy: 0.7184 , train acc : 0.993841416474211\n",
      "epoch 2250 ,Accuracy: 0.7255 , train acc : 0.9949961508852964\n",
      "epoch 2300 ,Accuracy: 0.7171 , train acc : 0.9965357967667436\n",
      "epoch 2350 ,Accuracy: 0.7306 , train acc : 0.9930715935334873\n",
      "epoch 2400 ,Accuracy: 0.7242 , train acc : 0.9946112394149346\n",
      "epoch 2450 ,Accuracy: 0.7242 , train acc : 0.9949961508852964\n",
      "epoch 2500 ,Accuracy: 0.7261 , train acc : 0.9942263279445728\n",
      "epoch 2550 ,Accuracy: 0.7197 , train acc : 0.9942263279445728\n",
      "epoch 2600 ,Accuracy: 0.7248 , train acc : 0.9946112394149346\n",
      "epoch 2650 ,Accuracy: 0.7261 , train acc : 0.9946112394149346\n",
      "epoch 2700 ,Accuracy: 0.7146 , train acc : 0.9934565050038491\n",
      "epoch 2750 ,Accuracy: 0.7210 , train acc : 0.9961508852963818\n",
      "epoch 2800 ,Accuracy: 0.7171 , train acc : 0.9949961508852964\n",
      "epoch 2850 ,Accuracy: 0.7178 , train acc : 0.9961508852963818\n",
      "epoch 2900 ,Accuracy: 0.7235 , train acc : 0.9949961508852964\n",
      "epoch 2950 ,Accuracy: 0.7274 , train acc : 0.9942263279445728\n",
      "Accuracy: 0.7216\n",
      "base model\n",
      "0.5888389993585632\n",
      "0.5815111591320771\n",
      "OurModel\n",
      "0.721616420782553\n",
      "0.7124064743907156\n",
      "*****\n",
      "epoch : 2 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2181\n",
      "epoch : 100 = >  Accuracy: 0.3528\n",
      "epoch : 150 = >  Accuracy: 0.4477\n",
      "epoch : 200 = >  Accuracy: 0.4631\n",
      "epoch : 250 = >  Accuracy: 0.4772\n",
      "epoch : 300 = >  Accuracy: 0.5048\n",
      "epoch : 350 = >  Accuracy: 0.5228\n",
      "epoch : 400 = >  Accuracy: 0.5330\n",
      "epoch : 450 = >  Accuracy: 0.5504\n",
      "epoch : 500 = >  Accuracy: 0.5625\n",
      "epoch : 550 = >  Accuracy: 0.5696\n",
      "epoch : 600 = >  Accuracy: 0.5805\n",
      "epoch : 650 = >  Accuracy: 0.5953\n",
      "epoch : 700 = >  Accuracy: 0.5997\n",
      "Final accuracy: 0.5997\n",
      "epoch 0 ,Accuracy: 0.2322 , train acc : 0.25096227867590454\n",
      "epoch 50 ,Accuracy: 0.6543 , train acc : 0.7382602001539645\n",
      "epoch 100 ,Accuracy: 0.6857 , train acc : 0.8113933795227097\n",
      "epoch 150 ,Accuracy: 0.7094 , train acc : 0.8371824480369515\n",
      "epoch 200 ,Accuracy: 0.7267 , train acc : 0.8645111624326405\n",
      "epoch 250 ,Accuracy: 0.7274 , train acc : 0.8868360277136259\n",
      "epoch 300 ,Accuracy: 0.7165 , train acc : 0.8972286374133949\n",
      "epoch 350 ,Accuracy: 0.7287 , train acc : 0.911855273287144\n",
      "epoch 400 ,Accuracy: 0.7319 , train acc : 0.918013856812933\n",
      "epoch 450 ,Accuracy: 0.7229 , train acc : 0.9272517321016166\n",
      "epoch 500 ,Accuracy: 0.7235 , train acc : 0.9395688991531947\n",
      "epoch 550 ,Accuracy: 0.7229 , train acc : 0.9530408006158584\n",
      "epoch 600 ,Accuracy: 0.7248 , train acc : 0.9572748267898383\n",
      "epoch 650 ,Accuracy: 0.7242 , train acc : 0.9626635873749038\n",
      "epoch 700 ,Accuracy: 0.7300 , train acc : 0.9638183217859893\n",
      "epoch 750 ,Accuracy: 0.7133 , train acc : 0.9672825250192456\n",
      "epoch 800 ,Accuracy: 0.7312 , train acc : 0.968437259430331\n",
      "epoch 850 ,Accuracy: 0.7287 , train acc : 0.9761354888375674\n",
      "epoch 900 ,Accuracy: 0.7261 , train acc : 0.9780600461893765\n",
      "epoch 950 ,Accuracy: 0.7165 , train acc : 0.9711316397228638\n",
      "epoch 1000 ,Accuracy: 0.7287 , train acc : 0.9772902232486528\n",
      "epoch 1050 ,Accuracy: 0.7216 , train acc : 0.9776751347190146\n",
      "epoch 1100 ,Accuracy: 0.7184 , train acc : 0.9842186297151655\n",
      "epoch 1150 ,Accuracy: 0.7300 , train acc : 0.9838337182448037\n",
      "epoch 1200 ,Accuracy: 0.7229 , train acc : 0.9846035411855273\n",
      "epoch 1250 ,Accuracy: 0.7280 , train acc : 0.9861431870669746\n",
      "epoch 1300 ,Accuracy: 0.7203 , train acc : 0.9822940723633564\n",
      "epoch 1350 ,Accuracy: 0.7081 , train acc : 0.9857582755966128\n",
      "epoch 1400 ,Accuracy: 0.7261 , train acc : 0.9861431870669746\n",
      "epoch 1450 ,Accuracy: 0.7242 , train acc : 0.9872979214780601\n",
      "epoch 1500 ,Accuracy: 0.7184 , train acc : 0.9857582755966128\n",
      "epoch 1550 ,Accuracy: 0.7248 , train acc : 0.9911470361816782\n",
      "epoch 1600 ,Accuracy: 0.7184 , train acc : 0.9907621247113164\n",
      "epoch 1650 ,Accuracy: 0.7210 , train acc : 0.9903772132409546\n",
      "epoch 1700 ,Accuracy: 0.7171 , train acc : 0.9884526558891455\n",
      "epoch 1750 ,Accuracy: 0.7229 , train acc : 0.9903772132409546\n",
      "epoch 1800 ,Accuracy: 0.7094 , train acc : 0.993841416474211\n",
      "epoch 1850 ,Accuracy: 0.7210 , train acc : 0.99153194765204\n",
      "epoch 1900 ,Accuracy: 0.7171 , train acc : 0.9923017705927637\n",
      "epoch 1950 ,Accuracy: 0.7351 , train acc : 0.9919168591224018\n",
      "epoch 2000 ,Accuracy: 0.7191 , train acc : 0.9907621247113164\n",
      "epoch 2050 ,Accuracy: 0.7152 , train acc : 0.99153194765204\n",
      "epoch 2100 ,Accuracy: 0.7184 , train acc : 0.9907621247113164\n",
      "epoch 2150 ,Accuracy: 0.7261 , train acc : 0.9926866820631255\n",
      "epoch 2200 ,Accuracy: 0.7210 , train acc : 0.9942263279445728\n",
      "epoch 2250 ,Accuracy: 0.7255 , train acc : 0.9919168591224018\n",
      "epoch 2300 ,Accuracy: 0.7300 , train acc : 0.9930715935334873\n",
      "epoch 2350 ,Accuracy: 0.7178 , train acc : 0.9949961508852964\n",
      "epoch 2400 ,Accuracy: 0.7184 , train acc : 0.9949961508852964\n",
      "epoch 2450 ,Accuracy: 0.7300 , train acc : 0.993841416474211\n",
      "epoch 2500 ,Accuracy: 0.7171 , train acc : 0.9961508852963818\n",
      "epoch 2550 ,Accuracy: 0.7274 , train acc : 0.9969207082371054\n",
      "epoch 2600 ,Accuracy: 0.7146 , train acc : 0.9957659738260201\n",
      "epoch 2650 ,Accuracy: 0.7255 , train acc : 0.9946112394149346\n",
      "epoch 2700 ,Accuracy: 0.7293 , train acc : 0.9961508852963818\n",
      "epoch 2750 ,Accuracy: 0.7216 , train acc : 0.9957659738260201\n",
      "epoch 2800 ,Accuracy: 0.7229 , train acc : 0.9980754426481909\n",
      "epoch 2850 ,Accuracy: 0.7274 , train acc : 0.9949961508852964\n",
      "epoch 2900 ,Accuracy: 0.7261 , train acc : 0.9976905311778291\n",
      "epoch 2950 ,Accuracy: 0.7210 , train acc : 0.9961508852963818\n",
      "Accuracy: 0.7133\n",
      "base model\n",
      "0.5997434252726106\n",
      "0.5905034697197611\n",
      "OurModel\n",
      "0.7132777421423989\n",
      "0.7074416460668135\n",
      "*****\n",
      "epoch : 3 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2162\n",
      "epoch : 100 = >  Accuracy: 0.3598\n",
      "epoch : 150 = >  Accuracy: 0.4484\n",
      "epoch : 200 = >  Accuracy: 0.4695\n",
      "epoch : 250 = >  Accuracy: 0.4913\n",
      "epoch : 300 = >  Accuracy: 0.5112\n",
      "epoch : 350 = >  Accuracy: 0.5273\n",
      "epoch : 400 = >  Accuracy: 0.5414\n",
      "epoch : 450 = >  Accuracy: 0.5465\n",
      "epoch : 500 = >  Accuracy: 0.5548\n",
      "epoch : 550 = >  Accuracy: 0.5657\n",
      "epoch : 600 = >  Accuracy: 0.5683\n",
      "epoch : 650 = >  Accuracy: 0.5779\n",
      "epoch : 700 = >  Accuracy: 0.5882\n",
      "Final accuracy: 0.5882\n",
      "epoch 0 ,Accuracy: 0.2598 , train acc : 0.2363356428021555\n",
      "epoch 50 ,Accuracy: 0.6459 , train acc : 0.7444187836797537\n",
      "epoch 100 ,Accuracy: 0.6684 , train acc : 0.8102386451116244\n",
      "epoch 150 ,Accuracy: 0.7075 , train acc : 0.848729792147806\n",
      "epoch 200 ,Accuracy: 0.7120 , train acc : 0.8672055427251733\n",
      "epoch 250 ,Accuracy: 0.7178 , train acc : 0.8922247882986913\n",
      "epoch 300 ,Accuracy: 0.7261 , train acc : 0.9003079291762894\n",
      "epoch 350 ,Accuracy: 0.7178 , train acc : 0.9026173979984603\n",
      "epoch 400 ,Accuracy: 0.7293 , train acc : 0.9260969976905312\n",
      "epoch 450 ,Accuracy: 0.7165 , train acc : 0.9295612009237876\n",
      "epoch 500 ,Accuracy: 0.7255 , train acc : 0.9414934565050038\n",
      "epoch 550 ,Accuracy: 0.7409 , train acc : 0.9491916859122402\n",
      "epoch 600 ,Accuracy: 0.7158 , train acc : 0.9603541185527329\n",
      "epoch 650 ,Accuracy: 0.7293 , train acc : 0.9541955350269438\n",
      "epoch 700 ,Accuracy: 0.7389 , train acc : 0.9680523479599692\n",
      "epoch 750 ,Accuracy: 0.7248 , train acc : 0.968437259430331\n",
      "epoch 800 ,Accuracy: 0.7197 , train acc : 0.9672825250192456\n",
      "epoch 850 ,Accuracy: 0.7197 , train acc : 0.9757505773672055\n",
      "epoch 900 ,Accuracy: 0.7229 , train acc : 0.9784449576597383\n",
      "epoch 950 ,Accuracy: 0.7274 , train acc : 0.9795996920708238\n",
      "epoch 1000 ,Accuracy: 0.7267 , train acc : 0.9788298691301001\n",
      "epoch 1050 ,Accuracy: 0.7377 , train acc : 0.9819091608929946\n",
      "epoch 1100 ,Accuracy: 0.7344 , train acc : 0.9842186297151655\n",
      "epoch 1150 ,Accuracy: 0.7216 , train acc : 0.9869130100076983\n",
      "epoch 1200 ,Accuracy: 0.7325 , train acc : 0.9842186297151655\n",
      "epoch 1250 ,Accuracy: 0.7210 , train acc : 0.985373364126251\n",
      "epoch 1300 ,Accuracy: 0.7319 , train acc : 0.9876828329484219\n",
      "epoch 1350 ,Accuracy: 0.7267 , train acc : 0.9896073903002309\n",
      "epoch 1400 ,Accuracy: 0.7267 , train acc : 0.9892224788298691\n",
      "epoch 1450 ,Accuracy: 0.7248 , train acc : 0.9923017705927637\n",
      "epoch 1500 ,Accuracy: 0.7223 , train acc : 0.9892224788298691\n",
      "epoch 1550 ,Accuracy: 0.7261 , train acc : 0.9923017705927637\n",
      "epoch 1600 ,Accuracy: 0.7248 , train acc : 0.9923017705927637\n",
      "epoch 1650 ,Accuracy: 0.7223 , train acc : 0.9896073903002309\n",
      "epoch 1700 ,Accuracy: 0.7235 , train acc : 0.9942263279445728\n",
      "epoch 1750 ,Accuracy: 0.7184 , train acc : 0.9934565050038491\n",
      "epoch 1800 ,Accuracy: 0.7197 , train acc : 0.9926866820631255\n",
      "epoch 1850 ,Accuracy: 0.7184 , train acc : 0.9903772132409546\n",
      "epoch 1900 ,Accuracy: 0.7203 , train acc : 0.9969207082371054\n",
      "epoch 1950 ,Accuracy: 0.7229 , train acc : 0.9930715935334873\n",
      "epoch 2000 ,Accuracy: 0.7267 , train acc : 0.9923017705927637\n",
      "epoch 2050 ,Accuracy: 0.7203 , train acc : 0.9949961508852964\n",
      "epoch 2100 ,Accuracy: 0.7280 , train acc : 0.9942263279445728\n",
      "epoch 2150 ,Accuracy: 0.7280 , train acc : 0.9953810623556582\n",
      "epoch 2200 ,Accuracy: 0.7191 , train acc : 0.9957659738260201\n",
      "epoch 2250 ,Accuracy: 0.7235 , train acc : 0.9942263279445728\n",
      "epoch 2300 ,Accuracy: 0.7287 , train acc : 0.9969207082371054\n",
      "epoch 2350 ,Accuracy: 0.7216 , train acc : 0.9953810623556582\n",
      "epoch 2400 ,Accuracy: 0.7165 , train acc : 0.993841416474211\n",
      "epoch 2450 ,Accuracy: 0.7274 , train acc : 0.9953810623556582\n",
      "epoch 2500 ,Accuracy: 0.7280 , train acc : 0.9957659738260201\n",
      "epoch 2550 ,Accuracy: 0.7223 , train acc : 0.9949961508852964\n",
      "epoch 2600 ,Accuracy: 0.7203 , train acc : 0.9953810623556582\n",
      "epoch 2650 ,Accuracy: 0.7191 , train acc : 0.9949961508852964\n",
      "epoch 2700 ,Accuracy: 0.7255 , train acc : 0.9984603541185527\n",
      "epoch 2750 ,Accuracy: 0.7152 , train acc : 0.9953810623556582\n",
      "epoch 2800 ,Accuracy: 0.7158 , train acc : 0.9969207082371054\n",
      "epoch 2850 ,Accuracy: 0.7293 , train acc : 0.9984603541185527\n",
      "epoch 2900 ,Accuracy: 0.7191 , train acc : 0.9965357967667436\n",
      "epoch 2950 ,Accuracy: 0.7255 , train acc : 0.9957659738260201\n",
      "Accuracy: 0.7280\n",
      "base model\n",
      "0.5881975625400898\n",
      "0.5781743977546819\n",
      "OurModel\n",
      "0.7280307889672867\n",
      "0.7207468738325972\n",
      "*****\n",
      "epoch : 4 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2162\n",
      "epoch : 100 = >  Accuracy: 0.3643\n",
      "epoch : 150 = >  Accuracy: 0.4471\n",
      "epoch : 200 = >  Accuracy: 0.4727\n",
      "epoch : 250 = >  Accuracy: 0.4971\n",
      "epoch : 300 = >  Accuracy: 0.5202\n",
      "epoch : 350 = >  Accuracy: 0.5324\n",
      "epoch : 400 = >  Accuracy: 0.5433\n",
      "epoch : 450 = >  Accuracy: 0.5491\n",
      "epoch : 500 = >  Accuracy: 0.5536\n",
      "epoch : 550 = >  Accuracy: 0.5645\n",
      "epoch : 600 = >  Accuracy: 0.5786\n",
      "epoch : 650 = >  Accuracy: 0.5856\n",
      "epoch : 700 = >  Accuracy: 0.5895\n",
      "Final accuracy: 0.5895\n",
      "epoch 0 ,Accuracy: 0.2168 , train acc : 0.2066974595842956\n",
      "epoch 50 ,Accuracy: 0.6248 , train acc : 0.7174749807544265\n",
      "epoch 100 ,Accuracy: 0.6786 , train acc : 0.8044649730561971\n",
      "epoch 150 ,Accuracy: 0.6889 , train acc : 0.8452655889145496\n",
      "epoch 200 ,Accuracy: 0.7043 , train acc : 0.865665896843726\n",
      "epoch 250 ,Accuracy: 0.7191 , train acc : 0.888760585065435\n",
      "epoch 300 ,Accuracy: 0.7223 , train acc : 0.894919168591224\n",
      "epoch 350 ,Accuracy: 0.7178 , train acc : 0.9083910700538876\n",
      "epoch 400 ,Accuracy: 0.7216 , train acc : 0.9214780600461894\n",
      "epoch 450 ,Accuracy: 0.7293 , train acc : 0.9330254041570438\n",
      "epoch 500 ,Accuracy: 0.7158 , train acc : 0.9441878367975366\n",
      "epoch 550 ,Accuracy: 0.7223 , train acc : 0.9511162432640493\n",
      "epoch 600 ,Accuracy: 0.7248 , train acc : 0.9522709776751347\n",
      "epoch 650 ,Accuracy: 0.7146 , train acc : 0.9518860662047729\n",
      "epoch 700 ,Accuracy: 0.7171 , train acc : 0.962278675904542\n",
      "epoch 750 ,Accuracy: 0.7101 , train acc : 0.9626635873749038\n",
      "epoch 800 ,Accuracy: 0.7152 , train acc : 0.9719014626635873\n",
      "epoch 850 ,Accuracy: 0.7191 , train acc : 0.9711316397228638\n",
      "epoch 900 ,Accuracy: 0.7191 , train acc : 0.9738260200153964\n",
      "epoch 950 ,Accuracy: 0.7216 , train acc : 0.9784449576597383\n",
      "epoch 1000 ,Accuracy: 0.7152 , train acc : 0.9788298691301001\n",
      "epoch 1050 ,Accuracy: 0.7146 , train acc : 0.9830638953040801\n",
      "epoch 1100 ,Accuracy: 0.7178 , train acc : 0.9838337182448037\n",
      "epoch 1150 ,Accuracy: 0.7165 , train acc : 0.9861431870669746\n",
      "epoch 1200 ,Accuracy: 0.7133 , train acc : 0.9869130100076983\n",
      "epoch 1250 ,Accuracy: 0.7203 , train acc : 0.9876828329484219\n",
      "epoch 1300 ,Accuracy: 0.7267 , train acc : 0.9876828329484219\n",
      "epoch 1350 ,Accuracy: 0.7235 , train acc : 0.9880677444187836\n",
      "epoch 1400 ,Accuracy: 0.7133 , train acc : 0.9892224788298691\n",
      "epoch 1450 ,Accuracy: 0.7133 , train acc : 0.9907621247113164\n",
      "epoch 1500 ,Accuracy: 0.7191 , train acc : 0.9876828329484219\n",
      "epoch 1550 ,Accuracy: 0.7255 , train acc : 0.9907621247113164\n",
      "epoch 1600 ,Accuracy: 0.7242 , train acc : 0.9911470361816782\n",
      "epoch 1650 ,Accuracy: 0.7152 , train acc : 0.9872979214780601\n",
      "epoch 1700 ,Accuracy: 0.7126 , train acc : 0.9907621247113164\n",
      "epoch 1750 ,Accuracy: 0.7197 , train acc : 0.993841416474211\n",
      "epoch 1800 ,Accuracy: 0.7152 , train acc : 0.9965357967667436\n",
      "epoch 1850 ,Accuracy: 0.7178 , train acc : 0.993841416474211\n",
      "epoch 1900 ,Accuracy: 0.7197 , train acc : 0.9876828329484219\n",
      "epoch 1950 ,Accuracy: 0.7126 , train acc : 0.9934565050038491\n",
      "epoch 2000 ,Accuracy: 0.7158 , train acc : 0.9923017705927637\n",
      "epoch 2050 ,Accuracy: 0.7223 , train acc : 0.9923017705927637\n",
      "epoch 2100 ,Accuracy: 0.7146 , train acc : 0.9934565050038491\n",
      "epoch 2150 ,Accuracy: 0.7261 , train acc : 0.9926866820631255\n",
      "epoch 2200 ,Accuracy: 0.7229 , train acc : 0.9907621247113164\n",
      "epoch 2250 ,Accuracy: 0.7255 , train acc : 0.9961508852963818\n",
      "epoch 2300 ,Accuracy: 0.7107 , train acc : 0.9969207082371054\n",
      "epoch 2350 ,Accuracy: 0.7171 , train acc : 0.9946112394149346\n",
      "epoch 2400 ,Accuracy: 0.7210 , train acc : 0.9969207082371054\n",
      "epoch 2450 ,Accuracy: 0.7114 , train acc : 0.9973056197074672\n",
      "epoch 2500 ,Accuracy: 0.7178 , train acc : 0.9934565050038491\n",
      "epoch 2550 ,Accuracy: 0.7152 , train acc : 0.9976905311778291\n",
      "epoch 2600 ,Accuracy: 0.7191 , train acc : 0.9953810623556582\n",
      "epoch 2650 ,Accuracy: 0.7223 , train acc : 0.9953810623556582\n",
      "epoch 2700 ,Accuracy: 0.7235 , train acc : 0.993841416474211\n",
      "epoch 2750 ,Accuracy: 0.7223 , train acc : 0.9961508852963818\n",
      "epoch 2800 ,Accuracy: 0.7287 , train acc : 0.9961508852963818\n",
      "epoch 2850 ,Accuracy: 0.7248 , train acc : 0.9973056197074672\n",
      "epoch 2900 ,Accuracy: 0.7191 , train acc : 0.9953810623556582\n",
      "epoch 2950 ,Accuracy: 0.7229 , train acc : 0.9969207082371054\n",
      "Accuracy: 0.7255\n",
      "base model\n",
      "0.5894804361770366\n",
      "0.5816134409416853\n",
      "OurModel\n",
      "0.7254650416933932\n",
      "0.719272709439291\n",
      "*****\n",
      "epoch : 5 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2149\n",
      "epoch : 100 = >  Accuracy: 0.3669\n",
      "epoch : 150 = >  Accuracy: 0.4419\n",
      "epoch : 200 = >  Accuracy: 0.4650\n",
      "epoch : 250 = >  Accuracy: 0.4830\n",
      "epoch : 300 = >  Accuracy: 0.5099\n",
      "epoch : 350 = >  Accuracy: 0.5350\n",
      "epoch : 400 = >  Accuracy: 0.5433\n",
      "epoch : 450 = >  Accuracy: 0.5414\n",
      "epoch : 500 = >  Accuracy: 0.5581\n",
      "epoch : 550 = >  Accuracy: 0.5619\n",
      "epoch : 600 = >  Accuracy: 0.5683\n",
      "epoch : 650 = >  Accuracy: 0.5792\n",
      "epoch : 700 = >  Accuracy: 0.5876\n",
      "Final accuracy: 0.5876\n",
      "epoch 0 ,Accuracy: 0.2232 , train acc : 0.2294072363356428\n",
      "epoch 50 ,Accuracy: 0.5292 , train acc : 0.6250962278675904\n",
      "epoch 100 ,Accuracy: 0.6466 , train acc : 0.7744418783679754\n",
      "epoch 150 ,Accuracy: 0.6716 , train acc : 0.815242494226328\n",
      "epoch 200 ,Accuracy: 0.6793 , train acc : 0.8333333333333334\n",
      "epoch 250 ,Accuracy: 0.6928 , train acc : 0.8641262509622787\n",
      "epoch 300 ,Accuracy: 0.7049 , train acc : 0.886451116243264\n",
      "epoch 350 ,Accuracy: 0.7030 , train acc : 0.8914549653579676\n",
      "epoch 400 ,Accuracy: 0.7024 , train acc : 0.8964588144726713\n",
      "epoch 450 ,Accuracy: 0.7081 , train acc : 0.909545804464973\n",
      "epoch 500 ,Accuracy: 0.7069 , train acc : 0.9110854503464203\n",
      "epoch 550 ,Accuracy: 0.7107 , train acc : 0.9268668206312548\n",
      "epoch 600 ,Accuracy: 0.7081 , train acc : 0.9260969976905312\n",
      "epoch 650 ,Accuracy: 0.7011 , train acc : 0.9361046959199384\n",
      "epoch 700 ,Accuracy: 0.7094 , train acc : 0.934949961508853\n",
      "epoch 750 ,Accuracy: 0.7069 , train acc : 0.9418783679753656\n",
      "epoch 800 ,Accuracy: 0.7114 , train acc : 0.9407236335642802\n",
      "epoch 850 ,Accuracy: 0.7203 , train acc : 0.949576597382602\n",
      "epoch 900 ,Accuracy: 0.7069 , train acc : 0.9518860662047729\n",
      "epoch 950 ,Accuracy: 0.7171 , train acc : 0.9545804464973057\n",
      "epoch 1000 ,Accuracy: 0.7267 , train acc : 0.9588144726712856\n",
      "epoch 1050 ,Accuracy: 0.7178 , train acc : 0.9611239414934565\n",
      "epoch 1100 ,Accuracy: 0.7139 , train acc : 0.9649730561970746\n",
      "epoch 1150 ,Accuracy: 0.7178 , train acc : 0.9591993841416474\n",
      "epoch 1200 ,Accuracy: 0.7178 , train acc : 0.9668976135488837\n",
      "epoch 1250 ,Accuracy: 0.7178 , train acc : 0.9688221709006929\n",
      "epoch 1300 ,Accuracy: 0.7133 , train acc : 0.968437259430331\n",
      "epoch 1350 ,Accuracy: 0.7235 , train acc : 0.9668976135488837\n",
      "epoch 1400 ,Accuracy: 0.7152 , train acc : 0.9703618167821401\n",
      "epoch 1450 ,Accuracy: 0.7210 , train acc : 0.9772902232486528\n",
      "epoch 1500 ,Accuracy: 0.7152 , train acc : 0.9703618167821401\n",
      "epoch 1550 ,Accuracy: 0.7184 , train acc : 0.9749807544264819\n",
      "epoch 1600 ,Accuracy: 0.7158 , train acc : 0.9757505773672055\n",
      "epoch 1650 ,Accuracy: 0.7210 , train acc : 0.976905311778291\n",
      "epoch 1700 ,Accuracy: 0.7242 , train acc : 0.9776751347190146\n",
      "epoch 1750 ,Accuracy: 0.7242 , train acc : 0.9745958429561201\n",
      "epoch 1800 ,Accuracy: 0.7223 , train acc : 0.9688221709006929\n",
      "epoch 1850 ,Accuracy: 0.7229 , train acc : 0.9749807544264819\n",
      "epoch 1900 ,Accuracy: 0.7255 , train acc : 0.9795996920708238\n",
      "epoch 1950 ,Accuracy: 0.7191 , train acc : 0.9803695150115473\n",
      "epoch 2000 ,Accuracy: 0.7197 , train acc : 0.9807544264819091\n",
      "epoch 2050 ,Accuracy: 0.7293 , train acc : 0.9795996920708238\n",
      "epoch 2100 ,Accuracy: 0.7216 , train acc : 0.9776751347190146\n",
      "epoch 2150 ,Accuracy: 0.7165 , train acc : 0.9780600461893765\n",
      "epoch 2200 ,Accuracy: 0.7223 , train acc : 0.9734411085450346\n",
      "epoch 2250 ,Accuracy: 0.7229 , train acc : 0.9788298691301001\n",
      "epoch 2300 ,Accuracy: 0.7184 , train acc : 0.9799846035411856\n",
      "epoch 2350 ,Accuracy: 0.7293 , train acc : 0.9846035411855273\n",
      "epoch 2400 ,Accuracy: 0.7351 , train acc : 0.9834488067744419\n",
      "epoch 2450 ,Accuracy: 0.7338 , train acc : 0.9826789838337182\n",
      "epoch 2500 ,Accuracy: 0.7184 , train acc : 0.9865280985373364\n",
      "epoch 2550 ,Accuracy: 0.7158 , train acc : 0.9803695150115473\n",
      "epoch 2600 ,Accuracy: 0.7171 , train acc : 0.9857582755966128\n",
      "epoch 2650 ,Accuracy: 0.7216 , train acc : 0.9869130100076983\n",
      "epoch 2700 ,Accuracy: 0.7280 , train acc : 0.9846035411855273\n",
      "epoch 2750 ,Accuracy: 0.7197 , train acc : 0.9899923017705927\n",
      "epoch 2800 ,Accuracy: 0.7171 , train acc : 0.9880677444187836\n",
      "epoch 2850 ,Accuracy: 0.7210 , train acc : 0.9903772132409546\n",
      "epoch 2900 ,Accuracy: 0.7191 , train acc : 0.9872979214780601\n",
      "epoch 2950 ,Accuracy: 0.7178 , train acc : 0.9892224788298691\n",
      "Accuracy: 0.7312\n",
      "base model\n",
      "0.5875561257216164\n",
      "0.5796729546662452\n",
      "OurModel\n",
      "0.7312379730596537\n",
      "0.7251557974687328\n",
      "*****\n",
      "epoch : 6 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2290\n",
      "epoch : 100 = >  Accuracy: 0.3631\n",
      "epoch : 150 = >  Accuracy: 0.4419\n",
      "epoch : 200 = >  Accuracy: 0.4631\n",
      "epoch : 250 = >  Accuracy: 0.4811\n",
      "epoch : 300 = >  Accuracy: 0.5080\n",
      "epoch : 350 = >  Accuracy: 0.5221\n",
      "epoch : 400 = >  Accuracy: 0.5439\n",
      "epoch : 450 = >  Accuracy: 0.5542\n",
      "epoch : 500 = >  Accuracy: 0.5702\n",
      "epoch : 550 = >  Accuracy: 0.5760\n",
      "epoch : 600 = >  Accuracy: 0.5811\n",
      "epoch : 650 = >  Accuracy: 0.5888\n",
      "epoch : 700 = >  Accuracy: 0.5953\n",
      "Final accuracy: 0.5953\n",
      "epoch 0 ,Accuracy: 0.2745 , train acc : 0.2613548883756736\n",
      "epoch 50 ,Accuracy: 0.6331 , train acc : 0.7528868360277137\n",
      "epoch 100 ,Accuracy: 0.6793 , train acc : 0.8140877598152425\n",
      "epoch 150 ,Accuracy: 0.7158 , train acc : 0.8583525789068515\n",
      "epoch 200 ,Accuracy: 0.7114 , train acc : 0.8710546574287914\n",
      "epoch 250 ,Accuracy: 0.7184 , train acc : 0.8918398768283294\n",
      "epoch 300 ,Accuracy: 0.7235 , train acc : 0.9072363356428021\n",
      "epoch 350 ,Accuracy: 0.7255 , train acc : 0.9183987682832948\n",
      "epoch 400 ,Accuracy: 0.7267 , train acc : 0.9253271747498075\n",
      "epoch 450 ,Accuracy: 0.7357 , train acc : 0.9341801385681293\n",
      "epoch 500 ,Accuracy: 0.7223 , train acc : 0.9403387220939184\n",
      "epoch 550 ,Accuracy: 0.7126 , train acc : 0.947267128560431\n",
      "epoch 600 ,Accuracy: 0.7223 , train acc : 0.9611239414934565\n",
      "epoch 650 ,Accuracy: 0.7280 , train acc : 0.964203233256351\n",
      "epoch 700 ,Accuracy: 0.7274 , train acc : 0.9695919938414165\n",
      "epoch 750 ,Accuracy: 0.7210 , train acc : 0.9738260200153964\n",
      "epoch 800 ,Accuracy: 0.7267 , train acc : 0.9772902232486528\n",
      "epoch 850 ,Accuracy: 0.7248 , train acc : 0.9795996920708238\n",
      "epoch 900 ,Accuracy: 0.7184 , train acc : 0.9799846035411856\n",
      "epoch 950 ,Accuracy: 0.7248 , train acc : 0.9795996920708238\n",
      "epoch 1000 ,Accuracy: 0.7242 , train acc : 0.9849884526558892\n",
      "epoch 1050 ,Accuracy: 0.7146 , train acc : 0.9846035411855273\n",
      "epoch 1100 ,Accuracy: 0.7338 , train acc : 0.9857582755966128\n",
      "epoch 1150 ,Accuracy: 0.7178 , train acc : 0.9872979214780601\n",
      "epoch 1200 ,Accuracy: 0.7267 , train acc : 0.9884526558891455\n",
      "epoch 1250 ,Accuracy: 0.7248 , train acc : 0.9857582755966128\n",
      "epoch 1300 ,Accuracy: 0.7203 , train acc : 0.985373364126251\n",
      "epoch 1350 ,Accuracy: 0.7165 , train acc : 0.9888375673595073\n",
      "epoch 1400 ,Accuracy: 0.7267 , train acc : 0.9926866820631255\n",
      "epoch 1450 ,Accuracy: 0.7287 , train acc : 0.9888375673595073\n",
      "epoch 1500 ,Accuracy: 0.7255 , train acc : 0.9876828329484219\n",
      "epoch 1550 ,Accuracy: 0.7287 , train acc : 0.9942263279445728\n",
      "epoch 1600 ,Accuracy: 0.7267 , train acc : 0.9930715935334873\n",
      "epoch 1650 ,Accuracy: 0.7248 , train acc : 0.9903772132409546\n",
      "epoch 1700 ,Accuracy: 0.7152 , train acc : 0.9926866820631255\n",
      "epoch 1750 ,Accuracy: 0.7274 , train acc : 0.9899923017705927\n",
      "epoch 1800 ,Accuracy: 0.7216 , train acc : 0.9942263279445728\n",
      "epoch 1850 ,Accuracy: 0.7165 , train acc : 0.9907621247113164\n",
      "epoch 1900 ,Accuracy: 0.7248 , train acc : 0.9946112394149346\n",
      "epoch 1950 ,Accuracy: 0.7325 , train acc : 0.9946112394149346\n",
      "epoch 2000 ,Accuracy: 0.7319 , train acc : 0.9930715935334873\n",
      "epoch 2050 ,Accuracy: 0.7319 , train acc : 0.9942263279445728\n",
      "epoch 2100 ,Accuracy: 0.7248 , train acc : 0.9923017705927637\n",
      "epoch 2150 ,Accuracy: 0.7184 , train acc : 0.9961508852963818\n",
      "epoch 2200 ,Accuracy: 0.7165 , train acc : 0.9934565050038491\n",
      "epoch 2250 ,Accuracy: 0.7319 , train acc : 0.9953810623556582\n",
      "epoch 2300 ,Accuracy: 0.7319 , train acc : 0.9942263279445728\n",
      "epoch 2350 ,Accuracy: 0.7300 , train acc : 0.9953810623556582\n",
      "epoch 2400 ,Accuracy: 0.7210 , train acc : 0.9946112394149346\n",
      "epoch 2450 ,Accuracy: 0.7364 , train acc : 0.9973056197074672\n",
      "epoch 2500 ,Accuracy: 0.7319 , train acc : 0.9969207082371054\n",
      "epoch 2550 ,Accuracy: 0.7223 , train acc : 0.9988452655889145\n",
      "epoch 2600 ,Accuracy: 0.7312 , train acc : 0.9969207082371054\n",
      "epoch 2650 ,Accuracy: 0.7300 , train acc : 0.9969207082371054\n",
      "epoch 2700 ,Accuracy: 0.7293 , train acc : 0.9969207082371054\n",
      "epoch 2750 ,Accuracy: 0.7287 , train acc : 0.9965357967667436\n",
      "epoch 2800 ,Accuracy: 0.7242 , train acc : 0.9976905311778291\n",
      "epoch 2850 ,Accuracy: 0.7274 , train acc : 0.9949961508852964\n",
      "epoch 2900 ,Accuracy: 0.7325 , train acc : 0.9973056197074672\n",
      "epoch 2950 ,Accuracy: 0.7389 , train acc : 0.9980754426481909\n",
      "Accuracy: 0.7287\n",
      "base model\n",
      "0.5952533675432969\n",
      "0.5859000053737778\n",
      "OurModel\n",
      "0.7286722257857601\n",
      "0.722388195995566\n",
      "*****\n",
      "epoch : 7 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2207\n",
      "epoch : 100 = >  Accuracy: 0.3477\n",
      "epoch : 150 = >  Accuracy: 0.4496\n",
      "epoch : 200 = >  Accuracy: 0.4830\n",
      "epoch : 250 = >  Accuracy: 0.4913\n",
      "epoch : 300 = >  Accuracy: 0.5215\n",
      "epoch : 350 = >  Accuracy: 0.5247\n",
      "epoch : 400 = >  Accuracy: 0.5427\n",
      "epoch : 450 = >  Accuracy: 0.5491\n",
      "epoch : 500 = >  Accuracy: 0.5613\n",
      "epoch : 550 = >  Accuracy: 0.5690\n",
      "epoch : 600 = >  Accuracy: 0.5767\n",
      "epoch : 650 = >  Accuracy: 0.5863\n",
      "epoch : 700 = >  Accuracy: 0.5850\n",
      "Final accuracy: 0.5850\n",
      "epoch 0 ,Accuracy: 0.2572 , train acc : 0.26982294072363355\n",
      "epoch 50 ,Accuracy: 0.6190 , train acc : 0.7186297151655119\n",
      "epoch 100 ,Accuracy: 0.6652 , train acc : 0.7913779830638953\n",
      "epoch 150 ,Accuracy: 0.6825 , train acc : 0.8267898383371824\n",
      "epoch 200 ,Accuracy: 0.6844 , train acc : 0.842571208622017\n",
      "epoch 250 ,Accuracy: 0.6857 , train acc : 0.859122401847575\n",
      "epoch 300 ,Accuracy: 0.6979 , train acc : 0.8783679753656659\n",
      "epoch 350 ,Accuracy: 0.6985 , train acc : 0.8914549653579676\n",
      "epoch 400 ,Accuracy: 0.7114 , train acc : 0.8979984603541186\n",
      "epoch 450 ,Accuracy: 0.7011 , train acc : 0.9099307159353349\n",
      "epoch 500 ,Accuracy: 0.7075 , train acc : 0.9149345650500385\n",
      "epoch 550 ,Accuracy: 0.7062 , train acc : 0.9245573518090839\n",
      "epoch 600 ,Accuracy: 0.7024 , train acc : 0.9287913779830639\n",
      "epoch 650 ,Accuracy: 0.7062 , train acc : 0.9303310238645112\n",
      "epoch 700 ,Accuracy: 0.7030 , train acc : 0.9334103156274057\n",
      "epoch 750 ,Accuracy: 0.7049 , train acc : 0.9445727482678984\n",
      "epoch 800 ,Accuracy: 0.7004 , train acc : 0.9445727482678984\n",
      "epoch 850 ,Accuracy: 0.7049 , train acc : 0.9434180138568129\n",
      "epoch 900 ,Accuracy: 0.7004 , train acc : 0.9430331023864511\n",
      "epoch 950 ,Accuracy: 0.7126 , train acc : 0.9634334103156275\n",
      "epoch 1000 ,Accuracy: 0.7152 , train acc : 0.9615088529638183\n",
      "epoch 1050 ,Accuracy: 0.7158 , train acc : 0.9615088529638183\n",
      "epoch 1100 ,Accuracy: 0.7075 , train acc : 0.9607390300230947\n",
      "epoch 1150 ,Accuracy: 0.7229 , train acc : 0.9649730561970746\n",
      "epoch 1200 ,Accuracy: 0.7024 , train acc : 0.9645881447267128\n",
      "epoch 1250 ,Accuracy: 0.7146 , train acc : 0.9661277906081601\n",
      "epoch 1300 ,Accuracy: 0.7120 , train acc : 0.972671285604311\n",
      "epoch 1350 ,Accuracy: 0.7088 , train acc : 0.9657428791377983\n",
      "epoch 1400 ,Accuracy: 0.7178 , train acc : 0.9742109314857583\n",
      "epoch 1450 ,Accuracy: 0.7101 , train acc : 0.9688221709006929\n",
      "epoch 1500 ,Accuracy: 0.7235 , train acc : 0.9711316397228638\n",
      "epoch 1550 ,Accuracy: 0.7165 , train acc : 0.9711316397228638\n",
      "epoch 1600 ,Accuracy: 0.7107 , train acc : 0.9730561970746728\n",
      "epoch 1650 ,Accuracy: 0.7191 , train acc : 0.9722863741339491\n",
      "epoch 1700 ,Accuracy: 0.7197 , train acc : 0.9688221709006929\n",
      "epoch 1750 ,Accuracy: 0.7261 , train acc : 0.9795996920708238\n",
      "epoch 1800 ,Accuracy: 0.7081 , train acc : 0.9688221709006929\n",
      "epoch 1850 ,Accuracy: 0.7280 , train acc : 0.9776751347190146\n",
      "epoch 1900 ,Accuracy: 0.7133 , train acc : 0.9792147806004619\n",
      "epoch 1950 ,Accuracy: 0.7158 , train acc : 0.9795996920708238\n",
      "epoch 2000 ,Accuracy: 0.7178 , train acc : 0.9846035411855273\n",
      "epoch 2050 ,Accuracy: 0.7152 , train acc : 0.9849884526558892\n",
      "epoch 2100 ,Accuracy: 0.7043 , train acc : 0.9838337182448037\n",
      "epoch 2150 ,Accuracy: 0.7191 , train acc : 0.9861431870669746\n",
      "epoch 2200 ,Accuracy: 0.7191 , train acc : 0.9872979214780601\n",
      "epoch 2250 ,Accuracy: 0.7191 , train acc : 0.9876828329484219\n",
      "epoch 2300 ,Accuracy: 0.7255 , train acc : 0.9876828329484219\n",
      "epoch 2350 ,Accuracy: 0.7171 , train acc : 0.9884526558891455\n",
      "epoch 2400 ,Accuracy: 0.7197 , train acc : 0.9896073903002309\n",
      "epoch 2450 ,Accuracy: 0.7126 , train acc : 0.9880677444187836\n",
      "epoch 2500 ,Accuracy: 0.7171 , train acc : 0.9896073903002309\n",
      "epoch 2550 ,Accuracy: 0.7191 , train acc : 0.9907621247113164\n",
      "epoch 2600 ,Accuracy: 0.7178 , train acc : 0.9888375673595073\n",
      "epoch 2650 ,Accuracy: 0.7114 , train acc : 0.9923017705927637\n",
      "epoch 2700 ,Accuracy: 0.7139 , train acc : 0.9923017705927637\n",
      "epoch 2750 ,Accuracy: 0.7158 , train acc : 0.9923017705927637\n",
      "epoch 2800 ,Accuracy: 0.7107 , train acc : 0.99153194765204\n",
      "epoch 2850 ,Accuracy: 0.7203 , train acc : 0.9919168591224018\n",
      "epoch 2900 ,Accuracy: 0.7133 , train acc : 0.9957659738260201\n",
      "epoch 2950 ,Accuracy: 0.7197 , train acc : 0.9934565050038491\n",
      "Accuracy: 0.7171\n",
      "base model\n",
      "0.584990378447723\n",
      "0.5766205528502021\n",
      "OurModel\n",
      "0.7171263630532393\n",
      "0.7114177792755129\n",
      "*****\n",
      "epoch : 8 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2181\n",
      "epoch : 100 = >  Accuracy: 0.3496\n",
      "epoch : 150 = >  Accuracy: 0.4419\n",
      "epoch : 200 = >  Accuracy: 0.4663\n",
      "epoch : 250 = >  Accuracy: 0.4856\n",
      "epoch : 300 = >  Accuracy: 0.5067\n",
      "epoch : 350 = >  Accuracy: 0.5362\n",
      "epoch : 400 = >  Accuracy: 0.5433\n",
      "epoch : 450 = >  Accuracy: 0.5548\n",
      "epoch : 500 = >  Accuracy: 0.5548\n",
      "epoch : 550 = >  Accuracy: 0.5702\n",
      "epoch : 600 = >  Accuracy: 0.5728\n",
      "epoch : 650 = >  Accuracy: 0.5786\n",
      "epoch : 700 = >  Accuracy: 0.5895\n",
      "Final accuracy: 0.5895\n",
      "epoch 0 ,Accuracy: 0.2854 , train acc : 0.2894534257120862\n",
      "epoch 50 ,Accuracy: 0.6645 , train acc : 0.74364896073903\n",
      "epoch 100 ,Accuracy: 0.6908 , train acc : 0.8221709006928406\n",
      "epoch 150 ,Accuracy: 0.7114 , train acc : 0.8514241724403387\n",
      "epoch 200 ,Accuracy: 0.7203 , train acc : 0.8806774441878368\n",
      "epoch 250 ,Accuracy: 0.7274 , train acc : 0.8906851424172441\n",
      "epoch 300 ,Accuracy: 0.7293 , train acc : 0.8983833718244804\n",
      "epoch 350 ,Accuracy: 0.7280 , train acc : 0.9237875288683602\n",
      "epoch 400 ,Accuracy: 0.7300 , train acc : 0.9230177059276367\n",
      "epoch 450 ,Accuracy: 0.7152 , train acc : 0.9414934565050038\n",
      "epoch 500 ,Accuracy: 0.7197 , train acc : 0.9434180138568129\n",
      "epoch 550 ,Accuracy: 0.7255 , train acc : 0.9576597382602001\n",
      "epoch 600 ,Accuracy: 0.7300 , train acc : 0.9599692070823711\n",
      "epoch 650 ,Accuracy: 0.7203 , train acc : 0.962278675904542\n",
      "epoch 700 ,Accuracy: 0.7229 , train acc : 0.9591993841416474\n",
      "epoch 750 ,Accuracy: 0.7139 , train acc : 0.9668976135488837\n",
      "epoch 800 ,Accuracy: 0.7197 , train acc : 0.9711316397228638\n",
      "epoch 850 ,Accuracy: 0.7274 , train acc : 0.970746728252502\n",
      "epoch 900 ,Accuracy: 0.7235 , train acc : 0.9722863741339491\n",
      "epoch 950 ,Accuracy: 0.7300 , train acc : 0.9799846035411856\n",
      "epoch 1000 ,Accuracy: 0.7126 , train acc : 0.9819091608929946\n",
      "epoch 1050 ,Accuracy: 0.7216 , train acc : 0.9857582755966128\n",
      "epoch 1100 ,Accuracy: 0.7197 , train acc : 0.9819091608929946\n",
      "epoch 1150 ,Accuracy: 0.7107 , train acc : 0.9846035411855273\n",
      "epoch 1200 ,Accuracy: 0.7197 , train acc : 0.9838337182448037\n",
      "epoch 1250 ,Accuracy: 0.7216 , train acc : 0.9872979214780601\n",
      "epoch 1300 ,Accuracy: 0.7158 , train acc : 0.9849884526558892\n",
      "epoch 1350 ,Accuracy: 0.7133 , train acc : 0.9884526558891455\n",
      "epoch 1400 ,Accuracy: 0.7158 , train acc : 0.9892224788298691\n",
      "epoch 1450 ,Accuracy: 0.7300 , train acc : 0.9911470361816782\n",
      "epoch 1500 ,Accuracy: 0.7210 , train acc : 0.9899923017705927\n",
      "epoch 1550 ,Accuracy: 0.7210 , train acc : 0.9919168591224018\n",
      "epoch 1600 ,Accuracy: 0.7203 , train acc : 0.9930715935334873\n",
      "epoch 1650 ,Accuracy: 0.7203 , train acc : 0.9911470361816782\n",
      "epoch 1700 ,Accuracy: 0.7184 , train acc : 0.9934565050038491\n",
      "epoch 1750 ,Accuracy: 0.7075 , train acc : 0.9934565050038491\n",
      "epoch 1800 ,Accuracy: 0.7171 , train acc : 0.9923017705927637\n",
      "epoch 1850 ,Accuracy: 0.7210 , train acc : 0.9911470361816782\n",
      "epoch 1900 ,Accuracy: 0.7165 , train acc : 0.9953810623556582\n",
      "epoch 1950 ,Accuracy: 0.7267 , train acc : 0.9903772132409546\n",
      "epoch 2000 ,Accuracy: 0.7261 , train acc : 0.9899923017705927\n",
      "epoch 2050 ,Accuracy: 0.7120 , train acc : 0.9926866820631255\n",
      "epoch 2100 ,Accuracy: 0.7248 , train acc : 0.9926866820631255\n",
      "epoch 2150 ,Accuracy: 0.7300 , train acc : 0.993841416474211\n",
      "epoch 2200 ,Accuracy: 0.7203 , train acc : 0.9949961508852964\n",
      "epoch 2250 ,Accuracy: 0.7165 , train acc : 0.9946112394149346\n",
      "epoch 2300 ,Accuracy: 0.7191 , train acc : 0.9926866820631255\n",
      "epoch 2350 ,Accuracy: 0.7248 , train acc : 0.9965357967667436\n",
      "epoch 2400 ,Accuracy: 0.7280 , train acc : 0.9946112394149346\n",
      "epoch 2450 ,Accuracy: 0.7235 , train acc : 0.9919168591224018\n",
      "epoch 2500 ,Accuracy: 0.7248 , train acc : 0.9934565050038491\n",
      "epoch 2550 ,Accuracy: 0.7267 , train acc : 0.993841416474211\n",
      "epoch 2600 ,Accuracy: 0.7274 , train acc : 0.9961508852963818\n",
      "epoch 2650 ,Accuracy: 0.7114 , train acc : 0.9949961508852964\n",
      "epoch 2700 ,Accuracy: 0.7242 , train acc : 0.9976905311778291\n",
      "epoch 2750 ,Accuracy: 0.7235 , train acc : 0.9949961508852964\n",
      "epoch 2800 ,Accuracy: 0.7158 , train acc : 0.9973056197074672\n",
      "epoch 2850 ,Accuracy: 0.7146 , train acc : 0.9957659738260201\n",
      "epoch 2900 ,Accuracy: 0.7319 , train acc : 0.993841416474211\n",
      "epoch 2950 ,Accuracy: 0.7274 , train acc : 0.9965357967667436\n",
      "Accuracy: 0.7139\n",
      "base model\n",
      "0.5894804361770366\n",
      "0.5797450801275493\n",
      "OurModel\n",
      "0.7139191789608723\n",
      "0.7085950679693505\n",
      "*****\n",
      "epoch : 9 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2136\n",
      "epoch : 100 = >  Accuracy: 0.3515\n",
      "epoch : 150 = >  Accuracy: 0.4452\n",
      "epoch : 200 = >  Accuracy: 0.4650\n",
      "epoch : 250 = >  Accuracy: 0.4869\n",
      "epoch : 300 = >  Accuracy: 0.5119\n",
      "epoch : 350 = >  Accuracy: 0.5330\n",
      "epoch : 400 = >  Accuracy: 0.5478\n",
      "epoch : 450 = >  Accuracy: 0.5555\n",
      "epoch : 500 = >  Accuracy: 0.5645\n",
      "epoch : 550 = >  Accuracy: 0.5696\n",
      "epoch : 600 = >  Accuracy: 0.5747\n",
      "epoch : 650 = >  Accuracy: 0.5837\n",
      "epoch : 700 = >  Accuracy: 0.5914\n",
      "Final accuracy: 0.5914\n",
      "epoch 0 ,Accuracy: 0.2591 , train acc : 0.2702078521939954\n",
      "epoch 50 ,Accuracy: 0.6453 , train acc : 0.7582755966127791\n",
      "epoch 100 ,Accuracy: 0.6895 , train acc : 0.8148575827559661\n",
      "epoch 150 ,Accuracy: 0.7158 , train acc : 0.8494996150885297\n",
      "epoch 200 ,Accuracy: 0.7191 , train acc : 0.8814472671285605\n",
      "epoch 250 ,Accuracy: 0.7197 , train acc : 0.8999230177059276\n",
      "epoch 300 ,Accuracy: 0.7133 , train acc : 0.9137798306389531\n",
      "epoch 350 ,Accuracy: 0.7178 , train acc : 0.9137798306389531\n",
      "epoch 400 ,Accuracy: 0.7242 , train acc : 0.9330254041570438\n",
      "epoch 450 ,Accuracy: 0.7319 , train acc : 0.9403387220939184\n",
      "epoch 500 ,Accuracy: 0.7216 , train acc : 0.9468822170900693\n",
      "epoch 550 ,Accuracy: 0.7300 , train acc : 0.9503464203233256\n",
      "epoch 600 ,Accuracy: 0.7242 , train acc : 0.9530408006158584\n",
      "epoch 650 ,Accuracy: 0.7255 , train acc : 0.9553502694380293\n",
      "epoch 700 ,Accuracy: 0.7267 , train acc : 0.9668976135488837\n",
      "epoch 750 ,Accuracy: 0.7158 , train acc : 0.9699769053117783\n",
      "epoch 800 ,Accuracy: 0.7267 , train acc : 0.9722863741339491\n",
      "epoch 850 ,Accuracy: 0.7274 , train acc : 0.9772902232486528\n",
      "epoch 900 ,Accuracy: 0.7255 , train acc : 0.9819091608929946\n",
      "epoch 950 ,Accuracy: 0.7267 , train acc : 0.976905311778291\n",
      "epoch 1000 ,Accuracy: 0.7255 , train acc : 0.9819091608929946\n",
      "epoch 1050 ,Accuracy: 0.7312 , train acc : 0.9776751347190146\n",
      "epoch 1100 ,Accuracy: 0.7203 , train acc : 0.9834488067744419\n",
      "epoch 1150 ,Accuracy: 0.7267 , train acc : 0.9861431870669746\n",
      "epoch 1200 ,Accuracy: 0.7319 , train acc : 0.9846035411855273\n",
      "epoch 1250 ,Accuracy: 0.7280 , train acc : 0.9876828329484219\n",
      "epoch 1300 ,Accuracy: 0.7210 , train acc : 0.9899923017705927\n",
      "epoch 1350 ,Accuracy: 0.7357 , train acc : 0.9896073903002309\n",
      "epoch 1400 ,Accuracy: 0.7357 , train acc : 0.9903772132409546\n",
      "epoch 1450 ,Accuracy: 0.7261 , train acc : 0.9907621247113164\n",
      "epoch 1500 ,Accuracy: 0.7261 , train acc : 0.9907621247113164\n",
      "epoch 1550 ,Accuracy: 0.7229 , train acc : 0.993841416474211\n",
      "epoch 1600 ,Accuracy: 0.7312 , train acc : 0.9926866820631255\n",
      "epoch 1650 ,Accuracy: 0.7351 , train acc : 0.9930715935334873\n",
      "epoch 1700 ,Accuracy: 0.7267 , train acc : 0.9923017705927637\n",
      "epoch 1750 ,Accuracy: 0.7325 , train acc : 0.99153194765204\n",
      "epoch 1800 ,Accuracy: 0.7287 , train acc : 0.9946112394149346\n",
      "epoch 1850 ,Accuracy: 0.7203 , train acc : 0.993841416474211\n",
      "epoch 1900 ,Accuracy: 0.7306 , train acc : 0.993841416474211\n",
      "epoch 1950 ,Accuracy: 0.7306 , train acc : 0.9911470361816782\n",
      "epoch 2000 ,Accuracy: 0.7364 , train acc : 0.9946112394149346\n",
      "epoch 2050 ,Accuracy: 0.7203 , train acc : 0.9923017705927637\n",
      "epoch 2100 ,Accuracy: 0.7242 , train acc : 0.99153194765204\n",
      "epoch 2150 ,Accuracy: 0.7267 , train acc : 0.9953810623556582\n",
      "epoch 2200 ,Accuracy: 0.7287 , train acc : 0.9965357967667436\n",
      "epoch 2250 ,Accuracy: 0.7255 , train acc : 0.9946112394149346\n",
      "epoch 2300 ,Accuracy: 0.7223 , train acc : 0.9946112394149346\n",
      "epoch 2350 ,Accuracy: 0.7351 , train acc : 0.9942263279445728\n",
      "epoch 2400 ,Accuracy: 0.7287 , train acc : 0.9949961508852964\n",
      "epoch 2450 ,Accuracy: 0.7364 , train acc : 0.9949961508852964\n",
      "epoch 2500 ,Accuracy: 0.7332 , train acc : 0.9942263279445728\n",
      "epoch 2550 ,Accuracy: 0.7242 , train acc : 0.9946112394149346\n",
      "epoch 2600 ,Accuracy: 0.7338 , train acc : 0.9957659738260201\n",
      "epoch 2650 ,Accuracy: 0.7325 , train acc : 0.9965357967667436\n",
      "epoch 2700 ,Accuracy: 0.7223 , train acc : 0.9953810623556582\n",
      "epoch 2750 ,Accuracy: 0.7229 , train acc : 0.9953810623556582\n",
      "epoch 2800 ,Accuracy: 0.7325 , train acc : 0.9976905311778291\n",
      "epoch 2850 ,Accuracy: 0.7293 , train acc : 0.9973056197074672\n",
      "epoch 2900 ,Accuracy: 0.7396 , train acc : 0.993841416474211\n",
      "epoch 2950 ,Accuracy: 0.7235 , train acc : 0.9957659738260201\n",
      "Accuracy: 0.7460\n",
      "base model\n",
      "0.5914047466324567\n",
      "0.5834539630255207\n",
      "OurModel\n",
      "0.7459910198845414\n",
      "0.7396432686950303\n",
      "*****\n",
      "epoch : 10 / 10\n",
      "epoch : 50 = >  Accuracy: 0.2418\n",
      "epoch : 100 = >  Accuracy: 0.3682\n",
      "epoch : 150 = >  Accuracy: 0.4458\n",
      "epoch : 200 = >  Accuracy: 0.4715\n",
      "epoch : 250 = >  Accuracy: 0.4836\n",
      "epoch : 300 = >  Accuracy: 0.5138\n",
      "epoch : 350 = >  Accuracy: 0.5228\n",
      "epoch : 400 = >  Accuracy: 0.5369\n",
      "epoch : 450 = >  Accuracy: 0.5452\n",
      "epoch : 500 = >  Accuracy: 0.5625\n",
      "epoch : 550 = >  Accuracy: 0.5651\n",
      "epoch : 600 = >  Accuracy: 0.5792\n",
      "epoch : 650 = >  Accuracy: 0.5799\n",
      "epoch : 700 = >  Accuracy: 0.5908\n",
      "Final accuracy: 0.5908\n",
      "epoch 0 ,Accuracy: 0.2675 , train acc : 0.25981524249422633\n",
      "epoch 50 ,Accuracy: 0.6312 , train acc : 0.7378752886836027\n",
      "epoch 100 ,Accuracy: 0.6812 , train acc : 0.8140877598152425\n",
      "epoch 150 ,Accuracy: 0.6889 , train acc : 0.8448806774441878\n",
      "epoch 200 ,Accuracy: 0.7126 , train acc : 0.8729792147806005\n",
      "epoch 250 ,Accuracy: 0.7229 , train acc : 0.8879907621247113\n",
      "epoch 300 ,Accuracy: 0.7210 , train acc : 0.8910700538876059\n",
      "epoch 350 ,Accuracy: 0.7088 , train acc : 0.9091608929946112\n",
      "epoch 400 ,Accuracy: 0.7242 , train acc : 0.9168591224018475\n",
      "epoch 450 ,Accuracy: 0.7235 , train acc : 0.930715935334873\n",
      "epoch 500 ,Accuracy: 0.7216 , train acc : 0.9372594303310239\n",
      "epoch 550 ,Accuracy: 0.7191 , train acc : 0.9434180138568129\n",
      "epoch 600 ,Accuracy: 0.7261 , train acc : 0.9549653579676675\n",
      "epoch 650 ,Accuracy: 0.7319 , train acc : 0.9526558891454965\n",
      "epoch 700 ,Accuracy: 0.7216 , train acc : 0.9611239414934565\n",
      "epoch 750 ,Accuracy: 0.7325 , train acc : 0.9630484988452656\n",
      "epoch 800 ,Accuracy: 0.7357 , train acc : 0.9665127020785219\n",
      "epoch 850 ,Accuracy: 0.7248 , train acc : 0.9715165511932256\n",
      "epoch 900 ,Accuracy: 0.7267 , train acc : 0.9753656658968437\n",
      "epoch 950 ,Accuracy: 0.7203 , train acc : 0.9761354888375674\n",
      "epoch 1000 ,Accuracy: 0.7184 , train acc : 0.9792147806004619\n",
      "epoch 1050 ,Accuracy: 0.7319 , train acc : 0.9772902232486528\n",
      "epoch 1100 ,Accuracy: 0.7293 , train acc : 0.9795996920708238\n",
      "epoch 1150 ,Accuracy: 0.7120 , train acc : 0.9830638953040801\n",
      "epoch 1200 ,Accuracy: 0.7370 , train acc : 0.9834488067744419\n",
      "epoch 1250 ,Accuracy: 0.7319 , train acc : 0.9819091608929946\n",
      "epoch 1300 ,Accuracy: 0.7216 , train acc : 0.9876828329484219\n",
      "epoch 1350 ,Accuracy: 0.7306 , train acc : 0.9865280985373364\n",
      "epoch 1400 ,Accuracy: 0.7229 , train acc : 0.9896073903002309\n",
      "epoch 1450 ,Accuracy: 0.7255 , train acc : 0.9888375673595073\n",
      "epoch 1500 ,Accuracy: 0.7287 , train acc : 0.9869130100076983\n",
      "epoch 1550 ,Accuracy: 0.7191 , train acc : 0.9861431870669746\n",
      "epoch 1600 ,Accuracy: 0.7351 , train acc : 0.9865280985373364\n",
      "epoch 1650 ,Accuracy: 0.7171 , train acc : 0.9923017705927637\n",
      "epoch 1700 ,Accuracy: 0.7274 , train acc : 0.9923017705927637\n",
      "epoch 1750 ,Accuracy: 0.7280 , train acc : 0.9907621247113164\n",
      "epoch 1800 ,Accuracy: 0.7267 , train acc : 0.9911470361816782\n",
      "epoch 1850 ,Accuracy: 0.7267 , train acc : 0.9957659738260201\n",
      "epoch 1900 ,Accuracy: 0.7377 , train acc : 0.9965357967667436\n",
      "epoch 1950 ,Accuracy: 0.7293 , train acc : 0.993841416474211\n",
      "epoch 2000 ,Accuracy: 0.7210 , train acc : 0.99153194765204\n",
      "epoch 2050 ,Accuracy: 0.7248 , train acc : 0.9949961508852964\n",
      "epoch 2100 ,Accuracy: 0.7332 , train acc : 0.9930715935334873\n",
      "epoch 2150 ,Accuracy: 0.7191 , train acc : 0.9926866820631255\n",
      "epoch 2200 ,Accuracy: 0.7223 , train acc : 0.9942263279445728\n",
      "epoch 2250 ,Accuracy: 0.7223 , train acc : 0.9969207082371054\n",
      "epoch 2300 ,Accuracy: 0.7332 , train acc : 0.9969207082371054\n",
      "epoch 2350 ,Accuracy: 0.7255 , train acc : 0.9957659738260201\n",
      "epoch 2400 ,Accuracy: 0.7261 , train acc : 0.9957659738260201\n",
      "epoch 2450 ,Accuracy: 0.7235 , train acc : 0.9957659738260201\n",
      "epoch 2500 ,Accuracy: 0.7184 , train acc : 0.9965357967667436\n",
      "epoch 2550 ,Accuracy: 0.7351 , train acc : 0.9957659738260201\n",
      "epoch 2600 ,Accuracy: 0.7210 , train acc : 0.9953810623556582\n",
      "epoch 2650 ,Accuracy: 0.7242 , train acc : 0.9969207082371054\n",
      "epoch 2700 ,Accuracy: 0.7357 , train acc : 0.9946112394149346\n",
      "epoch 2750 ,Accuracy: 0.7255 , train acc : 0.9961508852963818\n",
      "epoch 2800 ,Accuracy: 0.7280 , train acc : 0.9961508852963818\n",
      "epoch 2850 ,Accuracy: 0.7216 , train acc : 0.9961508852963818\n",
      "epoch 2900 ,Accuracy: 0.7210 , train acc : 0.9969207082371054\n",
      "epoch 2950 ,Accuracy: 0.7300 , train acc : 0.9980754426481909\n",
      "Accuracy: 0.7274\n",
      "base model\n",
      "0.5907633098139833\n",
      "0.5825661455006242\n",
      "OurModel\n",
      "0.7273893521488134\n",
      "0.7212793950717554\n",
      "+++***Fianal Result***+++\n",
      "base\n",
      "Accuracy avg = 0.5905708787684413\n",
      "Accuracy deviation = 0.004190393270897083\n",
      "F1 score(macro) avg = 0.5819761169092125\n",
      "F1 score(macro) deviation = 0.0040056868667583565\n",
      "new model\n",
      "Accuracy avg = 0.7252726106478512\n",
      "Accuracy deviation = 0.009666821497368205\n",
      "F1 score(macro) avg = 0.7188347208205366\n",
      "F1 score(macro) deviation = 0.009582330224166736\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "GNN_model = GCN(64, dataset.num_classes).to(device)\n",
    "run_model(GNN_model , Gnn_epochs=700 ,enc_address=\"encoder_emb_BlogCatalog64.pt\" ,reply_threshold=0.85 , head_epochs= 3000 , validation_mask=new_valdation_mask , early_stop=0.88 )"
   ],
   "metadata": {
    "id": "zXst0FPejpAs",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "6ceea6e1-75ac-4956-fe83-af00532dbd50",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "epoch : 1 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3990\n",
      "epoch : 100 = >  Accuracy: 0.4785\n",
      "epoch : 150 = >  Accuracy: 0.5382\n",
      "epoch : 200 = >  Accuracy: 0.5696\n",
      "epoch : 250 = >  Accuracy: 0.5920\n",
      "epoch : 300 = >  Accuracy: 0.6068\n",
      "epoch : 350 = >  Accuracy: 0.6126\n",
      "epoch : 400 = >  Accuracy: 0.6177\n",
      "epoch : 450 = >  Accuracy: 0.6196\n",
      "epoch : 500 = >  Accuracy: 0.6241\n",
      "epoch : 550 = >  Accuracy: 0.6260\n",
      "epoch : 600 = >  Accuracy: 0.6286\n",
      "epoch : 650 = >  Accuracy: 0.6318\n",
      "epoch : 700 = >  Accuracy: 0.6344\n",
      "Final accuracy: 0.6344\n",
      "epoch 0 ,Accuracy: 0.3675 , train acc : 0.3464203233256351\n",
      "epoch 50 ,Accuracy: 0.6645 , train acc : 0.6689761354888376\n",
      "epoch 100 ,Accuracy: 0.6998 , train acc : 0.6982294072363356\n",
      "epoch 150 ,Accuracy: 0.6985 , train acc : 0.7109314857582756\n",
      "epoch 200 ,Accuracy: 0.7030 , train acc : 0.7167051578137028\n",
      "epoch 250 ,Accuracy: 0.7062 , train acc : 0.7217090069284064\n",
      "epoch 300 ,Accuracy: 0.6972 , train acc : 0.7263279445727483\n",
      "epoch 350 ,Accuracy: 0.7075 , train acc : 0.7220939183987682\n",
      "epoch 400 ,Accuracy: 0.6979 , train acc : 0.7263279445727483\n",
      "epoch 450 ,Accuracy: 0.7043 , train acc : 0.729022324865281\n",
      "epoch 500 ,Accuracy: 0.7037 , train acc : 0.7301770592763664\n",
      "epoch 550 ,Accuracy: 0.7088 , train acc : 0.7347959969207082\n",
      "epoch 600 ,Accuracy: 0.6979 , train acc : 0.7344110854503464\n",
      "epoch 650 ,Accuracy: 0.8332 , train acc : 0.8879907621247113\n",
      "epoch 700 ,Accuracy: 0.8319 , train acc : 0.8933795227097767\n",
      "epoch 750 ,Accuracy: 0.8358 , train acc : 0.8953040800615858\n",
      "epoch 800 ,Accuracy: 0.8364 , train acc : 0.9006928406466512\n",
      "epoch 850 ,Accuracy: 0.8377 , train acc : 0.8983833718244804\n",
      "epoch 900 ,Accuracy: 0.8319 , train acc : 0.8972286374133949\n",
      "epoch 950 ,Accuracy: 0.8358 , train acc : 0.9110854503464203\n",
      "epoch 1000 ,Accuracy: 0.8352 , train acc : 0.9080061585835257\n",
      "epoch 1050 ,Accuracy: 0.8352 , train acc : 0.9110854503464203\n",
      "epoch 1100 ,Accuracy: 0.8403 , train acc : 0.9103156274056967\n",
      "epoch 1150 ,Accuracy: 0.8268 , train acc : 0.9064665127020786\n",
      "epoch 1200 ,Accuracy: 0.8377 , train acc : 0.9122401847575058\n",
      "epoch 1250 ,Accuracy: 0.8364 , train acc : 0.9218629715165512\n",
      "epoch 1300 ,Accuracy: 0.8319 , train acc : 0.9218629715165512\n",
      "epoch 1350 ,Accuracy: 0.8371 , train acc : 0.9199384141647421\n",
      "epoch 1400 ,Accuracy: 0.8384 , train acc : 0.9284064665127021\n",
      "epoch 1450 ,Accuracy: 0.8319 , train acc : 0.9353348729792148\n",
      "epoch 1500 ,Accuracy: 0.8403 , train acc : 0.9295612009237876\n",
      "epoch 1550 ,Accuracy: 0.8345 , train acc : 0.9237875288683602\n",
      "epoch 1600 ,Accuracy: 0.8345 , train acc : 0.9376443418013857\n",
      "epoch 1650 ,Accuracy: 0.8352 , train acc : 0.9257120862201693\n",
      "epoch 1700 ,Accuracy: 0.8294 , train acc : 0.9372594303310239\n",
      "epoch 1750 ,Accuracy: 0.8281 , train acc : 0.9303310238645112\n",
      "epoch 1800 ,Accuracy: 0.8281 , train acc : 0.9341801385681293\n",
      "epoch 1850 ,Accuracy: 0.8172 , train acc : 0.941108545034642\n",
      "epoch 1900 ,Accuracy: 0.8377 , train acc : 0.9464973056197075\n",
      "epoch 1950 ,Accuracy: 0.8281 , train acc : 0.9387990762124712\n",
      "epoch 2000 ,Accuracy: 0.8249 , train acc : 0.9449576597382602\n",
      "epoch 2050 ,Accuracy: 0.8223 , train acc : 0.9422632794457275\n",
      "epoch 2100 ,Accuracy: 0.8249 , train acc : 0.9445727482678984\n",
      "epoch 2150 ,Accuracy: 0.8307 , train acc : 0.947652040030793\n",
      "epoch 2200 ,Accuracy: 0.8268 , train acc : 0.9468822170900693\n",
      "epoch 2250 ,Accuracy: 0.8217 , train acc : 0.9491916859122402\n",
      "epoch 2300 ,Accuracy: 0.8326 , train acc : 0.9553502694380293\n",
      "epoch 2350 ,Accuracy: 0.8236 , train acc : 0.949576597382602\n",
      "epoch 2400 ,Accuracy: 0.8262 , train acc : 0.9561200923787528\n",
      "epoch 2450 ,Accuracy: 0.8300 , train acc : 0.9568899153194765\n",
      "epoch 2500 ,Accuracy: 0.8262 , train acc : 0.9588144726712856\n",
      "epoch 2550 ,Accuracy: 0.8242 , train acc : 0.9630484988452656\n",
      "epoch 2600 ,Accuracy: 0.8268 , train acc : 0.9615088529638183\n",
      "epoch 2650 ,Accuracy: 0.8281 , train acc : 0.9599692070823711\n",
      "epoch 2700 ,Accuracy: 0.8326 , train acc : 0.9480369515011547\n",
      "epoch 2750 ,Accuracy: 0.8223 , train acc : 0.9661277906081601\n",
      "epoch 2800 ,Accuracy: 0.8313 , train acc : 0.9618937644341802\n",
      "epoch 2850 ,Accuracy: 0.8326 , train acc : 0.9672825250192456\n",
      "epoch 2900 ,Accuracy: 0.8281 , train acc : 0.9665127020785219\n",
      "epoch 2950 ,Accuracy: 0.8339 , train acc : 0.9680523479599692\n",
      "Accuracy: 0.8255\n",
      "base model\n",
      "0.6343810134701732\n",
      "0.5628419296966982\n",
      "OurModel\n",
      "0.8255291853752406\n",
      "0.8211707918370088\n",
      "*****\n",
      "epoch : 2 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3720\n",
      "epoch : 100 = >  Accuracy: 0.4657\n",
      "epoch : 150 = >  Accuracy: 0.5510\n",
      "epoch : 200 = >  Accuracy: 0.6164\n",
      "epoch : 250 = >  Accuracy: 0.6581\n",
      "epoch : 300 = >  Accuracy: 0.6851\n",
      "epoch : 350 = >  Accuracy: 0.6953\n",
      "epoch : 400 = >  Accuracy: 0.7024\n",
      "epoch : 450 = >  Accuracy: 0.7075\n",
      "epoch : 500 = >  Accuracy: 0.7094\n",
      "epoch : 550 = >  Accuracy: 0.7158\n",
      "epoch : 600 = >  Accuracy: 0.7210\n",
      "epoch : 650 = >  Accuracy: 0.7255\n",
      "epoch : 700 = >  Accuracy: 0.7306\n",
      "Final accuracy: 0.7306\n",
      "epoch 0 ,Accuracy: 0.3419 , train acc : 0.34141647421093146\n",
      "epoch 50 ,Accuracy: 0.8024 , train acc : 0.8171670515781371\n",
      "epoch 100 ,Accuracy: 0.8377 , train acc : 0.8541185527328714\n",
      "epoch 150 ,Accuracy: 0.8435 , train acc : 0.8745188606620478\n",
      "epoch 200 ,Accuracy: 0.8486 , train acc : 0.8891454965357968\n",
      "epoch 250 ,Accuracy: 0.8538 , train acc : 0.8979984603541186\n",
      "epoch 300 ,Accuracy: 0.8589 , train acc : 0.9014626635873749\n",
      "epoch 350 ,Accuracy: 0.8640 , train acc : 0.9045419553502695\n",
      "epoch 400 ,Accuracy: 0.8627 , train acc : 0.9114703618167821\n",
      "epoch 450 ,Accuracy: 0.8627 , train acc : 0.9110854503464203\n",
      "epoch 500 ,Accuracy: 0.8698 , train acc : 0.9164742109314857\n",
      "epoch 550 ,Accuracy: 0.8640 , train acc : 0.9226327944572749\n",
      "epoch 600 ,Accuracy: 0.8659 , train acc : 0.9268668206312548\n",
      "epoch 650 ,Accuracy: 0.8679 , train acc : 0.930715935334873\n",
      "epoch 700 ,Accuracy: 0.8659 , train acc : 0.9272517321016166\n",
      "epoch 750 ,Accuracy: 0.8621 , train acc : 0.9299461123941494\n",
      "epoch 800 ,Accuracy: 0.8627 , train acc : 0.9361046959199384\n",
      "epoch 850 ,Accuracy: 0.8666 , train acc : 0.9407236335642802\n",
      "epoch 900 ,Accuracy: 0.8679 , train acc : 0.9407236335642802\n",
      "epoch 950 ,Accuracy: 0.8647 , train acc : 0.9426481909160893\n",
      "epoch 1000 ,Accuracy: 0.8647 , train acc : 0.9457274826789839\n",
      "epoch 1050 ,Accuracy: 0.8653 , train acc : 0.9480369515011547\n",
      "epoch 1100 ,Accuracy: 0.8647 , train acc : 0.9553502694380293\n",
      "epoch 1150 ,Accuracy: 0.8634 , train acc : 0.9491916859122402\n",
      "epoch 1200 ,Accuracy: 0.8602 , train acc : 0.9534257120862202\n",
      "epoch 1250 ,Accuracy: 0.8576 , train acc : 0.947652040030793\n",
      "epoch 1300 ,Accuracy: 0.8640 , train acc : 0.9565050038491147\n",
      "epoch 1350 ,Accuracy: 0.8602 , train acc : 0.9568899153194765\n",
      "epoch 1400 ,Accuracy: 0.8653 , train acc : 0.958044649730562\n",
      "epoch 1450 ,Accuracy: 0.8627 , train acc : 0.9638183217859893\n",
      "epoch 1500 ,Accuracy: 0.8672 , train acc : 0.9607390300230947\n",
      "epoch 1550 ,Accuracy: 0.8691 , train acc : 0.958044649730562\n",
      "epoch 1600 ,Accuracy: 0.8595 , train acc : 0.9615088529638183\n",
      "epoch 1650 ,Accuracy: 0.8621 , train acc : 0.9653579676674365\n",
      "epoch 1700 ,Accuracy: 0.8621 , train acc : 0.9680523479599692\n",
      "epoch 1750 ,Accuracy: 0.8614 , train acc : 0.9638183217859893\n",
      "epoch 1800 ,Accuracy: 0.8627 , train acc : 0.9688221709006929\n",
      "epoch 1850 ,Accuracy: 0.8653 , train acc : 0.9742109314857583\n",
      "epoch 1900 ,Accuracy: 0.8685 , train acc : 0.9722863741339491\n",
      "epoch 1950 ,Accuracy: 0.8679 , train acc : 0.9699769053117783\n",
      "epoch 2000 ,Accuracy: 0.8691 , train acc : 0.9742109314857583\n",
      "epoch 2050 ,Accuracy: 0.8691 , train acc : 0.976905311778291\n",
      "epoch 2100 ,Accuracy: 0.8595 , train acc : 0.9730561970746728\n",
      "epoch 2150 ,Accuracy: 0.8614 , train acc : 0.9734411085450346\n",
      "epoch 2200 ,Accuracy: 0.8685 , train acc : 0.9753656658968437\n",
      "epoch 2250 ,Accuracy: 0.8691 , train acc : 0.9772902232486528\n",
      "epoch 2300 ,Accuracy: 0.8672 , train acc : 0.9792147806004619\n",
      "epoch 2350 ,Accuracy: 0.8659 , train acc : 0.9795996920708238\n",
      "epoch 2400 ,Accuracy: 0.8602 , train acc : 0.9803695150115473\n",
      "epoch 2450 ,Accuracy: 0.8666 , train acc : 0.9830638953040801\n",
      "epoch 2500 ,Accuracy: 0.8647 , train acc : 0.9795996920708238\n",
      "epoch 2550 ,Accuracy: 0.8659 , train acc : 0.9838337182448037\n",
      "epoch 2600 ,Accuracy: 0.8627 , train acc : 0.9819091608929946\n",
      "epoch 2650 ,Accuracy: 0.8582 , train acc : 0.9826789838337182\n",
      "epoch 2700 ,Accuracy: 0.8685 , train acc : 0.9846035411855273\n",
      "epoch 2750 ,Accuracy: 0.8557 , train acc : 0.9822940723633564\n",
      "epoch 2800 ,Accuracy: 0.8602 , train acc : 0.9826789838337182\n",
      "epoch 2850 ,Accuracy: 0.8666 , train acc : 0.9819091608929946\n",
      "epoch 2900 ,Accuracy: 0.8627 , train acc : 0.9838337182448037\n",
      "epoch 2950 ,Accuracy: 0.8627 , train acc : 0.9861431870669746\n",
      "Accuracy: 0.8659\n",
      "base model\n",
      "0.7305965362411803\n",
      "0.7134506731720434\n",
      "OurModel\n",
      "0.8659397049390635\n",
      "0.8614246930710525\n",
      "*****\n",
      "epoch : 3 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3887\n",
      "epoch : 100 = >  Accuracy: 0.4727\n",
      "epoch : 150 = >  Accuracy: 0.5581\n",
      "epoch : 200 = >  Accuracy: 0.6164\n",
      "epoch : 250 = >  Accuracy: 0.6523\n",
      "epoch : 300 = >  Accuracy: 0.6793\n",
      "epoch : 350 = >  Accuracy: 0.6947\n",
      "epoch : 400 = >  Accuracy: 0.6998\n",
      "epoch : 450 = >  Accuracy: 0.7004\n",
      "epoch : 500 = >  Accuracy: 0.7069\n",
      "epoch : 550 = >  Accuracy: 0.7139\n",
      "epoch : 600 = >  Accuracy: 0.7184\n",
      "epoch : 650 = >  Accuracy: 0.7229\n",
      "epoch : 700 = >  Accuracy: 0.7255\n",
      "Final accuracy: 0.7255\n",
      "epoch 0 ,Accuracy: 0.2527 , train acc : 0.27136258660508084\n",
      "epoch 50 ,Accuracy: 0.7864 , train acc : 0.8006158583525789\n",
      "epoch 100 ,Accuracy: 0.8332 , train acc : 0.859122401847575\n",
      "epoch 150 ,Accuracy: 0.8339 , train acc : 0.8772132409545804\n",
      "epoch 200 ,Accuracy: 0.8525 , train acc : 0.8791377983063895\n",
      "epoch 250 ,Accuracy: 0.8627 , train acc : 0.8918398768283294\n",
      "epoch 300 ,Accuracy: 0.8538 , train acc : 0.9006928406466512\n",
      "epoch 350 ,Accuracy: 0.8666 , train acc : 0.9068514241724404\n",
      "epoch 400 ,Accuracy: 0.8647 , train acc : 0.9110854503464203\n",
      "epoch 450 ,Accuracy: 0.8621 , train acc : 0.9137798306389531\n",
      "epoch 500 ,Accuracy: 0.8595 , train acc : 0.9176289453425712\n",
      "epoch 550 ,Accuracy: 0.8653 , train acc : 0.922247882986913\n",
      "epoch 600 ,Accuracy: 0.8691 , train acc : 0.9284064665127021\n",
      "epoch 650 ,Accuracy: 0.8550 , train acc : 0.926481909160893\n",
      "epoch 700 ,Accuracy: 0.8724 , train acc : 0.9280215550423403\n",
      "epoch 750 ,Accuracy: 0.8711 , train acc : 0.9268668206312548\n",
      "epoch 800 ,Accuracy: 0.8608 , train acc : 0.9334103156274057\n",
      "epoch 850 ,Accuracy: 0.8685 , train acc : 0.9372594303310239\n",
      "epoch 900 ,Accuracy: 0.8666 , train acc : 0.941108545034642\n",
      "epoch 950 ,Accuracy: 0.8685 , train acc : 0.9449576597382602\n",
      "epoch 1000 ,Accuracy: 0.8711 , train acc : 0.9407236335642802\n",
      "epoch 1050 ,Accuracy: 0.8711 , train acc : 0.949576597382602\n",
      "epoch 1100 ,Accuracy: 0.8672 , train acc : 0.9522709776751347\n",
      "epoch 1150 ,Accuracy: 0.8634 , train acc : 0.9438029253271748\n",
      "epoch 1200 ,Accuracy: 0.8634 , train acc : 0.9499615088529638\n",
      "epoch 1250 ,Accuracy: 0.8595 , train acc : 0.9530408006158584\n",
      "epoch 1300 ,Accuracy: 0.8602 , train acc : 0.9526558891454965\n",
      "epoch 1350 ,Accuracy: 0.8640 , train acc : 0.9568899153194765\n",
      "epoch 1400 ,Accuracy: 0.8602 , train acc : 0.9599692070823711\n",
      "epoch 1450 ,Accuracy: 0.8614 , train acc : 0.9584295612009238\n",
      "epoch 1500 ,Accuracy: 0.8544 , train acc : 0.962278675904542\n",
      "epoch 1550 ,Accuracy: 0.8653 , train acc : 0.9561200923787528\n",
      "epoch 1600 ,Accuracy: 0.8621 , train acc : 0.9630484988452656\n",
      "epoch 1650 ,Accuracy: 0.8589 , train acc : 0.9591993841416474\n",
      "epoch 1700 ,Accuracy: 0.8589 , train acc : 0.964203233256351\n",
      "epoch 1750 ,Accuracy: 0.8634 , train acc : 0.9722863741339491\n",
      "epoch 1800 ,Accuracy: 0.8634 , train acc : 0.9703618167821401\n",
      "epoch 1850 ,Accuracy: 0.8640 , train acc : 0.970746728252502\n",
      "epoch 1900 ,Accuracy: 0.8595 , train acc : 0.9719014626635873\n",
      "epoch 1950 ,Accuracy: 0.8608 , train acc : 0.9730561970746728\n",
      "epoch 2000 ,Accuracy: 0.8647 , train acc : 0.9699769053117783\n",
      "epoch 2050 ,Accuracy: 0.8666 , train acc : 0.9738260200153964\n",
      "epoch 2100 ,Accuracy: 0.8582 , train acc : 0.9734411085450346\n",
      "epoch 2150 ,Accuracy: 0.8634 , train acc : 0.9730561970746728\n",
      "epoch 2200 ,Accuracy: 0.8653 , train acc : 0.9742109314857583\n",
      "epoch 2250 ,Accuracy: 0.8563 , train acc : 0.9765204003079292\n",
      "epoch 2300 ,Accuracy: 0.8621 , train acc : 0.9784449576597383\n",
      "epoch 2350 ,Accuracy: 0.8647 , train acc : 0.9807544264819091\n",
      "epoch 2400 ,Accuracy: 0.8582 , train acc : 0.9811393379522709\n",
      "epoch 2450 ,Accuracy: 0.8550 , train acc : 0.9799846035411856\n",
      "epoch 2500 ,Accuracy: 0.8634 , train acc : 0.9811393379522709\n",
      "epoch 2550 ,Accuracy: 0.8544 , train acc : 0.9826789838337182\n",
      "epoch 2600 ,Accuracy: 0.8563 , train acc : 0.9830638953040801\n",
      "epoch 2650 ,Accuracy: 0.8621 , train acc : 0.9784449576597383\n",
      "epoch 2700 ,Accuracy: 0.8627 , train acc : 0.9792147806004619\n",
      "epoch 2750 ,Accuracy: 0.8634 , train acc : 0.9830638953040801\n",
      "epoch 2800 ,Accuracy: 0.8589 , train acc : 0.9838337182448037\n",
      "epoch 2850 ,Accuracy: 0.8621 , train acc : 0.9819091608929946\n",
      "epoch 2900 ,Accuracy: 0.8595 , train acc : 0.985373364126251\n",
      "epoch 2950 ,Accuracy: 0.8595 , train acc : 0.9865280985373364\n",
      "Accuracy: 0.8550\n",
      "base model\n",
      "0.7254650416933932\n",
      "0.7079512531046365\n",
      "OurModel\n",
      "0.8550352790250161\n",
      "0.8502308574662504\n",
      "*****\n",
      "epoch : 4 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3784\n",
      "epoch : 100 = >  Accuracy: 0.4843\n",
      "epoch : 150 = >  Accuracy: 0.5613\n",
      "epoch : 200 = >  Accuracy: 0.6241\n",
      "epoch : 250 = >  Accuracy: 0.6562\n",
      "epoch : 300 = >  Accuracy: 0.6825\n",
      "epoch : 350 = >  Accuracy: 0.6947\n",
      "epoch : 400 = >  Accuracy: 0.7037\n",
      "epoch : 450 = >  Accuracy: 0.7037\n",
      "epoch : 500 = >  Accuracy: 0.7101\n",
      "epoch : 550 = >  Accuracy: 0.7171\n",
      "epoch : 600 = >  Accuracy: 0.7235\n",
      "epoch : 650 = >  Accuracy: 0.7293\n",
      "epoch : 700 = >  Accuracy: 0.7287\n",
      "Final accuracy: 0.7287\n",
      "epoch 0 ,Accuracy: 0.3682 , train acc : 0.37644341801385683\n",
      "epoch 50 ,Accuracy: 0.6671 , train acc : 0.678598922247883\n",
      "epoch 100 ,Accuracy: 0.7056 , train acc : 0.7143956889915319\n",
      "epoch 150 ,Accuracy: 0.7120 , train acc : 0.7359507313317937\n",
      "epoch 200 ,Accuracy: 0.7287 , train acc : 0.7440338722093919\n",
      "epoch 250 ,Accuracy: 0.7203 , train acc : 0.7448036951501155\n",
      "epoch 300 ,Accuracy: 0.7267 , train acc : 0.7517321016166282\n",
      "epoch 350 ,Accuracy: 0.7255 , train acc : 0.7555812163202463\n",
      "epoch 400 ,Accuracy: 0.7312 , train acc : 0.7594303310238645\n",
      "epoch 450 ,Accuracy: 0.7319 , train acc : 0.7544264819091608\n",
      "epoch 500 ,Accuracy: 0.7293 , train acc : 0.7602001539645882\n",
      "epoch 550 ,Accuracy: 0.7306 , train acc : 0.7698229407236336\n",
      "epoch 600 ,Accuracy: 0.7351 , train acc : 0.7652040030792918\n",
      "epoch 650 ,Accuracy: 0.7332 , train acc : 0.76905311778291\n",
      "epoch 700 ,Accuracy: 0.7351 , train acc : 0.775211701308699\n",
      "epoch 750 ,Accuracy: 0.7344 , train acc : 0.76905311778291\n",
      "epoch 800 ,Accuracy: 0.7306 , train acc : 0.7748267898383372\n",
      "epoch 850 ,Accuracy: 0.7267 , train acc : 0.7725173210161663\n",
      "epoch 900 ,Accuracy: 0.7319 , train acc : 0.7779060816012318\n",
      "epoch 950 ,Accuracy: 0.7293 , train acc : 0.775211701308699\n",
      "epoch 1000 ,Accuracy: 0.7274 , train acc : 0.7806004618937644\n",
      "epoch 1050 ,Accuracy: 0.7293 , train acc : 0.783679753656659\n",
      "epoch 1100 ,Accuracy: 0.7248 , train acc : 0.7813702848344881\n",
      "epoch 1150 ,Accuracy: 0.7165 , train acc : 0.7840646651270208\n",
      "epoch 1200 ,Accuracy: 0.7248 , train acc : 0.783679753656659\n",
      "epoch 1250 ,Accuracy: 0.7261 , train acc : 0.7886836027713626\n",
      "epoch 1300 ,Accuracy: 0.7248 , train acc : 0.7852193995381063\n",
      "epoch 1350 ,Accuracy: 0.7210 , train acc : 0.7875288683602771\n",
      "epoch 1400 ,Accuracy: 0.7197 , train acc : 0.7906081601231717\n",
      "epoch 1450 ,Accuracy: 0.7280 , train acc : 0.7867590454195535\n",
      "epoch 1500 ,Accuracy: 0.7261 , train acc : 0.7913779830638953\n",
      "epoch 1550 ,Accuracy: 0.7216 , train acc : 0.7948421862971516\n",
      "epoch 1600 ,Accuracy: 0.7203 , train acc : 0.792147806004619\n",
      "epoch 1650 ,Accuracy: 0.7242 , train acc : 0.7967667436489607\n",
      "epoch 1700 ,Accuracy: 0.7287 , train acc : 0.7975365665896844\n",
      "epoch 1750 ,Accuracy: 0.7306 , train acc : 0.798306389530408\n",
      "epoch 1800 ,Accuracy: 0.7229 , train acc : 0.7933025404157044\n",
      "epoch 1850 ,Accuracy: 0.7267 , train acc : 0.7933025404157044\n",
      "epoch 1900 ,Accuracy: 0.7255 , train acc : 0.7967667436489607\n",
      "epoch 1950 ,Accuracy: 0.7216 , train acc : 0.8010007698229408\n",
      "epoch 2000 ,Accuracy: 0.7255 , train acc : 0.7990762124711316\n",
      "epoch 2050 ,Accuracy: 0.7191 , train acc : 0.8013856812933026\n",
      "epoch 2100 ,Accuracy: 0.7261 , train acc : 0.8029253271747498\n",
      "epoch 2150 ,Accuracy: 0.7203 , train acc : 0.8002309468822171\n",
      "epoch 2200 ,Accuracy: 0.7229 , train acc : 0.8033102386451116\n",
      "epoch 2250 ,Accuracy: 0.7248 , train acc : 0.8036951501154734\n",
      "epoch 2300 ,Accuracy: 0.7223 , train acc : 0.7990762124711316\n",
      "epoch 2350 ,Accuracy: 0.7223 , train acc : 0.7998460354118553\n",
      "epoch 2400 ,Accuracy: 0.7338 , train acc : 0.8017705927636644\n",
      "epoch 2450 ,Accuracy: 0.7178 , train acc : 0.8044649730561971\n",
      "epoch 2500 ,Accuracy: 0.7158 , train acc : 0.806774441878368\n",
      "epoch 2550 ,Accuracy: 0.7274 , train acc : 0.8075442648190916\n",
      "epoch 2600 ,Accuracy: 0.7210 , train acc : 0.8040800615858352\n",
      "epoch 2650 ,Accuracy: 0.7146 , train acc : 0.8040800615858352\n",
      "epoch 2700 ,Accuracy: 0.7242 , train acc : 0.806774441878368\n",
      "epoch 2750 ,Accuracy: 0.7178 , train acc : 0.8060046189376443\n",
      "epoch 2800 ,Accuracy: 0.7261 , train acc : 0.806774441878368\n",
      "epoch 2850 ,Accuracy: 0.7191 , train acc : 0.8056197074672825\n",
      "epoch 2900 ,Accuracy: 0.7267 , train acc : 0.8060046189376443\n",
      "epoch 2950 ,Accuracy: 0.7223 , train acc : 0.8063895304080062\n",
      "epoch 0 ,Accuracy: 0.2668 , train acc : 0.2548113933795227\n",
      "epoch 50 ,Accuracy: 0.7216 , train acc : 0.7190146266358738\n",
      "epoch 100 ,Accuracy: 0.7537 , train acc : 0.7498075442648191\n",
      "epoch 150 ,Accuracy: 0.8352 , train acc : 0.8664357197844496\n",
      "epoch 200 ,Accuracy: 0.8525 , train acc : 0.8860662047729022\n",
      "epoch 250 ,Accuracy: 0.8544 , train acc : 0.8903002309468823\n",
      "epoch 300 ,Accuracy: 0.8499 , train acc : 0.8918398768283294\n",
      "epoch 350 ,Accuracy: 0.8653 , train acc : 0.903387220939184\n",
      "epoch 400 ,Accuracy: 0.8691 , train acc : 0.9018475750577367\n",
      "epoch 450 ,Accuracy: 0.8679 , train acc : 0.9130100076982294\n",
      "epoch 500 ,Accuracy: 0.8653 , train acc : 0.9207082371054658\n",
      "epoch 550 ,Accuracy: 0.8685 , train acc : 0.9187836797536567\n",
      "epoch 600 ,Accuracy: 0.8640 , train acc : 0.9268668206312548\n",
      "epoch 650 ,Accuracy: 0.8608 , train acc : 0.9303310238645112\n",
      "epoch 700 ,Accuracy: 0.8634 , train acc : 0.9257120862201693\n",
      "epoch 750 ,Accuracy: 0.8685 , train acc : 0.9368745188606621\n",
      "epoch 800 ,Accuracy: 0.8659 , train acc : 0.9341801385681293\n",
      "epoch 850 ,Accuracy: 0.8659 , train acc : 0.9399538106235565\n",
      "epoch 900 ,Accuracy: 0.8685 , train acc : 0.939183987682833\n",
      "epoch 950 ,Accuracy: 0.8627 , train acc : 0.9426481909160893\n",
      "epoch 1000 ,Accuracy: 0.8711 , train acc : 0.9430331023864511\n",
      "epoch 1050 ,Accuracy: 0.8679 , train acc : 0.9457274826789839\n",
      "epoch 1100 ,Accuracy: 0.8589 , train acc : 0.9515011547344111\n",
      "epoch 1150 ,Accuracy: 0.8627 , train acc : 0.9511162432640493\n",
      "epoch 1200 ,Accuracy: 0.8653 , train acc : 0.953810623556582\n",
      "epoch 1250 ,Accuracy: 0.8698 , train acc : 0.9530408006158584\n",
      "epoch 1300 ,Accuracy: 0.8704 , train acc : 0.9591993841416474\n",
      "epoch 1350 ,Accuracy: 0.8653 , train acc : 0.9603541185527329\n",
      "epoch 1400 ,Accuracy: 0.8685 , train acc : 0.9657428791377983\n",
      "epoch 1450 ,Accuracy: 0.8544 , train acc : 0.964203233256351\n",
      "epoch 1500 ,Accuracy: 0.8634 , train acc : 0.9611239414934565\n",
      "epoch 1550 ,Accuracy: 0.8621 , train acc : 0.9668976135488837\n",
      "epoch 1600 ,Accuracy: 0.8653 , train acc : 0.9634334103156275\n",
      "epoch 1650 ,Accuracy: 0.8621 , train acc : 0.9672825250192456\n",
      "epoch 1700 ,Accuracy: 0.8640 , train acc : 0.968437259430331\n",
      "epoch 1750 ,Accuracy: 0.8621 , train acc : 0.9703618167821401\n",
      "epoch 1800 ,Accuracy: 0.8634 , train acc : 0.9730561970746728\n",
      "epoch 1850 ,Accuracy: 0.8493 , train acc : 0.9745958429561201\n",
      "epoch 1900 ,Accuracy: 0.8647 , train acc : 0.9745958429561201\n",
      "epoch 1950 ,Accuracy: 0.8563 , train acc : 0.9761354888375674\n",
      "epoch 2000 ,Accuracy: 0.8621 , train acc : 0.9703618167821401\n",
      "epoch 2050 ,Accuracy: 0.8621 , train acc : 0.9765204003079292\n",
      "epoch 2100 ,Accuracy: 0.8557 , train acc : 0.9761354888375674\n",
      "epoch 2150 ,Accuracy: 0.8595 , train acc : 0.9742109314857583\n",
      "epoch 2200 ,Accuracy: 0.8659 , train acc : 0.9822940723633564\n",
      "epoch 2250 ,Accuracy: 0.8698 , train acc : 0.9780600461893765\n",
      "epoch 2300 ,Accuracy: 0.8640 , train acc : 0.9780600461893765\n",
      "epoch 2350 ,Accuracy: 0.8557 , train acc : 0.9792147806004619\n",
      "epoch 2400 ,Accuracy: 0.8557 , train acc : 0.9834488067744419\n",
      "epoch 2450 ,Accuracy: 0.8653 , train acc : 0.9857582755966128\n",
      "epoch 2500 ,Accuracy: 0.8704 , train acc : 0.9788298691301001\n",
      "epoch 2550 ,Accuracy: 0.8653 , train acc : 0.9834488067744419\n",
      "epoch 2600 ,Accuracy: 0.8659 , train acc : 0.9872979214780601\n",
      "epoch 2650 ,Accuracy: 0.8608 , train acc : 0.9830638953040801\n",
      "epoch 2700 ,Accuracy: 0.8621 , train acc : 0.9826789838337182\n",
      "epoch 2750 ,Accuracy: 0.8595 , train acc : 0.9838337182448037\n",
      "epoch 2800 ,Accuracy: 0.8621 , train acc : 0.9869130100076983\n",
      "epoch 2850 ,Accuracy: 0.8614 , train acc : 0.9857582755966128\n",
      "epoch 2900 ,Accuracy: 0.8608 , train acc : 0.9888375673595073\n",
      "epoch 2950 ,Accuracy: 0.8653 , train acc : 0.9872979214780601\n",
      "Accuracy: 0.8659\n",
      "base model\n",
      "0.7286722257857601\n",
      "0.7116617192656528\n",
      "OurModel\n",
      "0.8659397049390635\n",
      "0.8618798921031173\n",
      "*****\n",
      "epoch : 5 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3932\n",
      "epoch : 100 = >  Accuracy: 0.4817\n",
      "epoch : 150 = >  Accuracy: 0.5657\n",
      "epoch : 200 = >  Accuracy: 0.6248\n",
      "epoch : 250 = >  Accuracy: 0.6575\n",
      "epoch : 300 = >  Accuracy: 0.6825\n",
      "epoch : 350 = >  Accuracy: 0.6947\n",
      "epoch : 400 = >  Accuracy: 0.7037\n",
      "epoch : 450 = >  Accuracy: 0.7043\n",
      "epoch : 500 = >  Accuracy: 0.7107\n",
      "epoch : 550 = >  Accuracy: 0.7171\n",
      "epoch : 600 = >  Accuracy: 0.7235\n",
      "epoch : 650 = >  Accuracy: 0.7287\n",
      "epoch : 700 = >  Accuracy: 0.7280\n",
      "Final accuracy: 0.7280\n",
      "epoch 0 ,Accuracy: 0.3079 , train acc : 0.29869130100076985\n",
      "epoch 50 ,Accuracy: 0.7845 , train acc : 0.7909930715935335\n",
      "epoch 100 ,Accuracy: 0.8275 , train acc : 0.8537336412625096\n",
      "epoch 150 ,Accuracy: 0.8428 , train acc : 0.8722093918398768\n",
      "epoch 200 ,Accuracy: 0.8448 , train acc : 0.8876058506543495\n",
      "epoch 250 ,Accuracy: 0.8627 , train acc : 0.8910700538876059\n",
      "epoch 300 ,Accuracy: 0.8614 , train acc : 0.9022324865280985\n",
      "epoch 350 ,Accuracy: 0.8640 , train acc : 0.9114703618167821\n",
      "epoch 400 ,Accuracy: 0.8666 , train acc : 0.9026173979984603\n",
      "epoch 450 ,Accuracy: 0.8614 , train acc : 0.9107005388760585\n",
      "epoch 500 ,Accuracy: 0.8666 , train acc : 0.9153194765204004\n",
      "epoch 550 ,Accuracy: 0.8704 , train acc : 0.9187836797536567\n",
      "epoch 600 ,Accuracy: 0.8666 , train acc : 0.9195535026943803\n",
      "epoch 650 ,Accuracy: 0.8672 , train acc : 0.9207082371054658\n",
      "epoch 700 ,Accuracy: 0.8756 , train acc : 0.9214780600461894\n",
      "epoch 750 ,Accuracy: 0.8640 , train acc : 0.9260969976905312\n",
      "epoch 800 ,Accuracy: 0.8653 , train acc : 0.9268668206312548\n",
      "epoch 850 ,Accuracy: 0.8685 , train acc : 0.9334103156274057\n",
      "epoch 900 ,Accuracy: 0.8736 , train acc : 0.9345650500384911\n",
      "epoch 950 ,Accuracy: 0.8679 , train acc : 0.9318706697459584\n",
      "epoch 1000 ,Accuracy: 0.8704 , train acc : 0.9414934565050038\n",
      "epoch 1050 ,Accuracy: 0.8647 , train acc : 0.9407236335642802\n",
      "epoch 1100 ,Accuracy: 0.8647 , train acc : 0.9434180138568129\n",
      "epoch 1150 ,Accuracy: 0.8672 , train acc : 0.9399538106235565\n",
      "epoch 1200 ,Accuracy: 0.8679 , train acc : 0.9480369515011547\n",
      "epoch 1250 ,Accuracy: 0.8666 , train acc : 0.9499615088529638\n",
      "epoch 1300 ,Accuracy: 0.8672 , train acc : 0.9468822170900693\n",
      "epoch 1350 ,Accuracy: 0.8672 , train acc : 0.9526558891454965\n",
      "epoch 1400 ,Accuracy: 0.8614 , train acc : 0.9553502694380293\n",
      "epoch 1450 ,Accuracy: 0.8640 , train acc : 0.9515011547344111\n",
      "epoch 1500 ,Accuracy: 0.8634 , train acc : 0.9541955350269438\n",
      "epoch 1550 ,Accuracy: 0.8640 , train acc : 0.9530408006158584\n",
      "epoch 1600 ,Accuracy: 0.8602 , train acc : 0.9568899153194765\n",
      "epoch 1650 ,Accuracy: 0.8691 , train acc : 0.958044649730562\n",
      "epoch 1700 ,Accuracy: 0.8743 , train acc : 0.9568899153194765\n",
      "epoch 1750 ,Accuracy: 0.8653 , train acc : 0.9661277906081601\n",
      "epoch 1800 ,Accuracy: 0.8595 , train acc : 0.9638183217859893\n",
      "epoch 1850 ,Accuracy: 0.8627 , train acc : 0.9615088529638183\n",
      "epoch 1900 ,Accuracy: 0.8557 , train acc : 0.9653579676674365\n",
      "epoch 1950 ,Accuracy: 0.8704 , train acc : 0.9618937644341802\n",
      "epoch 2000 ,Accuracy: 0.8704 , train acc : 0.970746728252502\n",
      "epoch 2050 ,Accuracy: 0.8724 , train acc : 0.964203233256351\n",
      "epoch 2100 ,Accuracy: 0.8602 , train acc : 0.9738260200153964\n",
      "epoch 2150 ,Accuracy: 0.8589 , train acc : 0.9719014626635873\n",
      "epoch 2200 ,Accuracy: 0.8576 , train acc : 0.9715165511932256\n",
      "epoch 2250 ,Accuracy: 0.8544 , train acc : 0.9738260200153964\n",
      "epoch 2300 ,Accuracy: 0.8640 , train acc : 0.9757505773672055\n",
      "epoch 2350 ,Accuracy: 0.8634 , train acc : 0.9745958429561201\n",
      "epoch 2400 ,Accuracy: 0.8627 , train acc : 0.9749807544264819\n",
      "epoch 2450 ,Accuracy: 0.8582 , train acc : 0.976905311778291\n",
      "epoch 2500 ,Accuracy: 0.8659 , train acc : 0.9795996920708238\n",
      "epoch 2550 ,Accuracy: 0.8563 , train acc : 0.9819091608929946\n",
      "epoch 2600 ,Accuracy: 0.8634 , train acc : 0.9792147806004619\n",
      "epoch 2650 ,Accuracy: 0.8557 , train acc : 0.9792147806004619\n",
      "epoch 2700 ,Accuracy: 0.8679 , train acc : 0.9788298691301001\n",
      "epoch 2750 ,Accuracy: 0.8672 , train acc : 0.9807544264819091\n",
      "epoch 2800 ,Accuracy: 0.8563 , train acc : 0.9803695150115473\n",
      "epoch 2850 ,Accuracy: 0.8557 , train acc : 0.9822940723633564\n",
      "epoch 2900 ,Accuracy: 0.8570 , train acc : 0.9822940723633564\n",
      "epoch 2950 ,Accuracy: 0.8589 , train acc : 0.9857582755966128\n",
      "Accuracy: 0.8634\n",
      "base model\n",
      "0.7280307889672867\n",
      "0.711103285223114\n",
      "OurModel\n",
      "0.86337395766517\n",
      "0.859730060115807\n",
      "*****\n",
      "epoch : 6 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3906\n",
      "epoch : 100 = >  Accuracy: 0.4759\n",
      "epoch : 150 = >  Accuracy: 0.5606\n",
      "epoch : 200 = >  Accuracy: 0.6248\n",
      "epoch : 250 = >  Accuracy: 0.6562\n",
      "epoch : 300 = >  Accuracy: 0.6825\n",
      "epoch : 350 = >  Accuracy: 0.6953\n",
      "epoch : 400 = >  Accuracy: 0.7037\n",
      "epoch : 450 = >  Accuracy: 0.7043\n",
      "epoch : 500 = >  Accuracy: 0.7107\n",
      "epoch : 550 = >  Accuracy: 0.7165\n",
      "epoch : 600 = >  Accuracy: 0.7235\n",
      "epoch : 650 = >  Accuracy: 0.7287\n",
      "epoch : 700 = >  Accuracy: 0.7274\n",
      "Final accuracy: 0.7274\n",
      "epoch 0 ,Accuracy: 0.3175 , train acc : 0.325635103926097\n",
      "epoch 50 ,Accuracy: 0.7935 , train acc : 0.8086989992301771\n",
      "epoch 100 ,Accuracy: 0.8255 , train acc : 0.859122401847575\n",
      "epoch 150 ,Accuracy: 0.8441 , train acc : 0.8710546574287914\n",
      "epoch 200 ,Accuracy: 0.8576 , train acc : 0.8910700538876059\n",
      "epoch 250 ,Accuracy: 0.8627 , train acc : 0.888760585065435\n",
      "epoch 300 ,Accuracy: 0.8582 , train acc : 0.9083910700538876\n",
      "epoch 350 ,Accuracy: 0.8634 , train acc : 0.9068514241724404\n",
      "epoch 400 ,Accuracy: 0.8659 , train acc : 0.9153194765204004\n",
      "epoch 450 ,Accuracy: 0.8698 , train acc : 0.9122401847575058\n",
      "epoch 500 ,Accuracy: 0.8653 , train acc : 0.9183987682832948\n",
      "epoch 550 ,Accuracy: 0.8627 , train acc : 0.9214780600461894\n",
      "epoch 600 ,Accuracy: 0.8647 , train acc : 0.9284064665127021\n",
      "epoch 650 ,Accuracy: 0.8756 , train acc : 0.9176289453425712\n",
      "epoch 700 ,Accuracy: 0.8640 , train acc : 0.9260969976905312\n",
      "epoch 750 ,Accuracy: 0.8749 , train acc : 0.9303310238645112\n",
      "epoch 800 ,Accuracy: 0.8627 , train acc : 0.9314857582755967\n",
      "epoch 850 ,Accuracy: 0.8653 , train acc : 0.9353348729792148\n",
      "epoch 900 ,Accuracy: 0.8672 , train acc : 0.9380292532717475\n",
      "epoch 950 ,Accuracy: 0.8563 , train acc : 0.941108545034642\n",
      "epoch 1000 ,Accuracy: 0.8724 , train acc : 0.949576597382602\n",
      "epoch 1050 ,Accuracy: 0.8614 , train acc : 0.9387990762124712\n",
      "epoch 1100 ,Accuracy: 0.8634 , train acc : 0.9511162432640493\n",
      "epoch 1150 ,Accuracy: 0.8659 , train acc : 0.9545804464973057\n",
      "epoch 1200 ,Accuracy: 0.8704 , train acc : 0.9457274826789839\n",
      "epoch 1250 ,Accuracy: 0.8666 , train acc : 0.953810623556582\n",
      "epoch 1300 ,Accuracy: 0.8704 , train acc : 0.9549653579676675\n",
      "epoch 1350 ,Accuracy: 0.8711 , train acc : 0.953810623556582\n",
      "epoch 1400 ,Accuracy: 0.8608 , train acc : 0.9618937644341802\n",
      "epoch 1450 ,Accuracy: 0.8672 , train acc : 0.9615088529638183\n",
      "epoch 1500 ,Accuracy: 0.8672 , train acc : 0.9576597382602001\n",
      "epoch 1550 ,Accuracy: 0.8653 , train acc : 0.9607390300230947\n",
      "epoch 1600 ,Accuracy: 0.8672 , train acc : 0.9645881447267128\n",
      "epoch 1650 ,Accuracy: 0.8640 , train acc : 0.962278675904542\n",
      "epoch 1700 ,Accuracy: 0.8653 , train acc : 0.9676674364896074\n",
      "epoch 1750 ,Accuracy: 0.8666 , train acc : 0.9668976135488837\n",
      "epoch 1800 ,Accuracy: 0.8595 , train acc : 0.9722863741339491\n",
      "epoch 1850 ,Accuracy: 0.8653 , train acc : 0.9722863741339491\n",
      "epoch 1900 ,Accuracy: 0.8679 , train acc : 0.9703618167821401\n",
      "epoch 1950 ,Accuracy: 0.8672 , train acc : 0.9745958429561201\n",
      "epoch 2000 ,Accuracy: 0.8698 , train acc : 0.9761354888375674\n",
      "epoch 2050 ,Accuracy: 0.8762 , train acc : 0.9711316397228638\n",
      "epoch 2100 ,Accuracy: 0.8685 , train acc : 0.9730561970746728\n",
      "epoch 2150 ,Accuracy: 0.8602 , train acc : 0.9757505773672055\n",
      "epoch 2200 ,Accuracy: 0.8608 , train acc : 0.9753656658968437\n",
      "epoch 2250 ,Accuracy: 0.8621 , train acc : 0.9830638953040801\n",
      "epoch 2300 ,Accuracy: 0.8653 , train acc : 0.9776751347190146\n",
      "epoch 2350 ,Accuracy: 0.8634 , train acc : 0.9784449576597383\n",
      "epoch 2400 ,Accuracy: 0.8525 , train acc : 0.9792147806004619\n",
      "epoch 2450 ,Accuracy: 0.8666 , train acc : 0.9830638953040801\n",
      "epoch 2500 ,Accuracy: 0.8589 , train acc : 0.9803695150115473\n",
      "epoch 2550 ,Accuracy: 0.8570 , train acc : 0.9776751347190146\n",
      "epoch 2600 ,Accuracy: 0.8653 , train acc : 0.9788298691301001\n",
      "epoch 2650 ,Accuracy: 0.8602 , train acc : 0.9826789838337182\n",
      "epoch 2700 ,Accuracy: 0.8666 , train acc : 0.9842186297151655\n",
      "epoch 2750 ,Accuracy: 0.8493 , train acc : 0.9857582755966128\n",
      "epoch 2800 ,Accuracy: 0.8627 , train acc : 0.9861431870669746\n",
      "epoch 2850 ,Accuracy: 0.8653 , train acc : 0.9899923017705927\n",
      "epoch 2900 ,Accuracy: 0.8672 , train acc : 0.9861431870669746\n",
      "epoch 2950 ,Accuracy: 0.8589 , train acc : 0.9857582755966128\n",
      "Accuracy: 0.8653\n",
      "base model\n",
      "0.7273893521488134\n",
      "0.7104254827979243\n",
      "OurModel\n",
      "0.8652982681205901\n",
      "0.8612366857163151\n",
      "*****\n",
      "epoch : 7 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3906\n",
      "epoch : 100 = >  Accuracy: 0.4811\n",
      "epoch : 150 = >  Accuracy: 0.5606\n",
      "epoch : 200 = >  Accuracy: 0.6267\n",
      "epoch : 250 = >  Accuracy: 0.6549\n",
      "epoch : 300 = >  Accuracy: 0.6844\n",
      "epoch : 350 = >  Accuracy: 0.6966\n",
      "epoch : 400 = >  Accuracy: 0.7056\n",
      "epoch : 450 = >  Accuracy: 0.7094\n",
      "epoch : 500 = >  Accuracy: 0.7126\n",
      "epoch : 550 = >  Accuracy: 0.7184\n",
      "epoch : 600 = >  Accuracy: 0.7235\n",
      "epoch : 650 = >  Accuracy: 0.7306\n",
      "epoch : 700 = >  Accuracy: 0.7300\n",
      "Final accuracy: 0.7300\n",
      "epoch 0 ,Accuracy: 0.3368 , train acc : 0.3506543494996151\n",
      "epoch 50 ,Accuracy: 0.7890 , train acc : 0.8094688221709007\n",
      "epoch 100 ,Accuracy: 0.8332 , train acc : 0.8564280215550424\n",
      "epoch 150 ,Accuracy: 0.8467 , train acc : 0.8791377983063895\n",
      "epoch 200 ,Accuracy: 0.8448 , train acc : 0.8883756735950731\n",
      "epoch 250 ,Accuracy: 0.8512 , train acc : 0.8995381062355658\n",
      "epoch 300 ,Accuracy: 0.8576 , train acc : 0.9037721324095458\n",
      "epoch 350 ,Accuracy: 0.8730 , train acc : 0.909545804464973\n",
      "epoch 400 ,Accuracy: 0.8717 , train acc : 0.909545804464973\n",
      "epoch 450 ,Accuracy: 0.8627 , train acc : 0.9153194765204004\n",
      "epoch 500 ,Accuracy: 0.8685 , train acc : 0.9199384141647421\n",
      "epoch 550 ,Accuracy: 0.8736 , train acc : 0.9230177059276367\n",
      "epoch 600 ,Accuracy: 0.8704 , train acc : 0.9241724403387221\n",
      "epoch 650 ,Accuracy: 0.8627 , train acc : 0.9314857582755967\n",
      "epoch 700 ,Accuracy: 0.8691 , train acc : 0.932640492686682\n",
      "epoch 750 ,Accuracy: 0.8724 , train acc : 0.9280215550423403\n",
      "epoch 800 ,Accuracy: 0.8627 , train acc : 0.9361046959199384\n",
      "epoch 850 ,Accuracy: 0.8685 , train acc : 0.9372594303310239\n",
      "epoch 900 ,Accuracy: 0.8698 , train acc : 0.9364896073903002\n",
      "epoch 950 ,Accuracy: 0.8698 , train acc : 0.9376443418013857\n",
      "epoch 1000 ,Accuracy: 0.8666 , train acc : 0.9457274826789839\n",
      "epoch 1050 ,Accuracy: 0.8640 , train acc : 0.9438029253271748\n",
      "epoch 1100 ,Accuracy: 0.8602 , train acc : 0.947652040030793\n",
      "epoch 1150 ,Accuracy: 0.8659 , train acc : 0.9522709776751347\n",
      "epoch 1200 ,Accuracy: 0.8653 , train acc : 0.9541955350269438\n",
      "epoch 1250 ,Accuracy: 0.8672 , train acc : 0.9549653579676675\n",
      "epoch 1300 ,Accuracy: 0.8621 , train acc : 0.9572748267898383\n",
      "epoch 1350 ,Accuracy: 0.8634 , train acc : 0.9565050038491147\n",
      "epoch 1400 ,Accuracy: 0.8640 , train acc : 0.953810623556582\n",
      "epoch 1450 ,Accuracy: 0.8595 , train acc : 0.9588144726712856\n",
      "epoch 1500 ,Accuracy: 0.8756 , train acc : 0.9611239414934565\n",
      "epoch 1550 ,Accuracy: 0.8743 , train acc : 0.9626635873749038\n",
      "epoch 1600 ,Accuracy: 0.8685 , train acc : 0.9649730561970746\n",
      "epoch 1650 ,Accuracy: 0.8634 , train acc : 0.9676674364896074\n",
      "epoch 1700 ,Accuracy: 0.8730 , train acc : 0.9738260200153964\n",
      "epoch 1750 ,Accuracy: 0.8679 , train acc : 0.9776751347190146\n",
      "epoch 1800 ,Accuracy: 0.8627 , train acc : 0.972671285604311\n",
      "epoch 1850 ,Accuracy: 0.8589 , train acc : 0.9672825250192456\n",
      "epoch 1900 ,Accuracy: 0.8743 , train acc : 0.970746728252502\n",
      "epoch 1950 ,Accuracy: 0.8659 , train acc : 0.9695919938414165\n",
      "epoch 2000 ,Accuracy: 0.8691 , train acc : 0.9680523479599692\n",
      "epoch 2050 ,Accuracy: 0.8704 , train acc : 0.976905311778291\n",
      "epoch 2100 ,Accuracy: 0.8653 , train acc : 0.9761354888375674\n",
      "epoch 2150 ,Accuracy: 0.8595 , train acc : 0.9757505773672055\n",
      "epoch 2200 ,Accuracy: 0.8698 , train acc : 0.9815242494226328\n",
      "epoch 2250 ,Accuracy: 0.8666 , train acc : 0.9788298691301001\n",
      "epoch 2300 ,Accuracy: 0.8685 , train acc : 0.9757505773672055\n",
      "epoch 2350 ,Accuracy: 0.8736 , train acc : 0.9792147806004619\n",
      "epoch 2400 ,Accuracy: 0.8647 , train acc : 0.972671285604311\n",
      "epoch 2450 ,Accuracy: 0.8717 , train acc : 0.9815242494226328\n",
      "epoch 2500 ,Accuracy: 0.8691 , train acc : 0.9803695150115473\n",
      "epoch 2550 ,Accuracy: 0.8717 , train acc : 0.985373364126251\n",
      "epoch 2600 ,Accuracy: 0.8717 , train acc : 0.9834488067744419\n",
      "epoch 2650 ,Accuracy: 0.8659 , train acc : 0.9838337182448037\n",
      "epoch 2700 ,Accuracy: 0.8634 , train acc : 0.9815242494226328\n",
      "epoch 2750 ,Accuracy: 0.8724 , train acc : 0.9846035411855273\n",
      "epoch 2800 ,Accuracy: 0.8672 , train acc : 0.9876828329484219\n",
      "epoch 2850 ,Accuracy: 0.8666 , train acc : 0.9857582755966128\n",
      "epoch 2900 ,Accuracy: 0.8634 , train acc : 0.9846035411855273\n",
      "epoch 2950 ,Accuracy: 0.8640 , train acc : 0.9811393379522709\n",
      "Accuracy: 0.8685\n",
      "base model\n",
      "0.7299550994227069\n",
      "0.7124835632156757\n",
      "OurModel\n",
      "0.868505452212957\n",
      "0.8649915045347555\n",
      "*****\n",
      "epoch : 8 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3887\n",
      "epoch : 100 = >  Accuracy: 0.4759\n",
      "epoch : 150 = >  Accuracy: 0.5581\n",
      "epoch : 200 = >  Accuracy: 0.6190\n",
      "epoch : 250 = >  Accuracy: 0.6536\n",
      "epoch : 300 = >  Accuracy: 0.6812\n",
      "epoch : 350 = >  Accuracy: 0.6947\n",
      "epoch : 400 = >  Accuracy: 0.7004\n",
      "epoch : 450 = >  Accuracy: 0.7004\n",
      "epoch : 500 = >  Accuracy: 0.7081\n",
      "epoch : 550 = >  Accuracy: 0.7146\n",
      "epoch : 600 = >  Accuracy: 0.7191\n",
      "epoch : 650 = >  Accuracy: 0.7235\n",
      "epoch : 700 = >  Accuracy: 0.7274\n",
      "Final accuracy: 0.7274\n",
      "epoch 0 ,Accuracy: 0.2899 , train acc : 0.2705927636643572\n",
      "epoch 50 ,Accuracy: 0.7813 , train acc : 0.8021555042340262\n",
      "epoch 100 ,Accuracy: 0.8172 , train acc : 0.8548883756735951\n",
      "epoch 150 ,Accuracy: 0.8505 , train acc : 0.8706697459584296\n",
      "epoch 200 ,Accuracy: 0.8570 , train acc : 0.8895304080061586\n",
      "epoch 250 ,Accuracy: 0.8608 , train acc : 0.8953040800615858\n",
      "epoch 300 ,Accuracy: 0.8672 , train acc : 0.9006928406466512\n",
      "epoch 350 ,Accuracy: 0.8640 , train acc : 0.9103156274056967\n",
      "epoch 400 ,Accuracy: 0.8698 , train acc : 0.9103156274056967\n",
      "epoch 450 ,Accuracy: 0.8704 , train acc : 0.9164742109314857\n",
      "epoch 500 ,Accuracy: 0.8621 , train acc : 0.9122401847575058\n",
      "epoch 550 ,Accuracy: 0.8756 , train acc : 0.9199384141647421\n",
      "epoch 600 ,Accuracy: 0.8768 , train acc : 0.926481909160893\n",
      "epoch 650 ,Accuracy: 0.8736 , train acc : 0.9218629715165512\n",
      "epoch 700 ,Accuracy: 0.8717 , train acc : 0.9376443418013857\n",
      "epoch 750 ,Accuracy: 0.8717 , train acc : 0.9334103156274057\n",
      "Accuracy: 0.8698\n",
      "base model\n",
      "0.7273893521488134\n",
      "0.709854297049984\n",
      "OurModel\n",
      "0.8697883258499037\n",
      "0.865415119183233\n",
      "*****\n",
      "epoch : 9 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3746\n",
      "epoch : 100 = >  Accuracy: 0.4631\n",
      "epoch : 150 = >  Accuracy: 0.5471\n",
      "epoch : 200 = >  Accuracy: 0.6100\n",
      "epoch : 250 = >  Accuracy: 0.6498\n",
      "epoch : 300 = >  Accuracy: 0.6786\n",
      "epoch : 350 = >  Accuracy: 0.6960\n",
      "epoch : 400 = >  Accuracy: 0.7004\n",
      "epoch : 450 = >  Accuracy: 0.7030\n",
      "epoch : 500 = >  Accuracy: 0.7056\n",
      "epoch : 550 = >  Accuracy: 0.7139\n",
      "epoch : 600 = >  Accuracy: 0.7203\n",
      "epoch : 650 = >  Accuracy: 0.7242\n",
      "epoch : 700 = >  Accuracy: 0.7267\n",
      "Final accuracy: 0.7267\n",
      "epoch 0 ,Accuracy: 0.4157 , train acc : 0.40454195535026943\n",
      "epoch 50 ,Accuracy: 0.7928 , train acc : 0.8090839107005389\n",
      "epoch 100 ,Accuracy: 0.8217 , train acc : 0.8568129330254042\n",
      "epoch 150 ,Accuracy: 0.8416 , train acc : 0.8826020015396459\n",
      "epoch 200 ,Accuracy: 0.8499 , train acc : 0.8829869130100076\n",
      "epoch 250 ,Accuracy: 0.8570 , train acc : 0.8941493456505004\n",
      "epoch 300 ,Accuracy: 0.8595 , train acc : 0.8956889915319477\n",
      "epoch 350 ,Accuracy: 0.8672 , train acc : 0.9049268668206313\n",
      "epoch 400 ,Accuracy: 0.8627 , train acc : 0.9126250962278676\n",
      "epoch 450 ,Accuracy: 0.8679 , train acc : 0.9087759815242494\n",
      "epoch 500 ,Accuracy: 0.8659 , train acc : 0.922247882986913\n",
      "epoch 550 ,Accuracy: 0.8730 , train acc : 0.9207082371054658\n",
      "epoch 600 ,Accuracy: 0.8653 , train acc : 0.9210931485758276\n",
      "epoch 650 ,Accuracy: 0.8672 , train acc : 0.9287913779830639\n",
      "epoch 700 ,Accuracy: 0.8724 , train acc : 0.9334103156274057\n",
      "epoch 750 ,Accuracy: 0.8672 , train acc : 0.9322555812163202\n",
      "epoch 800 ,Accuracy: 0.8589 , train acc : 0.939183987682833\n",
      "epoch 850 ,Accuracy: 0.8627 , train acc : 0.9357197844495766\n",
      "epoch 900 ,Accuracy: 0.8672 , train acc : 0.9368745188606621\n",
      "epoch 950 ,Accuracy: 0.8621 , train acc : 0.9441878367975366\n",
      "epoch 1000 ,Accuracy: 0.8717 , train acc : 0.9445727482678984\n",
      "epoch 1050 ,Accuracy: 0.8672 , train acc : 0.945342571208622\n",
      "epoch 1100 ,Accuracy: 0.8717 , train acc : 0.945342571208622\n",
      "epoch 1150 ,Accuracy: 0.8730 , train acc : 0.9464973056197075\n",
      "Accuracy: 0.8698\n",
      "base model\n",
      "0.72674791533034\n",
      "0.7093902992756584\n",
      "OurModel\n",
      "0.8697883258499037\n",
      "0.8658852501385946\n",
      "*****\n",
      "epoch : 10 / 10\n",
      "epoch : 50 = >  Accuracy: 0.3836\n",
      "epoch : 100 = >  Accuracy: 0.4798\n",
      "epoch : 150 = >  Accuracy: 0.5638\n",
      "epoch : 200 = >  Accuracy: 0.6228\n",
      "epoch : 250 = >  Accuracy: 0.6543\n",
      "epoch : 300 = >  Accuracy: 0.6793\n",
      "epoch : 350 = >  Accuracy: 0.6947\n",
      "epoch : 400 = >  Accuracy: 0.7011\n",
      "epoch : 450 = >  Accuracy: 0.7024\n",
      "epoch : 500 = >  Accuracy: 0.7081\n",
      "epoch : 550 = >  Accuracy: 0.7146\n",
      "epoch : 600 = >  Accuracy: 0.7210\n",
      "epoch : 650 = >  Accuracy: 0.7261\n",
      "epoch : 700 = >  Accuracy: 0.7300\n",
      "Final accuracy: 0.7300\n",
      "epoch 0 ,Accuracy: 0.3323 , train acc : 0.3737490377213241\n",
      "epoch 50 ,Accuracy: 0.6786 , train acc : 0.7128560431100847\n",
      "epoch 100 ,Accuracy: 0.7120 , train acc : 0.7363356428021555\n",
      "epoch 150 ,Accuracy: 0.7126 , train acc : 0.7528868360277137\n",
      "epoch 200 ,Accuracy: 0.7255 , train acc : 0.7594303310238645\n",
      "epoch 250 ,Accuracy: 0.7248 , train acc : 0.7590454195535027\n",
      "epoch 300 ,Accuracy: 0.7300 , train acc : 0.7655889145496536\n",
      "epoch 350 ,Accuracy: 0.7274 , train acc : 0.7682832948421863\n",
      "epoch 400 ,Accuracy: 0.7325 , train acc : 0.7698229407236336\n",
      "epoch 450 ,Accuracy: 0.7344 , train acc : 0.7798306389530408\n",
      "epoch 500 ,Accuracy: 0.7325 , train acc : 0.7748267898383372\n",
      "epoch 550 ,Accuracy: 0.7280 , train acc : 0.7744418783679754\n",
      "epoch 600 ,Accuracy: 0.7229 , train acc : 0.7829099307159353\n",
      "epoch 650 ,Accuracy: 0.7338 , train acc : 0.7844495765973826\n",
      "epoch 700 ,Accuracy: 0.7332 , train acc : 0.7848344880677445\n",
      "epoch 750 ,Accuracy: 0.7261 , train acc : 0.7890685142417244\n",
      "epoch 800 ,Accuracy: 0.7248 , train acc : 0.7894534257120862\n",
      "epoch 850 ,Accuracy: 0.7274 , train acc : 0.7925327174749808\n",
      "epoch 900 ,Accuracy: 0.7325 , train acc : 0.7967667436489607\n",
      "epoch 950 ,Accuracy: 0.7229 , train acc : 0.7940723633564281\n",
      "epoch 1000 ,Accuracy: 0.7248 , train acc : 0.7975365665896844\n",
      "epoch 1050 ,Accuracy: 0.7267 , train acc : 0.8002309468822171\n",
      "epoch 1100 ,Accuracy: 0.7223 , train acc : 0.7986913010007698\n",
      "epoch 1150 ,Accuracy: 0.7280 , train acc : 0.8025404157043879\n",
      "epoch 1200 ,Accuracy: 0.7261 , train acc : 0.8052347959969207\n",
      "epoch 1250 ,Accuracy: 0.7242 , train acc : 0.8048498845265589\n",
      "epoch 1300 ,Accuracy: 0.7255 , train acc : 0.8060046189376443\n",
      "epoch 1350 ,Accuracy: 0.7267 , train acc : 0.8079291762894534\n",
      "epoch 1400 ,Accuracy: 0.7229 , train acc : 0.806774441878368\n",
      "epoch 1450 ,Accuracy: 0.7267 , train acc : 0.8083140877598153\n",
      "epoch 1500 ,Accuracy: 0.7184 , train acc : 0.8094688221709007\n",
      "epoch 1550 ,Accuracy: 0.7325 , train acc : 0.8125481139337952\n",
      "epoch 1600 ,Accuracy: 0.7280 , train acc : 0.8110084680523479\n",
      "epoch 1650 ,Accuracy: 0.7287 , train acc : 0.815242494226328\n",
      "epoch 1700 ,Accuracy: 0.7229 , train acc : 0.8144726712856043\n",
      "epoch 1750 ,Accuracy: 0.7261 , train acc : 0.8190916089299461\n",
      "epoch 1800 ,Accuracy: 0.7261 , train acc : 0.8175519630484989\n",
      "epoch 1850 ,Accuracy: 0.7139 , train acc : 0.8160123171670516\n",
      "epoch 1900 ,Accuracy: 0.7293 , train acc : 0.8206312548113934\n",
      "epoch 1950 ,Accuracy: 0.7242 , train acc : 0.8133179368745188\n",
      "epoch 2000 ,Accuracy: 0.7216 , train acc : 0.8160123171670516\n",
      "epoch 2050 ,Accuracy: 0.7210 , train acc : 0.8163972286374134\n",
      "epoch 2100 ,Accuracy: 0.7171 , train acc : 0.8206312548113934\n",
      "epoch 2150 ,Accuracy: 0.7229 , train acc : 0.8237105465742879\n",
      "epoch 2200 ,Accuracy: 0.7235 , train acc : 0.8179368745188607\n",
      "epoch 2250 ,Accuracy: 0.7158 , train acc : 0.8194765204003079\n",
      "epoch 2300 ,Accuracy: 0.7210 , train acc : 0.8194765204003079\n",
      "epoch 2350 ,Accuracy: 0.7210 , train acc : 0.8244803695150116\n",
      "epoch 2400 ,Accuracy: 0.7203 , train acc : 0.8194765204003079\n",
      "epoch 2450 ,Accuracy: 0.7152 , train acc : 0.8225558121632025\n",
      "epoch 2500 ,Accuracy: 0.7184 , train acc : 0.8252501924557352\n",
      "epoch 2550 ,Accuracy: 0.7165 , train acc : 0.8225558121632025\n",
      "epoch 2600 ,Accuracy: 0.7261 , train acc : 0.8233256351039261\n",
      "epoch 2650 ,Accuracy: 0.7171 , train acc : 0.8240954580446497\n",
      "epoch 2700 ,Accuracy: 0.7229 , train acc : 0.8198614318706697\n",
      "epoch 2750 ,Accuracy: 0.7191 , train acc : 0.825635103926097\n",
      "epoch 2800 ,Accuracy: 0.7267 , train acc : 0.8264049268668207\n",
      "epoch 2850 ,Accuracy: 0.7229 , train acc : 0.8271747498075442\n",
      "epoch 2900 ,Accuracy: 0.7210 , train acc : 0.8279445727482679\n",
      "epoch 2950 ,Accuracy: 0.7280 , train acc : 0.8279445727482679\n",
      "epoch 0 ,Accuracy: 0.3688 , train acc : 0.3367975365665897\n",
      "epoch 50 ,Accuracy: 0.5728 , train acc : 0.5889145496535797\n",
      "epoch 100 ,Accuracy: 0.6928 , train acc : 0.7143956889915319\n",
      "epoch 150 ,Accuracy: 0.7158 , train acc : 0.7305619707467282\n",
      "epoch 200 ,Accuracy: 0.7216 , train acc : 0.7397998460354118\n",
      "epoch 250 ,Accuracy: 0.8557 , train acc : 0.8906851424172441\n",
      "epoch 300 ,Accuracy: 0.8614 , train acc : 0.8991531947652041\n",
      "epoch 350 ,Accuracy: 0.8647 , train acc : 0.9056966897613549\n",
      "epoch 400 ,Accuracy: 0.8685 , train acc : 0.9099307159353349\n",
      "epoch 450 ,Accuracy: 0.8679 , train acc : 0.9107005388760585\n",
      "epoch 500 ,Accuracy: 0.8666 , train acc : 0.9183987682832948\n",
      "epoch 550 ,Accuracy: 0.8550 , train acc : 0.9218629715165512\n",
      "epoch 600 ,Accuracy: 0.8627 , train acc : 0.9257120862201693\n",
      "epoch 650 ,Accuracy: 0.8647 , train acc : 0.9257120862201693\n",
      "epoch 700 ,Accuracy: 0.8679 , train acc : 0.926481909160893\n",
      "epoch 750 ,Accuracy: 0.8621 , train acc : 0.930715935334873\n",
      "epoch 800 ,Accuracy: 0.8698 , train acc : 0.9353348729792148\n",
      "epoch 850 ,Accuracy: 0.8717 , train acc : 0.9422632794457275\n",
      "epoch 900 ,Accuracy: 0.8653 , train acc : 0.9399538106235565\n",
      "epoch 950 ,Accuracy: 0.8711 , train acc : 0.9414934565050038\n",
      "epoch 1000 ,Accuracy: 0.8653 , train acc : 0.941108545034642\n",
      "epoch 1050 ,Accuracy: 0.8589 , train acc : 0.9426481909160893\n",
      "epoch 1100 ,Accuracy: 0.8685 , train acc : 0.9503464203233256\n",
      "epoch 1150 ,Accuracy: 0.8685 , train acc : 0.9507313317936874\n",
      "epoch 1200 ,Accuracy: 0.8672 , train acc : 0.9534257120862202\n",
      "epoch 1250 ,Accuracy: 0.8711 , train acc : 0.955735180908391\n",
      "epoch 1300 ,Accuracy: 0.8762 , train acc : 0.958044649730562\n",
      "epoch 1350 ,Accuracy: 0.8640 , train acc : 0.9576597382602001\n",
      "epoch 1400 ,Accuracy: 0.8640 , train acc : 0.9568899153194765\n",
      "epoch 1450 ,Accuracy: 0.8570 , train acc : 0.9611239414934565\n",
      "epoch 1500 ,Accuracy: 0.8653 , train acc : 0.9603541185527329\n",
      "epoch 1550 ,Accuracy: 0.8608 , train acc : 0.9603541185527329\n",
      "epoch 1600 ,Accuracy: 0.8595 , train acc : 0.9699769053117783\n",
      "epoch 1650 ,Accuracy: 0.8634 , train acc : 0.968437259430331\n",
      "epoch 1700 ,Accuracy: 0.8730 , train acc : 0.9722863741339491\n",
      "epoch 1750 ,Accuracy: 0.8672 , train acc : 0.9688221709006929\n",
      "epoch 1800 ,Accuracy: 0.8672 , train acc : 0.9738260200153964\n",
      "epoch 1850 ,Accuracy: 0.8544 , train acc : 0.9672825250192456\n",
      "epoch 1900 ,Accuracy: 0.8608 , train acc : 0.9703618167821401\n",
      "epoch 1950 ,Accuracy: 0.8634 , train acc : 0.9753656658968437\n",
      "epoch 2000 ,Accuracy: 0.8595 , train acc : 0.9803695150115473\n",
      "epoch 2050 ,Accuracy: 0.8647 , train acc : 0.970746728252502\n",
      "epoch 2100 ,Accuracy: 0.8685 , train acc : 0.9792147806004619\n",
      "epoch 2150 ,Accuracy: 0.8691 , train acc : 0.9822940723633564\n",
      "epoch 2200 ,Accuracy: 0.8538 , train acc : 0.976905311778291\n",
      "epoch 2250 ,Accuracy: 0.8666 , train acc : 0.9765204003079292\n",
      "epoch 2300 ,Accuracy: 0.8627 , train acc : 0.9822940723633564\n",
      "epoch 2350 ,Accuracy: 0.8595 , train acc : 0.9819091608929946\n",
      "epoch 2400 ,Accuracy: 0.8685 , train acc : 0.9819091608929946\n",
      "epoch 2450 ,Accuracy: 0.8582 , train acc : 0.9811393379522709\n",
      "epoch 2500 ,Accuracy: 0.8582 , train acc : 0.9792147806004619\n",
      "epoch 2550 ,Accuracy: 0.8614 , train acc : 0.9842186297151655\n",
      "epoch 2600 ,Accuracy: 0.8717 , train acc : 0.9865280985373364\n",
      "epoch 2650 ,Accuracy: 0.8621 , train acc : 0.9842186297151655\n",
      "epoch 2700 ,Accuracy: 0.8582 , train acc : 0.9846035411855273\n",
      "epoch 2750 ,Accuracy: 0.8627 , train acc : 0.9842186297151655\n",
      "epoch 2800 ,Accuracy: 0.8595 , train acc : 0.9896073903002309\n",
      "epoch 2850 ,Accuracy: 0.8640 , train acc : 0.9888375673595073\n",
      "epoch 2900 ,Accuracy: 0.8691 , train acc : 0.9907621247113164\n",
      "epoch 2950 ,Accuracy: 0.8589 , train acc : 0.9888375673595073\n",
      "Accuracy: 0.8557\n",
      "base model\n",
      "0.7299550994227069\n",
      "0.7129020896786867\n",
      "OurModel\n",
      "0.8556767158434894\n",
      "0.8517813018522467\n",
      "+++***Fianal Result***+++\n",
      "base\n",
      "Accuracy avg = 0.7188582424631174\n",
      "Accuracy deviation = 0.029725366094180673\n",
      "F1 score(macro) avg = 0.6962064592480074\n",
      "F1 score(macro) deviation = 0.04689009284094176\n",
      "new model\n",
      "Accuracy avg = 0.8604874919820398\n",
      "Accuracy deviation = 0.013346579274569668\n",
      "F1 score(macro) avg = 0.8563746156018381\n",
      "F1 score(macro) deviation = 0.013479602852541309\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}